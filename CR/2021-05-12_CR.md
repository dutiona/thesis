# CR réunion plan manuscrit

Présents EC MR

Ordre du jour
---

* retours sur chapitres Genericity et Taxonomy

Remarques
---

Genericité :
===

* définir à minima une image pour la suite du chapitre
* généricité dans les bibliothèques : parler plus en détail des endroits qui sont notés comme "not aborded here"
* introduire ce qu'est un type/supertype, à quoi ca sert, propriétés statiques/dynamiques etc (cf. com)
* polymorphisme paramètrique > parler plus en détail et notament concernant les références
* axe de généricité qui est indépendant de l'archi, dissocier de la prog hétérogène (code qui s'execute sur plusieurs architectures, code host, code devices), par opposition au C++ qui a son propre modèle mémoire bien spécifié. En parler au début, avec des exemples
* détailler le tableau
* parler des désavantages à être trop statiques (ne pas pouvoir sélectionner son SE dans Pylène, cf. com), par ex une image non connu préalablement à la compilation = pas possible, quid image5d_double ?
* -> ce qui est important de connaitre à la compilation, ce qui est important de connaitre à l'exécution (prop statiques, dynamiques)
* quand on parle de propriétés : qu'est-ce qu'une image, que sont ses propriétés dynémiques et statiques
* 

Dans pre-2011 :
* prendre exemples olena/milena pour CRTP/SFINAE avec SCOOP
* en CRTP : montrer les comment c'est utile pour appliquer des pre-concepts (SCOOP et Boost.concept)
* il manque l'aspect trait (property-based dans SCOOP) pour le dispatch
* il n'y a pas besoin d'avoir une taxonomie complète des images pour introduire les concepts nécessaire pour la comphérension de ce chatpitre
* critiquer ces méthodes : pro/cons, problèmes, itération des solutions

Dans post2011 :
* reprendre les exemples pre-2011 et les simplifier 
* bechmark 2.3.3 : réfléchir à l'utilité de ce bench et revoir le setup nombre de type différents chéckés vs. nb de concepts vs. nombre d'appels à des fonctions contraintes pour coller aux cas réels d'utilisation
* benchmark : expliquer la motivation, renommer le titre
* le mot constrained genericity n'apparait pas
* C++ template in a dynamic world : pourquoi on est dans un monde dynamique dans notre cas
  * expliquer les use cases
  * images ont des informations dynamiques
  * on veut être capable de les utiliser dans une interface dynamique (notebook) dans un cycle repl court
* 

Taxonomy
===

* decomposabilité = pour les élément structurants, reste exact pour un élément structurant plat (min, max -> peut on faire le max des max (max max)
* séparabilité = pour les filtres linéaires, par exemples les gaussienes, on sépare en 2 : ce sont des sommes, est-ce que la somme(somme,somme) donne le même résultat.
* réellement définir une image en profondeur

Taxonomy :
* faire la taxonomy des algorithmes avant celles des image puisqu'ils définissent les images
* algorithmes pixel-wise, algorithmes locaux, algorithmes globaux
  * se restreindre à la morpho maths pour l'énumération des algos
  * but = motivier la complexiter de l'interface des concepts taxonomy image/se
* définir ce qu'est une image :
  * niveau de l'interface
  * niveau de l'imple
  * différents type de structure (pixels hexa, mesh, graph)
  * topology (grille, cubique)
  * morphologie des types
  * propriétés
* il faut que l'interface dans les listing de concept soit justifié par les besoins définis dans ce qu'est une image (et se, voisinage)
* taxonomy motivée par le besoin algorithmique
* relire ce qu'avait fait Roland
* faire un graph hiérarchique récapitulatif des objets relatifs à la taxonomy
  * le design est orienté propriété avec des concepts qui sont des archetypes d'ensemble de propriété qui ont du sens groupées ensemble d'un point de vue algorithmique
* différence propriété vs. concept (ex. pk writable n'est pas un trait dans l'image)
* pourquoi a-t-on encore besoin de trait ?
* deep learning : confusion entre la méthode d'apprentissage et le calcul déporté sur cloud/cluster/GPU/...
  * différence entre ce qui est exécuté et comment l'exécuter

* aborder le parcours performant d'une image (mdrange) 
  * citer les benchmarks algos eécrits en C vs. algo bibliothèque

* canvas = 2 choses:
  * factorisation du boilerplate dispatch ce qui simplifie l'écriture du code pour des target arch différentes
  * abstraction d'un type de parcours d'image pour du traitement. Par ex, parallel for, tiling
  * avec 1 canvas d'algorithme on arrive à écrire plusieurs algorithmes de MM
    * plusieurs versions et spécialisation de ces algorithmes
      * version -> pluralité des types d'entré pour un même opérateur
      * spécialisation -> pluralité des possibilité d'optimisation au sein de l'algorithme en fonction des propriété de ces types d'entrée
    * quels sont les règles de dispatch dans le canvas (régularité, se sep/dec/inc, etc. par ex dans une dil/ero)
    * regarder le canvas d'union find utilisé pour tous les opérateurs algébriques de MM

  * canvas = meta algo donc ils sont abstraits de l'imple. Et donc le mainteneur peut faire de la prog hétérogène en sous-jascent sans que le user ne soit impacté.
    * en particulier, monoid + accumulation local -> devide & conquer (map/reduce est exclusif au calcul distribué)
* opérateurs connexes, canvas d'union find.

Remarque globale :
* aller plus loin que dilatation/érosion
