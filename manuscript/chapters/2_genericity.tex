\chapter{Genericity}
\label{chap.genericity}

In natural language we say that something is generic when it can fit several purpose at once while being decently
efficient. For instance, a computer is generic tool that allows one to write documents, access emails, browse Internet,
play video games, watch movies, read e-books etc. In programming, we will say that a tool is generic when it can fit
several purposes. For instance, the gcc compiler can compile several programming languages (C, C++, Objective-C,
Objective-C++, Fortran, Ada, D, Go, and BRIG (HSAIL)) as well as target several architectures (IA-32 (x86), x86-64, ARM,
SPARC, etc.). Henceforth we can say that gcc is a generic compiler. At this point it is important to note that even
though a tool is deemed generic, there is a scope on what the tool can do and what the tool cannot do. A compiler
despite supporting many languages and architectures, will not be able to make a phone call or a coffee. As such it is
important to note that genericity is an aspect that qualifies something. We will now study the generic aspect related to
libraries and programming languages.

\paragraph{Genericity within libraries} is described by the cardinality of how many use-cases it can handle. Very often
a library provide data structures, to represent and give sens to the data the user wants to process, as well as
algorithms to process those data and provide different type of results. A library will be then labeled as \emph{generic}
when (i) its data structure allows the user to express himself fully with no limitation and when (ii) its algorithm bank
is large enough to do anything the user would want to do with its data. In reality such a library does not exists and
there are always limitations. Studying those limitation and what reason motivates them is the key to understand how to
surpass them in the future, by developing new hardware and/or software support to new feature allowing for more
genericity.

\paragraph{Genericity within programming language} is described by the ability of the language to execute a code
statement over a large amount of data structure, be they native (char, int, ...) or not (user defined). It is nowadays
primordial for a programming language to be able to do so nowadays. Indeed, in a world where Information Technologies
are everywhere, the amount of code written by software developers is staggering. And with it so are the amount of bugs
and security vulnerabilities. Being able to natively have a programming language that enables to do \emph{more} by
writing \emph{less} mathematically results in a reduced development and maintenance cost. Programming languages offers
many ways to achieve genericity which is dependent of the language intrinsic specificities: compiled or interpreted,
native or emulated, etc.


\section{Genericity within libraries}
\label{genericity.sec.libraries}

Projecting the notion of genericity to Image Processing, we can deduce that we need two important aspects in order to be
generic. First, we need to decorelate the data structures and its topology and underlying data from the algorithms.
Indeed, we want our algorithms to support as much data structures as possible. Second, many algorithms share the same
computational shape and can be factorized together.

Genericity can have two different meanings depending on the people you ask. For instance, some will argue that
genericity is high level and qualifies a tool which is "generic enough" to handle all of his use-cases. Others will
argue that genericity is about how the code is written: generic enough to handle all the use cases possibles. Neither is
wrong. However, for the sake of comprehension we will use different words for each of these cases. A tool generic enough
to handle a lot of use-case will be called \emph{versatile}. Finally, for a tool whose aim is to provide a programming
framework to handle code of any use-case we will use \emph{generic}. In this paper, genericity will be about code. The
figure~\ref{fig.type.vs.algo} illustrates this result of the same generic watershed implementation applied on an image
2D, a graph as well as a mesh.

\begin{figure}[tbh]
  \centering
  \begin{tabular}{cccc}
                                                                     & image 2D
                                                                     & graph    & mesh \\[5pt]
    input:                                                           &
    \fbox{\includegraphics[width=.2\linewidth]{figs/geninput-000b}}  &
    \fbox{\includegraphics[width=.2\linewidth]{figs/geninput-001b}}  &
    \fbox{\includegraphics[width=.2\linewidth]{figs/geninput-002b}}
    \\[5pt]
    %
    output:                                                          &
    \fbox{\includegraphics[width=.2\linewidth]{figs/genoutput-000}}  &
    \fbox{\includegraphics[width=.2\linewidth]{figs/genoutput-001b}} &
    \fbox{\includegraphics[width=.2\linewidth]{figs/genoutput-002b}}
    \\
  \end{tabular}
  \bigskip

  \text{The same code run on all these input.}

  \caption{Watershed algorithm applied to three different image types.}
  \label{fig.type.vs.algo}
\end{figure}

In image processing, there are 3 main axes around which genericity is working. The first axis is about the data type:
grey level or RGB color (8-bits, 10-bits), decimal (double) and so on. The second axis, is about the structure of the
image: a contiguous buffer (2D or 3D), a graph, a look-up table and so on. Finally, the third axis is about additional
data that can be fed to image processing algorithms: structuring element (disc, ball, square, cube), labels
(classification), maps, border information and so on. In the end, an image is just a point within this space of
possibilities, illustrated in~\ref{fig.gen.espaceSAV}. Nowadays, it is not reasonable to have specific code for every
existing possibility within this space. It is all the more true when one wants efficiency.

\begin{figure}[tbh]
  \centering
  \subfloat[]{\includestandalone[width=1.7in]{figs/espaceSeI}}
  \hfil
  \subfloat[]{\includestandalone[width=1.7in]{figs/espaceSAV}}
  \caption{The space of possible implementation of the \emph{dilation(image, se)} routine. The image axis shown in (a)
    is in-fact multidimensional and should be considered 2D as in (b).}
  \label{fig.gen.espaceSAV}
\end{figure}

Genericity is not new and was first introduced in 1988 by Musser et al.~\cite{musser.1988.generic} in 1988. The main
point is to dissociate data structures and algorithms. The more your data structures and algorithms are tied together,
the less you will be generic and will fail to handle multiple data structures in the same algorithm. Further work has
been made about genericity in~\cite{musser.1994.algorithm, dehnert.1998.fundamentals}. Those works highlight the notion
of abstraction to be able to turn an algorithm tied to a data structure into a generic algorithm. Notably
in~\cite{stepanov.2009.elements}, Stepanov digs further and introduce the notion of \emph{Concepts}, which are static
requirements about the behavior of a type, by showing how to design a generic library and its algorithms. He highlights
the importance of having the algorithms driving the behavior requirements, and not the opposite. These works are very
suitable to be applied in the area of Image processing where we typically have a lot of algorithms (also called
operators) that are required to work on a lot of different data structures (also called image types).

The authors explain in~\cite{roynard.2019.rrpr} how to capitalize on those works to turn a data-structure-specific image
processing algorithm into a generic algorithm. We also explain how \emph{concepts} can ease the implementation of
generic algorithms. This approach is implemented in a library~\cite{carlinet.2018.pylena} which allows us to provide a
proof of concept over the feasibility of having generic image processing operators running on multiple image types with
near-native performances. Let us first explain briefly how we achieved this.

\subsection{Different approaches to get genericity}
\label{genericity.libraries.subsec.approaches}

First, let us consider the morphological \emph{dilation} that takes two inputs: an image and a flat structuring element
(SE). Then the set of some possible inputs is depicted in~\ref{fig.gen.espaceSAV}. Without genericity, with $s$ the
number of image type, $v$ the number of value type and $k$ the number of structuring elements, one would have to write
$s * v * k$ different \emph{dilation} routine.

There are several ways to reach a high level of genericity. First there are the \emph{code duplication} approach as well
as the \emph{generalization} approach. Finally, there is a way that consists in using expert, domain specific tools
specifically engineered for this purpose and build upon them: those tools usually make heavy usage of \emph{inclusion
  \& parametric polymorphism}, also known as template metaprogramming in C++, to provide the basic bricks the user needs
to build upon.

\paragraph{Code duplication approach} consists in writing and optimizing the algorithm for a particular type in mind.
Then, each time a new type is introduced, all the algorithm must be rewritten for this specific type. Additionally, each
time a new algorithm is introduced, it must support all the existing types and thus be written multiple times. This
approach does not scale well when the complexity of algorithms grows, and the number of data types increases. Neither it
does allow the implementer to easily make use of optimization opportunities that can be offered by different data types
having a common property. This translates into heavy switch/case statement in the code as show in~\ref{fig.gen.exhau}
that illustrate how the \emph{fill} algorithm needs to dispatch according to the input data type.

\begin{figure}[tbh]
  \centering
  \begin{minted}[linenos,xleftmargin=17pt,gobble=2]{cpp}
  // image types parametrized by their
  // underlying value type
  template <ValueType V> struct image2d<V> { /* ... */ };
  template <ValueType V> struct image_lut<V> {/* ... */};
  // ...
  void fill(any_image img, any_value v)
  {
    switch((img.structure_kind, img.value_kind))
    {
    case (BUFFER2D, UINT8):
      fill_img2d_uint8( (image2d<uint8>) img,
                        (uint8) any_value );
    // ...
    case (LUT, RGB8):
      fill_lut_rgb8( (image_lut<rgb8>) img,
                     (rgb8) any_value );
    }
  }
  \end{minted}
  \caption{Fill algorithm skeleton with a switch/case dispatcher to ensure exhaustivity.}
  \label{fig.gen.exhau}
\end{figure}

In addition, it is important to note that the exhaustivity aspect is only illustrated regarding the data structure types
here. Indeed, the data structures are all already generic for their underlying data type (named \emph{ValueType} in the
code). When one write \texttt{image2d<uint8>} (l.10), it means \emph{2D-image whose pixels' have a single channel 8-bits
  value}. This approach enables one to write an algorithm at maximum efficiency for a particular data type, however one
can easily miss optimization opportunities if not knowledgeable enough too. This approach is best for early prototypes
and trying to find common behaviors pattern among algorithms, or common properties across different data types. No IP
library has chosen this approach due to the obvious maintenance issue induced.

\paragraph{Generalization approach} consists in finding a common denominator to all the image types. Once designed, this
common denominator, also called supertype, will allow the library developer to write all the algorithms only once: for
the supertype. The processing pipeline will then consist in three steps. First convert the input image type into the
supertype, second process the supertype into the algorithm pipeline requested by the user, finally convert back the
resulting image into the specific image type the user is expecting. This approach offers the advantage of being
maintainable. Adding a new image type is just a matter of providing the two conversions facilities: to and from the
supertype. Adding an algorithm is also just a matter of writing it once for the supertype. This mechanism is shown
in~\ref{fig.gen.generalized}. However, one must keep in mind that the conversion can be costly. Also, processing the
supertype may induce a significant performance trade-off while processing the original type would be much faster.
Furthermore, it is not always possible to find this common denominator when enumerating through some esoteric data
types. Finally, the provided interface (from the supertype) may allow the image to be used incorrectly, such as a $2D$
image being processed into video ($3D+t$) algorithm. Widely use libraries such as
OpenCV~\cite{bradski.2000.opencv}, scikit-image~\cite{vanderwalt.2014.skimage} use this technique to handle as many
image types as possible. There are other libraries, for instance CImg~\cite{tschumperle.2012.cimg},
MegaWave~\cite{froment.2012.megawave}, that also use this approach however this paper will not address them.

\begin{figure}[tbh]
  \centering
  \begin{minted}[gobble=2]{cpp}
  struct any_image { /* ... */ }; // generalized type
  // specific types w/ conversion routines
  struct image2D { any_image to(); void from(any_image); };
  struct imageGraph { any_image to(); void from(any_image); };
  // ...
  void fill(any_image img, any_value v) {
    for(auto p : img.pixels())
      p.val() = v;
  }
  \end{minted}
  \caption{Fill algorithm for a generalized supertype.}
  \label{fig.gen.generalized}
\end{figure}

\paragraph{Inclusion \& Parametric polymorphism approach} consists in extracting behavior patterns from algorithms to
group them into logical brick called \emph{concepts} (for static parametric polymorphism), or \emph{interface} (for
dynamic inclusion polymorphism). Each algorithm will require a set of behavior pattern that the inputs need to satisfy.
In C++, it can be done either by using inclusion polymorphism, or by using parametric polymorphism, as shown
in~\ref{fig.gen.inclupoly}. In~\cite{roynard.2019.rrpr}, the authors leverage a new C++20 feature (the concept) to show
how it is possible to turn an algorithm, specific to an image type, into a more abstract, generic one that does not
induce any performance loss.

\begin{figure}[htb]
  \centering
  \subfloat{
    \includegraphics[width=1.64in]{figs/inclupoly}
  }
  \hfil
  \subfloat{
    \includegraphics[width=1.64in]{figs/parapoly}
  }
  \vfil
  \subfloat[]{
    \includegraphics[width=1.64in]{figs/inclupoly_code}
  }
  \hfil
  \subfloat[]{
    \includegraphics[width=1.64in]{figs/parapoly_code}
  }
  \caption{Dynamic, object-oriented polymorphism (a) vs. static, parametric polymorphism (b).}
  \label{fig.gen.inclupoly}
\end{figure}

Multiple libraries exist and leverage this approach to try to achieve a high genericity degree as well as high
performance by offering varied abstract facilities over image types and underlying data types. Those are
IPP~\cite{taylor.2004.intel}, ITK~\cite{johnson.2013.ITKSoftwareGuideThirdEdition}, Boost.GIL~\cite{bourdev.2006.bgil},
Vigra~\cite{kothe.2011.generic}, GrAL~\cite{berti.2006.gral}, DGTal~\cite{coeurjolly.2016.dgtal},
Milena~\cite{levillain.2009.ismm,levillain.2010.icip},
Olena~\cite{olena.2000.www,levillain.2011.phd,geraud.2012.hdr,levillain.2014.ciarp} and
Pylena~\cite{carlinet.2018.pylena}. Most of them have been written in complex C++ whose details remain visible from the
user standpoint and thus are often difficult and complex to handle. It is also harder to debug because errors in highly
templated code shows up very deep in compiler error trace.

\paragraph{Alternative approaches} such as relying on a \emph{Domain Specific Language} (DSL) exists and usually try to
address heterogeneous computation, which can be considered as another kind of genericity related to the target
architectures. Halide~\cite{ragankelley.2013.halide} and SYCL~\cite{brown.2019.heterogeneous,wong.2019.heterogeneous}
both provide their own DSL to that end. Others like Eigen~\cite{guennebaud.2010.eigen},
Blaze~\cite{iglberger.2012.blaze,iglberger.2012_1.blaze}, Blitz++~\cite{veldhuizen.2000.blitz} or
Armadillo~\cite{sanderson.2016.armadillo} have their main goal set on performances and try to provide a generic way to
address the issue of parallelization and/or vectorization leveraging lazy computing via a construct named
\emph{expression templates}~\cite{veldhuizen.1995.expression}. They do not aim to be able to handle as many input types
as possible, however, the lazy-computing techniques used generates new types on-the-fly. Henceforth, those libraries
still need to have embed generic facilities. This paper address genericity at the input level rather than the target
architecture level, henceforth, we will not broach this topic in this paper.

The table comparing all the pros. and cons. from the aforementioned approaches is presented
in~\cref{table.gen.approaches}.

\begin{table}[tbh]
  \centering
  \begin{threeparttable}
    \caption{Genericity approaches: pros. \& cons.}
    \begin{tabular}{l|ccccc}
      Paradigm             & TC      & CS      & E       & 1IA    & EA      \\
      \hline
      Code Duplication     & \cmark  & \xmark  & \cmark  & \xmark & \xmark  \\
      Code Generalization  & \xmark  & \eqmark & \eqmark & \cmark & \xmark  \\
      Object-Orientation   & \eqmark & \cmark  & \xmark  & \cmark & \cmark  \\
      Generic Programming: &         &         &         &        &         \\
      \quad with C++11     & \cmark  & \eqmark & \cmark  & \cmark & \eqmark \\
      \quad with C++17     & \cmark  & \cmark  & \cmark  & \cmark & \eqmark \\
      \quad with C++20     & \cmark  & \cmark  & \cmark  & \cmark & \cmark  \\
    \end{tabular}
    \begin{tablenotes}
      \item TC: type checking; CS: code simplicity; E: efficiency
      \item 1IA: one implementation per algorithm; EA: explicit abstractions / constrained genericity
    \end{tablenotes}
    \label{table.gen.approaches}
  \end{threeparttable}
\end{table}


\subsection{Unjustified limitations}
\label{genericity.libraries.subsec.limitations}

Image processing community operates mostly with either Python or Matlab~\cite{etter.2002.introduction}. As such this
paper will focus on those two technologies. Python offers access to two major libraries for image processing: OpenCV and
scikit-image. Matlab has built-in support as well as toolboxes for more advanced features. When we intersect
scikit-image and Matlab, we can notice that both are very similar both in feature and interface. As such, it is possible
to regroup them both here for the sake of comprehension. As stated above, when considering a generic library, one must
consider the three axes: underlying data type, domain structure and additional data. Let us compare how the mentioned
library behave along those axes with a simple algorithm such as the morphological dilation.

\subsubsection{Limitations regarding feasibility}

\paragraph{Data type} Dilating a grayscale or a binary image works fine as intended with all the libraries. However,
when dilating a RGB colored image, usually the algorithm should be able to work if a supremum function is provided (or a
defaulted one is automatically selected). Despite that fact, scikit-image does not allow one to dilate a colored RGB
image and raises an error: it is required to convert the image beforehand.

OpenCV arbitrarily decides that the dilation consists in dilating each channel of the coloured image separately from one
another, which most of the time is wrong because false colors may appear. Furthermore, it is not possible to provide a
supremum function to the dilation algorithm.

\paragraph{Domain structure} To perform a dilation, it is required to have a structuring element whose shape match the
structure of the domain of the image. For instance, dilating a 2D-image requires the use of a structuring element whose
shape may be a disc or a rectangle. To dilate a 3D-image, one would need to use a structuring element whose shape is of
a ball or a cube. Scikit-image supports 3D-images as well as structuring element whose shape are compatible (ball,
rectangle and octahedron). This naturally leads to having a support for the dilation of 3D-images. On the other hand,
OpenCV does support 3D-images whereas its dilation algorithm cannot handle them. The algorithm exits with an error.
Worse, when passing a wrong structuring element (a rectangle) to the dilation algorithm alongside the 3D-image, the
algorithm works and produce a result which is false: it is different from the application of the 2D- structuring element
on each slice of the image.


\subsubsection{Limitations regarding optimizations}

Each library has its own strategies to optimize its routines when implementing them.

\paragraph{Scikit-image} Scikit-image, for instance, will check whether the structuring element is separable (only for
rectangle shapes) so that it can dispatch on an optimized multi-pass 1D routine for each part separated which linearize
the execution time and greatly improve performances for large structuring element.

Also, Scikit-image relies on SciPy internals which does not abstract the underlying data type for the algorithm
implementer. As such, each algorithm must provide a switch/case dispatch for every supported type (floating points,
8-bit channel, 16-bit channel, RGB, etc.), and it must provide it in the middle of the algorithm implementation. If one
type is not natively supported; an error occurs and the program halts. Henceforth, handling a new supported data type
will requires to review every single written algorithm.

On the other hand, SciPy provides an abstraction layer over the dimensional aspect of the image by providing a tool
named point iterator. This tool allows one to iterate over every point of the image, without being aware of the number
of its dimension, and make the translation from the abstract iterator to the actual offset in the data buffer of the
image. The implementer can then only worry about handling the underlying data type to provide a generic algorithm. This
approach, sadly, is fully dynamic (that is, runtime) and does not allow the compiler to provide native optimization such
as vectorization out of the box.

\paragraph{OpenCV \& Matlab} In OpenCV as well as in Matlab, the choice was made to systematically attempt to decompose
big rectangular structuring elements into smaller $3x3$ structuring elements. This is not as effective as using
multi-pass 1D algorithm but still allows for relatively stable performances.

Also, OpenCV let the implementer handle the cases he wants to support by himself. For instance, the dilation algorithm
is written with a dispatch on the data type before the actual call to the algorithm. This enables compiler optimizations
such as vectorization because all the required information is known at the right time. It also enables offloading the
computation into GPU kernels when feasible. However, the downside is that few algorithms are written in a way to handle
multidimensional images. Most are written to only handle specific subsets. As such, conversion from one subset to
another may be unavoidable when writing an algorithm pipeline for a more complex application. For instance, it is
currently not possible to dilate a 3D image with a 3D ball (as stated above).

Another point to note with OpenCV is the requirement to do temporary copies (to extract data or to have working copy)
when writing an algorithm. For instance, it is currently not possible to write a blurring algorithm operating only on
the green channel of an RGB image. One must first extract the green channel into a single channel temporary image, blur
that image, to finally put the result back into the original image. Generally, in-place computation is poorly handled in
OpenCV.

\paragraph{Benchmark} When comparing performances of the simple dilation between Matlab and OpenCV, which is done
in~\cite{matuska.2012.bench}, shows that Matlab is very oriented toward prototyping and not toward production. The
performance gap between the two libraries shows that performances may not a major concern for MatLab in this case.
Opposite to this, OpenCV and scikit-image both have a C/C++ core to provide fast basic algorithms such as the dilation
and erosion mathematical morphology.

As such, when comparing the performances of OpenCV, Scikit-image and Pylene in~\cref{fig.gen.bench.square.disc}, we can
notice some interesting facts. Both scikit-image and Pylene have a very stable execution time even though the size of
the structuring element grows by power of two. This corroborate the fact that the author did see code taking advantage
of the structuring element's properties, such as the decomposability/separability. OpenCV has very good performances for
a square because it has specific handwritten code for both vectorization and GPU offloading when possible: even if
OpenCV decomposed its square into smaller sub square (and not periodic lines), it remains steady fast.

\begin{figure}[htb]
  \centering
  \includegraphics[width=3.8in]{figs/bench_disc_rect_by_SE}
  \caption{Benchmark: dilation of a 2D image (3128x3128 \eqmark 10Mpix) with a 2D square and a 2D disc.}
  \label{fig.gen.bench.square.disc}
\end{figure}

In the case of a structuring element shaped as a disc (also in~\cref{fig.gen.bench.square.disc}), we can observe that
the execution time raises exponentially for both Scikit-image and OpenCV whereas Pylene remains regular and steady fast.
These results show that Pylene's attempt to decompose each structuring element into periodic lines when possible may be
a little bit slower for smaller structuring elements whereas it is much more regular and faster when the structuring
element start to be of a certain size.


\section{Genericity in pre C++11}
\label{genericity.sec.language.precpp11}

Before C++11~\parencite{iso.2011.cpp} came out the genericity facilities offered by the C++ programming language were
already turing complete~\parencite{veldhuizen.2003.c++templates}. However, it was lacking a certain amount of features
the language now have that made writing generic code a real challenge at that time. For instance, when writing code with
a variable number of type (nowadays designed as variadic templates) one had to write the generic code for each and every
number of type supported. This meant that to implement \texttt{std::tuple}, one had to copy the implementation for every
number of type supported by \texttt{std::tuple}. This limitation defeated the very first principle and motivation of
generic programming which is to write \emph{less} Code. To compensate, library implementers used tricks with macro not
to have to rewrite code which made the initial code even harder to understand for outsiders.

\subsection{SFINAE: Substitution-Failure-Is-Not-An-Error}
\label{genericity.language.precpp11.sebsec.sfinae}

In spite of all those limitations at the time, generic programming was well supported by the language and allowed the
programmer to already design generic libraries, in particular thanks to the SFINAE~\parencite{vandevoorde.2002.c++}
(substitution-failure-is-not-an-error) technique that leads to the popularisation of the usage of the
\texttt{std::enable\_if} meta-programming facility. The SFINAE technique relies on a feature of the C++ programming
language. Indeed, when standardizing how the compiler should resolve and select function overloads, in a templated
context, the standard committee chose to have the following behavior. When substituting the explicitly specified or
deduced type for the template parameter fails, the specialization (function overload candidate) is discarded from the
overload set (of matching functions) instead of causing an error.

This feature allows to write code that seem to be ill-formed, for instance in a function, trying to access to a class
member type, variable or function that does not exist should be ill-formed. However, because it happens in the templated
world, when the compiler tries to compile the function code with a given type, the compiler will just discard the
function from the overload resolution at call-site instead of throwing a hard error. An error can occur only when the
compiler tried all the overload it knows and still could not find an overload that was not ill-formed. If this happen,
the compiler will then proceed to list all the overloads it tried, to list all the template substitution it tried and
finally to list why it failed. This mechanism is the very reason of the unpopularity of this technique because it leads
to situation where the compiler can output \emph{several Mos} of error message for one single file. Error messages
becomes incomprehensible very fast and programs are hard to debug. But still, it was the only technique we had to
perform detections on types at compile time and process some kind of contraints on them. For instance, a code that
detects wether a class provide a subtype named \texttt{custom\_type} at that time is shown
in~\cref{fig.gen.sfinae.nested}.

\begin{figure}[tbh]
  \centering
  \begin{minted}[]{C++}
    // Step 1: write the detector using partial specialization
    template <class TestedType, class Void = void>
    struct has_nested_sub_type {
      typedef bool type;
      static const type value = false; // default value: not detected
    };
    // This class template specialization has value set as true
    // when it detects that the nested type exists
    template <class TestedType>
    struct has_nested_sub_type<TestedType, typename TestedType::custom_type> {
      typedef bool type;
      static const type value = true;
    };

    // Step 2: declare the well- and ill-formed classes
    class well_formed {
      typedef int custom_type;
    };
    class ill_formed {
      typedef int another_type;
    };

    // Step 3: implement the enable_if facility that will use our
    // detector written at step 1
    template<bool B, class T = void>
    struct enable_if {
    };
    template<class T>
    struct enable_if<true, T> {
      typedef T type;
    };

    // Step 4: write overloads the compiler will use
    // overload #1
    template <typename UserType>
    void my_procedure(const UserType& ut) {}; // accept everything

    // overload #2
    template <typename UserType>
    void my_procedure(const UserType& ut, // accept only constrained types
    typename enable_if<has_nested_sub_type<UserType>::value>::type* = 0) {};

    int main() {
      well_formed wlf;
      ill_formed ilf;

      my_procedure(wlf); // will call overload #1
      my_procedure(ilf); // no hard error, will call opverload #2

      // A hard error would occur only if overload #1 did not exist.
    }
  \end{minted}
  \caption{C++0x SFINAE detection of nested sub-type.}
  \label{fig.gen.sfinae.nested}
\end{figure}

\subsection{CRTP: Curiously Recurring Template Pattern}
\label{genericity.language.precpp11.sebsec.crtp}

Another features that precede C++11 and was available in C++98~\parencite{iso.1998.cpp} and
C++03~\parencite{iso.2003.cpp} is the curiously recurring template pattern (CRTP). This programming technique allowed a
base class (in its specific code) to be aware of its derived class at compile type. This pattern is extremely useful to
solve issues revolving around covariant return type polymorphism in C++ with pointers. Indeed, before smart pointers
were standardized, they existed in libraries such as boost~\parencite{boost.2021} and were used to solve memory leak
issues. However, when implementing cloning facilities where lots of derived class were involved, one could not just
return a smart pointer of the base class since no derived class derived from the capsule smart pointer class itself.
This broke the covariant return type feature. CRTP is a tool that brings a solution: we were now able to construct a
smart pointer capsule of the derived class inside the base class: there are now only one function in the base class and
no ambiguities is detected by the compiler.

\begin{figure}[tbh]
  \centering
  \begin{minted}[]{C++}
    #include <string>

    class AbstractBase {
    public:
        virtual ~AbstractBase()                      = default;
        virtual AbstractBase*       clone() const    = 0; // covariant return type
        virtual const std::string&  get_name() const = 0;
    };

    class Derived : public AbstractBase {
        std::string name_;
    public:
        Derived(const std::string& name) : name_(name) {}
        Derived* clone() const /* override */ {
        return new Derived(name_);             // works thanks to covariance
        }
        const std::string& get_name() const {
        return name_;
        }
    };

    int main() {
        AbstractBase* objptr = new Derived("John");     // works
        AbstractBase* cloned_objptr = objptr->clone();  // also works
        objptr->get_name();        // "John"
        cloned_objptr->get_name(); // also "John"
        // Do not forget to delete to avoid memory leaks
        delete cloned_objptr;
        delete objptr;
    }
  \end{minted}
  \caption{C++0x cloning example with covariant return type.}
  \label{fig.gen.crtp.work}
\end{figure}

For instance, a cloning facility with no smart pointers was implemented with covariant return type in the code shown
in~\cref{fig.gen.crtp.work}. The obvious disadvantage was to have to deal with naked pointers, \texttt{new},
\texttt{delete} and all the consequences that comes with the manual memory handling. When the programmer wants to switch
to an implementation that uses smart pointers, he would naively write the code shown in~\cref{fig.gen.crtp.dontwork}.

\begin{figure}[tbh]
  \centering
  \begin{minted}[]{C++}
    #include <string>
    #include <smart_pointers>

    class AbstractBase {
    public:
      virtual ~AbstractBase()                           = default;
      virtual unique_ptr<AbstractBase> clone() const    = 0; // covariance is lost
      virtual const std::string&       get_name() const = 0;
    };

    class Derived : public AbstractBase {
      std::string name_;
    public:
      Derived(const std::string& name) : name_(name) {}
      unique_ptr<Derived> clone() const /* override */ { // No covariance
        // does not work because Derived does not derive from unique_ptr
        return unique_ptr<Derived>(new Derived(name_)); 
      }
      const std::string& get_name() const{
        return name_;
      }
    };

    int main() {
      unique_ptr<AbstractBase> objptr =
          unique_ptr<AbstractBase>(new Derived("John"));        // works
      unique_ptr<AbstractBase> cloned_objptr = objptr->clone(); // does not work
      objptr->get_name();        // "John"
      cloned_objptr->get_name(); // also "John"
      // No delete needed
    }
  \end{minted}
  \caption{C++0x not-working cloning example with smart pointers.}
  \label{fig.gen.crtp.dontwork}
\end{figure}

The solution is then found with the CRTP technique where we do all the creation inside the base class instead of forcing
the derive class to implement its own cloning facility. The code in~\cref{fig.gen.crtp.final} shows how it is done. In
order for the user not to have to write \texttt{AbstractClass<Devived>} in his code, we have adopted another abstraction
layer to hide this implementation detail in the form of a intermediary class \texttt{Base} that hides the CRTP
complexity.

\begin{figure}[tbh]
  \centering
  \begin{minted}[]{C++}
    #include <string>
    #include <smart_pointers>
    
    class AbstractBase {
    public:
        virtual ~AbstractBase()                           = default;
        virtual unique_ptr<AbstractBase> clone()    const = 0;
        virtual const std::string&       get_name() const = 0;
    };
    
    template <class Derived>
    class Base : public AbstractBase{
    public:
        virtual unique_ptr<AbstractBase> clone() const /* override */ {
            // Covariance is kept by converting here
            return unique_ptr<Derived>(new Derived(get_name()));
        }
    };
    
    class Derived : public Base<Derived> {
        std::string name_;
    public:
        Derived(const std::string& name) : name_(name) {}
        const std::string& get_name() const {
            return name_;
        }
    };
    
    int main() {
        unique_ptr<AbstractBase> objptr =
            unique_ptr<AbstractBase>(new Derived("John"));        // works
        unique_ptr<AbstractBase> cloned_objptr = objptr->clone(); // does work
        objptr->get_name();       // "John"
        cloned_objptr->get_name(); // also "John"
        // No delete needed
    }
  \end{minted}
  \caption{C++0x working cloning example with smart pointers.}
  \label{fig.gen.crtp.final}
\end{figure}

Thanks to these two techniques (SFINAE and CRTP), past work was done to achieve a design:
SCOOP~\parencite{burrus.2003.mpool,geraud.2006.scoop-pres,geraud.2008.mpool}. These design combined CRTP and SFINAE to
build a machinery where it is possible to apply constraints via concepts (in the sense described
in~\citetitle{stepanov.2009.elements} by~\citeauthor{stepanov.2009.elements}). The library
Olena~\parencite{olena.2000.www,geraud.2012.hdr} was born and carried the work around this field of research applied to
Image processing in~\parencite{geraud.2000.icpr,duretlutz.2000.olena,darbon.2002.ismm,darbon.2004.ecoopphd}. This design
is described in details by~\citeauthor{levillain.2011.phd} among his
work~\parencite{levillain.2009.ismm,levillain.2010.icip,levillain.2010.wadgmm,levillain.2011.gretsi,levillain.2011.phd,levillain.2012.wadgmm-lncs,levillain.2014.ciarp}.
Finally, with the release of new C++ standards in 2011~\parencite{iso.2011.cpp}, then 2014~\parencite{iso.2014.cpp},
2017~\parencite{iso.2017.cpp} where template metaprogramming facilities were greatly improved, it was necessary to
review once more this design to improve the design in order to achieve genericity, performance and ease of use. This is
the birth of a new library, Pylene~\parencite{carlinet.2018.pylena}. In the end, it was C++20~\parencite{iso.2011.cpp}
that marked the shift wanted by
Stepanov~\parencite{musser.1988.generic,musser.1994.algorithm,dehnert.1998.fundamentals,stepanov.2009.elements} and
Stroustrup~\parencite{stroustrup.1995.design,stroustrup.1999.hot,stroustrup.2003.concepts,stroustrup.2007.hopl} for
years with the coming of Concepts, and all the new possibilities it brings to the programmer.


\section{Genericity in post C++11 (C++20 and Concepts)}
\label{genericity.sec.language.postcpp11}

\begin{figure}[tbh]
  \centering
  \begin{minted}[linenos,xleftmargin=17pt,gobble=2,highlightlines={2,4,5}]{c++}
  template <Collection C, ValueType V>
    requires Same<Collection::ValueType, ValueType>
  void fill(C c, V v) {
    for(auto e : c)
      e = v;
  }
  \end{minted}

  \caption{Fill algorithm, generic implementation.}
  \label{fig.gen.fill}
\end{figure}

Most of the algorithms are \emph{generic} by nature. What limits their genericity is the way they are implemented. This
statement is justified by the work achieved in the Standard Template Library (STL)~\parencite{dehnert.1998.fundamentals}
in C++ whose algorithms are implemented and designed in a way where they work with all the built-in collections (linked
list, vector, etc.). Let us take the example of the algorithm \texttt{fill(Collection c, Value v)} which set the same
value for all the element of a collection (see~\cref{fig.gen.fill}). There are three main requirements here that are not
related to the underlying type of \emph{Collection}. First, we check (l.2~\ref{fig.gen.fill}) that we are actually
filling the collection with the correct type of value. Indeed, it would not make sense, for instance, to assign an RGB
triplet color into a pixel from a grayscale image. Secondly, we need to be able to iterate over all the element of the
collection (l.4~\ref{fig.gen.fill}). Finally, we need to be able to write a value into the collection
(l.5~\ref{fig.gen.fill}). This requires the collection not to be read-only, or the collection's values not to be yielded
on-the-fly. This allows us to deduce what is called a \emph{concept}: a breakdown of all the requirement about the
behavior of our collection. When writing down what a \emph{concept} should require, one should always respect this rule:
\blockquote{\emph{It is not the types that define the concepts: it is the algorithms}}. Concepts in C++ are not new and
there have been a long work to introduce them that goes back from
2003~\parencite{seymour.2009.concepts,stroustrup.2003.concepts,sutton.2017.concepts} to finally appear in the 2020
standard~\cite{voutilainen.2017.concepts} (referred as C++20~\parencite{iso.2011.cpp}). This allows us, as of today, to
write code leveraging this facility.

\subsection{Conceptification}
\label{genericity.postcpp11.subsec.conceptification}

C++ is a multi-paradigm language that enables the developer to write code that can be \emph{object oriented},
\emph{procedural}, \emph{functional} and \emph{generic}. However, there were limitations that were mostly due to the
backward compatibility constraint as well as the zero-cost abstraction principle. In particular the \emph{generic
  programming} paradigm is provided by the \emph{template metaprogramming} machinery which can be rather obscure and
error-prone. Furthermore, when the code is incorrect, due to the nature of templates (and the way they are specified) it
is extremely difficult for a compiler to provide a clear and useful error message. To solve this issue, a new facility
named \emph{concepts} was brought to the language. It enables the developer to constraint types: we say that the type
\emph{models} the \emph{concept(s)}. For instance, to compare two images, a function \emph{compare} would restrict its
input image types to the ones whose value type provides the \emph{comparison operator ==}. In spite of the history
behind the \emph{concept checking} facilities being very
turbulent~\parencite{seymour.2009.concepts,stroustrup.2003.concepts,sutton.2017.concepts}, it will finally appear in the
next standard~\cite{voutilainen.2017.concepts} (C++20).

The C++ \emph{Standard Template Library} (STL) is a collection of algorithms and data structures that allow the
developer to code with generic facilities. For instance, there is a standard way to \emph{reduce} a collection of
elements: \texttt{std:: accumulate} that is agnostic to the underlying collection type. The collection just needs to
provide a facility so that it can work. This facility is called \emph{iterator}. All STL algorithms behave this way: the
type is a template parameter so it can be anything. What is important is how this type behaves. Some collection requires
you to define a \texttt{hash} functions (\texttt{std::map}), some requires you to set an \emph{order} on your elements
(\texttt{std::set}) etc. This emphasis the power of genericity. The most important point to remember here (and explained
very early in 1988~\cite{musser.1988.generic}) is the answer to: \blockquote{\emph{What is a generic algorithm?}}. The
answer is: \blockquote{\emph{An algorithm is generic when it is expressed in the most abstract way possible}}. Later, in
his book~\cite{stepanov.2009.elements}, Stepanov explained the design decision behind those algorithms as well as an
important notion born in the early 2000s: the concepts. The most important point about concepts is that it constraints
the behavior. Henceforth: \blockquote{\emph{It is not the types that define the concepts: it is the algorithms}}. The
\emph{Image Processing} and \emph{Computer Vision} fields are facing this issue because there are a lot of algorithms, a
lot of different kind of images and a lot of different kind of requirements/properties for those algorithms to work. In
fact, when analyzing the algorithms, you can always extract those requirements in the form of one or several
\emph{concepts}.

Image processing algorithms, similarly, are \emph{generic} by
nature~\cite{ritter.1990.cvgi,geraud.2000.icpr,darbon.2002.ismm,levillain.2010.icip,levillain.2014.ciarp}. When writing
an image processing algorithm, there is always a way to express it with a high level of genericity. For instance, if is
possible to write a morphological dilation in a way that does not care about the underlying value type, the domain nor
the structuring element specificities. The most abstract way to write a dilation is shown in~\ref{fig.gen.dilate}.

\begin{figure}[tbh]
  \centering
  \begin{minted}[linenos,xleftmargin=17pt,gobble=2]{C++}
  template <Image I, WritableImage O,
              StructuringElement SE>
  void dilation(I input, O output, SE se) {
    assert(input.domain() == output.domain());
    for(auto pnt : input.points()) {
      output(p) = input(p)
      for (nx : se(p))
        output(p) = max(input(nx), output(p))
    }
  }
  \end{minted}
  \caption{Dilation algorithm, generic implementation.}
  \label{fig.gen.dilate}
\end{figure}

This implementation introduces three concepts at line 1: \emph{Image}, \emph{WritableImage} and
\emph{StructuringElement}. Following the behavior of each one of them into the algorithm, we can deduce a list of
requirements for each one of them.

\paragraph{Image} is the most basic representation of what an image should be. An image should (a) provide a way to
access its domain (l.3~\ref{fig.gen.dilate}) and (b) a way to iterate over its points (l.4~\ref{fig.gen.dilate}). This
then allows us later to (c) access to the value returned by the image at this point (l.5~\ref{fig.gen.dilate}). To this
point the value is only accessed in read-only. We can then write the following two concepts:
\begin{minted}{C++}
  template <typename I>
  concept Image = requires {
    typename I::point_range;            // needed for b
    typename I::point_type;             // needed for c
    typename I::value_type;             // needed for c
  } && ForwardRange<I::point_range>     // needed for b
  && requires (I ima, I::point_type pnt) {
    { ima.domain() };                   // a
    { ima.points() } -> I::point_range  // b
    { ima(pnt) }     -> I::value_type   // c
  };
\end{minted}
In reality, more boilerplate code is needed to ensure, for instance that there is no type mismatch between the image's
\texttt{point\_type} and the \texttt{point\_range}'s value type. For the sake of brevity this boilerplate code is
omitted here.

\paragraph{WritableImage} is a more specific concept based on the previous \emph{Image} concept. It requires that the
image's value can be (d) accessed to be modified: the user should be able to write into the image's value accessed by a
specific point (l.6~\ref{fig.gen.dilate}). We can then write the following two concepts:
\begin{minted}{C++}
  template <typename WI>
  concept WritableImage = Image<WI>
  && requires (WI wima, I::point_type pnt,
                I::value_type val) {
    { wima(pnt) = val };                // d
  };
\end{minted}

\paragraph{StructuringElement} is an additional input to the image defining the window around each point that will be
considered during the dilation (also called the neighborhood). A structuring element should just provide a list of point
when input with one (e). From this behavior we can deduce the following concept:
\begin{minted}{C++}
  template <typename SE, typename I>
  concept StructuringElement = Image<I>
  && requires (SE se,I::point_type pnt) {
    { se(pnt) } -> I::point_range;      // e
  }
\end{minted}

This new notion of concept is very important because it decorrelate the requirements on behavior required inside
algorithms from the way the data structures are designed. One wan always wrap a specific data structure so that it can
behave properly into an algorithm, without needing to rewrite that algorithm.

\subsection{Simplifying code}
\label{genericity.postcpp11.subsec.simplifying}

The main advantage brought by using modern C++ as the implementation language for an image processing library is to be
able to leverage what is called metaprogramming. Metaprogramming is a way to tell the compiler to make decision about
which type, which code to generate. These decisions, made at compile time, and then absent from the resulting binary:
only the fast and optimised code remains. This bring a new distinction between the static world (what is decided at
compile time) and the dynamic world (what is decided at runtime). The more is decided at compile time the smaller,
faster the binary will because there is work less to do at runtime. By following this principle, one can think of some
properties that are known ahead of time (at compilation) when writing one's image processing algorithm. For instance,
when considering the example of the dilation whose code is shown in~\ref{fig.decomp.dilate}, we can see that the
property about the decomposability if the structuring element is linked to the type. This means that when the
structuring element's type is of a disc, or a square, the compiler will know at compile time that it is decomposable. To
tell the compiler to take advantage of a property at compile time, C++ has a language construct named if-constexpr. The
resulting code then becomes:

\begin{minted}[highlightlines=3]{c++}
  template <Image Img, StructuringElement SE>
  auto dilate(Img img, SE se) {
    if constexpr (se.is_decomposable()) {
      lst_small_se = se.decompose();
      for (auto small_se : lst_small_se)
        img = dilate(img, small_se) // Recursive call
      return img;
    } else if (is_pediodic_line(se))
      return fast_dilate1d(img, se) // Van Herk's algorithm;
    else
      return dilate_normal(img, se) // Classic algorithm;
  }
\end{minted}

There are other ways to achieve the same result with different language constructs in C++. There are two "legacy"
language constructs which are tag dispatching (or overload) and SFINAE. With the release of C++17 came a new language
construct presented above: if-constexpr. Finally, with C++20, it will be possible to use concepts to achieve the same
result. To achieve the same result as above with tag dispatching, one would need to write the following code:

\begin{minted}[highlightlines={1-2,7,14}]{c++}
  struct SE_decomp {};
  struct SE_no_decomp {};

  template <Image Img, StructuringElement SE>
  auto dilate(Img img, SE se) {
    // either SE_decompo or SE_no_decomp
    return dilate_(img, se, typename SE::decomposable());
  }

  auto dilate_(Img img, SE se, SE_decomp) {
    lst_small_se = se.decompose();
    for (auto small_se : lst_small_se)
      // Recursive call
      img = dilate(img, small_se, SE_no_decomp)
    return img;
  }
  auto dilate_(Img img, SE se, SE_no_decomp) {
    if (is_pediodic_line(se))
      return fast_dilate1d(img, se) // Van Herk's algorithm;
    else
      return dilate_normal(img, se) // Classic algorithm;
  }
\end{minted}

To achieve the same result with SFINAE, one would need to write the following code:

\begin{minted}[highlightlines={5-6,14,23}]{c++}
  // SFINAE helper
  template <typename SE, typename = void>
  struct is_decomposable : std::false_type {};
  template <typename SE>
  struct is_decomposable<SE,
    // Check wether the type provides the decompose() method
    std::void_t<decltype(std::declval<SE>().decompose())>
  > : std::true_type {};
  template <typename SE>
  constexpr bool is_decomposable_v =
                  is_decomposable<SE>::value;

  template <Image Img, StructuringElement SE,
    typename = std::enable_if_t<is_decomposable_v<SE>>>
  auto dilate(Img img, SE se) {
    lst_small_se = se.decompose();
    for (auto small_se : lst_small_se)
      img = dilate(img, small_se) // Recursive call
    return img;
  }

  template <Image Img, StructuringElement SE,
    typename = std::enable_if_t<not is_decomposable_v<SE>>>
  auto dilate(Img img, SE se) {
    if (is_pediodic_line(se))
      return fast_dilate1d(img, se) // Van Herk's algorithm;
    else
      return dilate_normal(img, se) // Classic algorithm;
  }
\end{minted}

Comparing those two last ways of writing static code to the first one comes to an obvious conclusion: the if-constexpr
facility is much more readable and maintainable than the two legacy ways of doing it. Finally, there is still another
way to handle the issue and it is with C++20's concepts. The following code demonstrates how to leverage this language
construct:

\begin{minted}[highlightlines={1-4,15}]{c++}
  template <typename SE>
  concept SE_decomposable = requires (SE se) {
    se.decompose(); // this method must exist
  };

  template <typename Img, typename SE>
  auto dilate(Img img, SE se) {
   if (is_pediodic_line(se))
      return fast_dilate1d(img, se) // Van Herk's algorithm;
    else
      return dilate_normal(img, se) // Classic algorithm;
  }

  template <typename Img, typename SE>
    requires SE_decomposable<SE>
  auto dilate(Img img, SE se) {
    lst_small_se = se.decompose();
    for (auto small_se : lst_small_se)
      img = dilate(img, small_se) // Recursive call
    return img;
  }
\end{minted}
A best-match mechanic operates under the hood to select the function overload whose concept is the most specialized when
possible.

\subsection{Benchmarks}
\label{genericity.postcpp11.subsec.benchmarks}

\FIXME{TODO: clean figures (titres, gradution, 2 par 2, lables \& axes)}

In order to get a real feeling on how fast would the compile time of programs would be impacted, we wanted to do
benchmarks. The aim is to mesure how much faster concepts will be in production code. To do so we used
Metabench~\parencite{dionne.2021.metabench}, a benchmarking facility to benchmark compilation time of C++ programs. We
wrote programs (given in~\cref{appendix.benchmark_compilation_time}) to benchmark compilation time with three compilers
Gcc-10, Clang-10 and Clang-11.

For Gcc-10, we can see the results in~\cref{fig.gen.bench.gcc10.1.concept.sfinae}. Those results show that the concept
implementation is still very much slower than the SFINAE implementation. However, we were able to pinpoint the slowness
of this implementation which is the implementation of the library trait \texttt{std::movable}. Indeed, when lightening
this trait into some builtin intrinsic (that are almost equivalent), we can see the curve \emph{concept\_fast}
in~\cref{fig.gen.bench.gcc10.2.concept.sfinae} being faster than the SFINAE implementation.

\begin{figure}[htb]
  \centering
  \includegraphics[width=4.2in]{figs/compile_time_benches/gcc10/chart.concept.png}
  \caption{Benchmark GCC-10: Benchmarking compilation speed of template instanciation constrained by Concepts (vanilla) vs. Concepts (improved) vs. SFINAE.}
  \label{fig.gen.bench.gcc10.1.concept.sfinae}
\end{figure}

\begin{figure}[htb]
  \centering
  \includegraphics[width=4.2in]{figs/compile_time_benches/gcc10/chart.concept2.png}
  \caption{Benchmark GCC-10: Benchmarking compilation speed of template instanciation constrained by Concepts vs. SFINAE.}
  \label{fig.gen.bench.gcc10.2.concept.sfinae}
\end{figure}

For Clang-10, the concept implementation is globally slower than the SFINAE implementation (seen
in~\cref{fig.gen.bench.clang10.1.concept.sfinae}). Even not using the slow \texttt{std::movable} library trait does not
do the trick as seen in~\cref{fig.gen.bench.clang10.2.concept.sfinae}

\begin{figure}[htb]
  \centering
  \includegraphics[width=4.2in]{figs/compile_time_benches/clang10/chart.concept.png}
  \caption{Benchmark Clang-10: Benchmarking compilation speed of template instanciation constrained by Concepts (vanilla) vs. Concepts (improved) vs. SFINAE.}
  \label{fig.gen.bench.clang10.1.concept.sfinae}
\end{figure}

\begin{figure}[htb]
  \centering
  \includegraphics[width=4.2in]{figs/compile_time_benches/clang10/chart.concept2.png}
  \caption{Benchmark Clang-10: Benchmarking compilation speed of template instanciation constrained by Concepts vs. SFINAE.}
  \label{fig.gen.bench.clang10.2.concept.sfinae}
\end{figure}

Finally, for Clang-11, we can see that the builtin implementation of concepts has improved very much from its previous
version (see~\cref{fig.gen.bench.clang11.1.concept.sfinae}). However, we see that the library trait
\texttt{std::movable} is still the source of a massive slowness (see~\cref{fig.gen.bench.clang11.2.concept.sfinae}) that
needs to be addressed in future versions of both Gcc and Clang.

\begin{figure}[htb]
  \centering
  \includegraphics[width=4.2in]{figs/compile_time_benches/clang11/chart.concept.png}
  \caption{Benchmark Clang-11: Benchmarking compilation speed of template instanciation constrained by Concepts (vanilla) vs. Concepts (improved) vs. SFINAE.}
  \label{fig.gen.bench.clang11.1.concept.sfinae}
\end{figure}

\begin{figure}[htb]
  \centering
  \includegraphics[width=4.2in]{figs/compile_time_benches/clang11/chart.concept2.png}
  \caption{Benchmark Clang-11: Benchmarking compilation speed of template instanciation constrained by Concepts vs. SFINAE.}
  \label{fig.gen.bench.clang11.2.concept.sfinae}
\end{figure}


\section{C++ templates in a dynamic world}
\label{genericity.sec.template.dynworld}

There are two main categories of programming languages. First are the \emph{compiled} programming languages which
requires to feed the source code to a program (a compiler) that will output a binary. This binary will then produce the
desired output once the user execute it. Some well known languages of this category are C, C++, Ada, Fortran. Secondly
there are the interpreted programming language which requires to feed the source code to a program (an interpreter) that
will directly produce the output as is a binary was executed. Some well known languages of this category are Javascript,
Python, Matlab, Common Lisp. There is a third category that tries to combine the best of both world by compiling into
bytecode which is an optimized intermediate language that will then be interpreted into a virtual machine. The most
famous are indubitably Java and C\#. Both categories have advantages as well as drawbacks.

\paragraph{Compiled languages} are still widely spread and used as of today. They present a working pipeline which is
very classic. First the programmer will write code, then the compiler will build a binary optimized for the target
machine and finally the programmer can execute his binary to produce a result. Usually the compilation step is slow
whereas executing the binary is fast. There is no additional step when it comes to the binary execution. This, however,
has the effect of having a poor portability. Indeed, my binary optimized to use fast and recent SIMD AVX-512
instructions will not work on an old x86 machine that does not support those instructions. When distributing our
program, multiple binaries must be produced for each supported CPU architectures. Furthermore, usually compiled
languages have very poor support of dynamic language features such as reflection, code evaluation or dynamic typing. It
tends to improve with time but solutions are limited to compile-time informations or need to ship a JIT-compiler into
the final binary (such as cling~\parencite{vassilev.2012.cling} for C++) to generate new binary on-the-fly to be
executed right after. This has two drawbacks: slowness when the case of needing compilation is presented and increase in
the binary size.

\paragraph{Interpreted languages} are also widely used, especially in the research area where a fast feedback loop
between prototyping and getting results is needed. The compilation time is very fast and allows a program to be almost
instantly executed. In fact, the compilation can be done just ahead of program execution not to compile unnecessary
code. However the execution time will generally be slow. To the user it is invisible because both compilation step and
execution step are blurred together. Furthermore, most of the time a same interpreted program is executed once. Then the
programmer will modify it and continue its prototyping process. The real advantage of an interpreted language is the
portability. As it is the responsibility of the client to install the correct language interpreter (for the correct
version) before running the program from the source code, as long as an interpreter can be installed on a machine, the
program can then be run. This also drastically slow distributed package for programs as only source code must be
distributed instead of compiled binary. However, the source code is leaked with all the security implication this can
have. Finally, interpreted language usually have better memory management (builtin garbage collectors), are easier to
debug, have very rich support of dynamic typing, dynamic scoping, reflections facilities, on-the-fly evaluation from the
source code or even more like modifying the Abstract Syntax Tree (AST) resulting from the first compilation pass on
source code by the interpreter. This last one is implemented in Common Lisp in the name of macros. There are more to say
about interpreted languages, especially about those that are compiled into bytecode and tend to get the best of both
worlds without the drawbacks but this thesis will not discuss this matter any further.

The main point to understand here is that our main interest is set on C++, a compiled language with slow compilation
time and very fast execution time. In C++ there are template metaprogramming to achieve genericity but \emph{templates
  do not generate any binary code}. Why? Because when the compiler meet a templated type or a templated routine, it does
not know which type it will be instantiated with when it is used. Therefore, it can not calculate stuff like type size,
alignement, can not select which assembly instruction to select to do an addition or a division (fixed vs. floating
point arithmetic). This is why the compiler does not generate any binary code when it first meet templates. The code is
generated only it is used with a concrete and known type. This is a huge problem. Now, if a library implementer wants to
distribute his generic library, he must distribute source code and have  the user compile it. For a language like C++,
with no standard dependency management, it can be a massive turn off. Furthermore, it may not be reasonable for the user
to have C++ compiling facilities when the target client is embedded devices with limited storage space. Indeed, C++
intermediary compilation artefacts tend to use a lot of disk space before it is linked into a smaller binary. What
solution do we have then?

\paragraph{SWILENA~\parencite{beazley.1996.swig,olena.2000.www}} is a Python bindings wrapper using Swig for the Olena
C++ generic library. This wrapper will enumerate all the common use cases and implement a binding for them. The compiler
will then generate binary code from the templated generic code for each use case enumerated in the wrapper. This way, we
have given access into the dynamic world (Python) to generic code (C++ template). But it is still limited to the
supported types. Each type a new combinaison of type needs to be supported from Python, it needs to be explicitly
declared and compiled in the wrapper. Other image processing libraries, such as VIGRA~\parencite{kothe.2011.generic},
chose this solution.

\paragraph{VCSN~\parencite{demaille.2013.vcsn}} is a novel solution that essentially take the same base as SWILENA but
goes beyond the boundary to implement a handmade facility that do system compiler calls to compile and link needed code
on-the-fly when the binding does not exist. It then leverage the code hotloading feature to plug new dynamic libraries
(.dll on windows and .so on linux) into the wrapper to provide the user its needed bindings.

\paragraph{Cython~\parencite{behnel.2010.cython}} attempt to solve the issue of the Python inherent language slowness
due to its interpreted nature by providing a facility able to transpile a Python program into a C program so that a
genuine C compiler (with extensions) is able to compile it and to link it against the Python/C API in order to achieve a
huge performance gain at the cost of near zero knowledge of the complex Python/C API for the user. This novel solution
essentialy bypass the work of a JIT compiler (that would be used by a programming using bytecode such as Java or C\#)
and just offload it onto well known/proven solution: the machine's C compiler.

\paragraph{Autowig~\parencite{fernique.2018.autowig}, Cppyy~\parencite{wimtlplavrijsen.2016.cppyy} and
  Xeus-cling~\parencite{quantstack.2021.xeus-cling}} are all solutions aiming to generate automaticaly Python bindings
on-the-fly using different solutions. Autowig has in-house code based on LLVM/Clang to parse C++ code in order to
generate and compile a Swig Python binding using the Mako templating engine. Cppyy will generate Python bindings but can
also directly interpret C++ code from Python code thanks to being base on LLVM/Cling, a Clang-base C++ interpreter.
Finally, Xeus-cling is a Jupyter~\parencite{kluyver.2016.jupyter} kernel allowing to directly interpret C++ into a
Jupyter notebook. Like Cppyy, it is based on LLVM/Cling. Those three projects are very promising and improve greatly the
scope of possibilities for the future.
