\chapter*{Introduction}
\label{introduction.chap.introduction}

\lettrine[lines=2]{N}{owadays} \emph{Computer Vision} and \emph{Image Processing (IP)} are omnipresent in the day to day
life of the people. It is present each time we pass by a CCTV camera, each time we go to the hospital do an MRI, each
time we drive our car and pass in front of a speed camera and each time we use our computer, smartphone or tablet. We
just cannot avoid it anymore. The systems using this technology are sometimes simple and, sometimes, more complex. Also
the usage made of this technology has several different purposes: space observation, medical, quality of life
improvement, surveillance, control, autonomous system, etc. Henceforth, Image processing has a wide range of research
and despite having a mass of previous of work already contributed to, there are still a lot to explore.

Let us take the example of a modern smartphone application which provides facial recognition in order to recognize
people whom are featuring inside a photo. To provide accurate result, this application will have to do a lot of
different processing. Indeed, there are a lot of elements to handle. We can list (non exhaustively) the weather, the
light exposition, the resolution, the orientation, the number of person, the localization of the person, the distinction
between humans and objects/animals, etc. All of these is in order to finally recognizing the person(s) inside the photo.
What the application does not tell you is the complexity of the image processing pipeline behind the scene that can not
even be executed in its entirety on one's device (smartphone, tablet, \ldots). Indeed, image processing is costly in
computing ressources and would not meet the time requirement desired by the user if the entire pipeline was executed on
the device. Furthermore, for the final part which is "recognize the person on the photo", one needs to feed the
pre-processed photo to a neural network trained beforehand through deep learning techniques in order to give an accurate
response. There exists technologies able to embed neural network into mobile phone such as
MobileNets~\parencite{howard.2017.mobilenets} but it is still limited. It can detect a human being inside a photo but
not give the answer about who this human being is for instance. That is why, accurate neural network system usually are
abstracted away in cloud technologies making them available only via Internet. When uploading his image, the user does
not imagine the amount of technologies and computing power that will be used to find who is on the photo.

We now understand that in order to build applications that interact with photos or videos nowadays, we need to be able
to do accurate, fast and scalable image processing on a multitude of devices (smartphone, tablet, \ldots). In order to
achieve this goal, image processing practitioners needs to have two kinds of tools at their disposal. One will be the
prototyping environnement, a toolbox which allow the practitioner to develop, test and improve its application logic.
The other is the production environnement which deploy the viable version of the application that was developed by the
practitioner. Both environment may not have the same needs. On one hand, the prototyping environment usually requires to
have a fast feedback loop for testing, an availability of state-of-the-art algorithms and existing software. This way
the practitioner can easily build upon them and be fast enough in order not to keep waiting for results when testing
many prototypes. On the other hand, the production environment must be stable, resilient, fast and scalable.

When looking at standards in the industry nowadays, we notice that Python is the main choice for prototyping. Also,
Python may not be enough so that a viable prototype can be pushed in production with minimal changes afterwards. We find
it non-ideal that the practitioner cannot take advantages of many optimisation opportunities, both in term of algorithm
efficiency and better hardware usage, when proceeding this way. It would be much more efficient to have basic low level
building blocks that can be adapted to fit as mush use cases as possible. This way, the practitioner can easily build
upon them when designing its application. We distinguishes two kind of use cases. The first one is about the
multiplicity of types or algorithms the practitioner is facing. The second one is about the diversity of hardware the
practitioner may want to run his program. The goal is to have building blocks that can be intelligent enough to take
advantage of many optimization opportunities, with regard to both input data types/algorithms and target hardware. Then
the practitioner would have a huge performance improvement, by default, without specifically tweaking its application.
As such, the concept of genericity was introduced. It aims at providing a common ground about how an image should behave
when passed to basic algorithms needed for complex applications. This way, in theory, one only needs to write the
algorithm once for it to work with any given kind of image.

Finally, \FIXME{(find the quote)} it is often known that there is a rule of three about genericity, efficiency and ease
of use. The rule states that one can only have two of those items by sacrificing the third one. If one wants to be
generic and efficient, then the naive solution will be very complex to use with lot of parameters. If one wants a
solution to be generic and easy to use, then it will be not very efficient by default. If one wants a solution to be
easy to use and efficient then it will not be very generic. Through continuing work onto the image processing library
Pylene~\cite{carlinet.2018.pylena}, we demonstrate how a library can be generic, efficient and easy to use all at the
same time. This thesis leverages the modern C++ language and its many new features related to genericity and performance
to break this rule in the image processing area. This thesis finally attempts, through a static/dynamic bridge, to bring
low level tools and concepts from the static world to the high level and dynamic prototyping world for a better ease of
use.

With this philosophy in mind, this manuscript aims at presenting our thesis work related to the C++ language applied to
the Image Processing domain. It is organized as followed:

\paragraph{Motivation and Context~\ref{part.context_and_motivations}} presents in-depth specificities about what are the
needs of Image processing. It then explains who are the different kind of users we find in this area and how this work
may be of interest to them. We then present the previous work on this subject and what the continuation aims to be.

\paragraph{Genericity~\ref{part.genericity}} presents a state-of-the-art overview about the notion of genericity. We
explain its origin, how it has evolved (especially within the C++ language), what issues it is solving, what issues it
is creating. Finally we tour around existing facilities that allows genericity (intrinsically restricted to compiled
language) to exists in the dynamic world (with interpreted languages such as Python).

\paragraph{Images and Algorithms taxonomy~\ref{part.image_and_algorithms_taxonomy}} presents our first contribution
which is a comprehensive work in the image processing area around the taxonomy of different images families as well of
different algorithms families. This part explains, among others, the notion of concept and how it applies to the
image processing domain.

\paragraph{Images Views~\ref{part.image_views}} presents our second contribution which is a generalization of the
concept of View (from the C++ language) to images. This allows the creation of lightweight, cheap-to-copy images. It
also enable a much simpler way to design image processing pipeline by chaining operations directly in the code in an
intuitive way.

\paragraph{Static dynamic bridge~\ref{part.static_dynamic_bridge}} presents our third contribution which is a way to
grant access to the generic facilities of a compiled language (such as C++) to a dynamic language (such as Python) to
ease the gap between the prototyping phase and the production phase. Indeed, why not enable the practitioner to have
access to production-ready fast algorithm by default? In this part, we discuss some ways of achieving this and offer our
take in the shape of an hybrid solution.
