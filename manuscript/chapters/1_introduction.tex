\chapter*{Introduction}
\label{introduction.chap.introduction}

\lettrine[lines=2]{N}{owadays} \emph{Computer Vision} and \emph{Image Processing (IP)} are omnipresent in the day to day
life of the people. It is present each time we pass by a CCTV camera, each time we go to the hospital do an MRI, each
time we drive our car and pass in front of a speed camera and each time we use our computer, smartphone or tablet. We
just cannot avoid it anymore. The systems using this technology are sometimes simple and, sometimes, more complex. Also
the usage made of this technology has several different purposes: space observation, medical, quality of life
improvement, surveillance, control, autonomous system, etc. Henceforth, Image processing has a wide range of research
and despite having a mass of previous of work already contributed to, there are still a lot to explore.

Let us take the example of a modern smartphone application which provides facial recognition in order to recognize
people whom are featuring inside a photo. To provide accurate result, this application will have to do a lot of
different processing. Indeed, there are a lot of elements to handle. We can list (non exhaustively) the weather, the
light exposition, the resolution, the orientation, the number of person, the localization of the person, the distinction
between humans and objects/animals, etc. All of these is in order to finally recognizing the person(s) inside the photo.
What the application does not tell you is the complexity of the image processing pipeline behind the scene that can not
even be executed in its entirety on one's device (smartphone, tablet, \ldots). Indeed, image processing is costly in
computing ressources and would not meet the time requirement desired by the user if the entire pipeline was executed on
the device. Furthermore, for the final part which is "recognize the person on the photo", one needs to feed the
pre-processed photo to a neural network trained beforehand through deep learning techniques in order to give an accurate
response. There exists technologies able to embed neural network into mobile phone such as
MobileNets~\parencite{howard.2017.mobilenets} but it is still limited. It can detect a human being inside a photo but
not give the answer about who this human being is for instance. That is why, accurate neural network system usually are
abstracted away in cloud technologies making them available only via Internet. When uploading his image, the user does
not imagine the amount of technologies and computing power that will be used to find who is on the photo.

We now understand that in order to build applications that interact with photos or videos nowadays, we need to be able
to do accurate, fast and scalable image processing on a multitude of devices (smartphone, tablet, \ldots). In order to
achieve this goal, image processing practitioners needs to have two kinds of tools at their disposal. One will be the
prototyping environnement, a toolbox which allow the practitioner to develop, test and improve its application logic.
The other is the production environnement which deploy the viable version of the application that was developed by the
practitioner. Both environment may not have the same needs. On one hand, the prototyping environment usually requires to
have a fast feedback loop for testing, an availability of state-of-the-art algorithms and existing software. This way
the practitioner can easily build upon them and be fast enough in order not to keep waiting for results when testing
many prototypes. On the other hand, the production environment must be stable, resilient, fast and scalable.

When looking at standards in the industry nowadays, we notice that Python is the main choice for prototyping. Also,
Python may not be enough so that a viable prototype can be pushed in production with minimal changes afterwards. We find
it non-ideal that the practitioner cannot take advantages of many optimisation opportunities, both in term of algorithm
efficiency and better hardware usage, when proceeding this way. It would be much more efficient to have basic low level
building blocks that can be adapted to fit as mush use cases as possible. This way, the practitioner can easily build
upon them when designing its application. We distinguishes two kind of use cases. The first one is about the
multiplicity of types or algorithms the practitioner is facing. The second one is about the diversity of hardware the
practitioner may want to run his program. The goal is to have building blocks that can be intelligent enough to take
advantage of many optimization opportunities, with regard to both input data types/algorithms and target hardware. Then
the practitioner would have a huge performance improvement, by default, without specifically tweaking its application.
As such, the concept of genericity was introduced. It aims at providing a common ground about how an image should behave
when passed to basic algorithms needed for complex applications. This way, in theory, one only needs to write the
algorithm once for it to work with any given kind of image.

Finally, \FIXME{(find the quote)} it is often known that there is a rule of three about genericity, efficiency and ease
of use. The rule states that one can only have two of those items by sacrificing the third one. If one wants to be
generic and efficient, then the naive solution will be very complex to use with lot of parameters. If one wants a
solution to be generic and easy to use, then it will be not very efficient by default. If one wants a solution to be
easy to use and efficient then it will not be very generic. Through continuing work onto the image processing library
Pylene~\cite{carlinet.2018.pylena}, we demonstrate how a library can be generic, efficient and easy to use all at the
same time. This thesis leverages the modern C++ language and its many new features related to genericity and performance
to break this rule in the image processing area. This thesis finally attempts, through a static/dynamic bridge, to bring
low level tools and concepts from the static world to the high level and dynamic prototyping world for a better ease of
use.

With this philosophy in mind, this manuscript aims at presenting our thesis work related to the C++ language applied to
the Image Processing domain. It is organized as followed:

\paragraph{Genericity~\ref{part.genericity}} presents a state-of-the-art overview about the notion of genericity. We
explain its origin, how it has evolved (especially within the C++ language), what issues it is solving, what issues it
is creating. Finally we tour around existing facilities that allows genericity (intrinsically restricted to compiled
language) to exists in the dynamic world (with interpreted languages such as Python).

\paragraph{Images and Algorithms taxonomy~\ref{part.image_and_algorithms_taxonomy}} presents our first contribution
which is a comprehensive work in the image processing area around the taxonomy of different images families as well of
different algorithms families. This part explains, among others, the notion of concept and how it applies to the
image processing domain.

\paragraph{Images Views~\ref{part.image_views}} presents our second contribution which is a generalization of the
concept of View (from the C++ language) to images. This allows the creation of lightweight, cheap-to-copy images. It
also enable a much simpler way to design image processing pipeline by chaining operations directly in the code in an
intuitive way.

\paragraph{Static dynamic bridge~\ref{part.static_dynamic_bridge}} presents our third contribution which is a way to
grant access to the generic facilities of a compiled language (such as C++) to a dynamic language (such as Python) to
ease the gap between the prototyping phase and the production phase. Indeed, why not enable the practitioner to have
access to production-ready fast algorithm by default? In this part, we discuss some ways of achieving this and offer our
take in the shape of an hybrid solution.


context
outline
diversity of image types and algorithms, and surrounding data
diversity of users
diversity of use cases
diversity of tools
Définitions du périmètre de la bibliothèque et de ses objectifs:
\begin{itemize}
  \item Performance
  \item Facile d'utilisation (UX client)
  \item Facile de développement (Core developer xp)
  \item Versatilité des types d'images
  \item Utilisable depuis Python, Orientée MM
\end{itemize}
topic of thesis



--------------

Image processing nowadays is very diverse and cover a wide variety of purpose. Henceforth there are many tools for many
different usages, from prototyping to production or from 2D image to graph \& complex images. All the complex image
processing applications relies on the same building blocks that are used and reused to get the wanted applicative
result. Following this assessment, it makes a lot of sense to provide a user-friendly toolbox of basic building blocks
that can be used to solve as many problem as possible, and with greet efficiency so that it does not need to be fully
rewritten when switching from prototyping to production. This paper discusses how we can achieve this goal with
genericity and how modern C++ (standard 2020) allows the implementation of generic, simple and efficient algorithms.
This paper later discusses the algorithm composability into pipeline (widely used in image processing) and how modern
C++, with views, provide the tools to naturally achieve this goal, being efficient by default. Furthermore, the methods
discussed in this paper are not specific to image processing and can be reapplied to other scientific library aiming at
solving different kind of problems.

Image processing has evolved over time to become a field where a very wide array of problematic has arisen. The time
when the 2-dimensional images whose colors were encoded within three 8-bits RGB channels, was a complex construct is
long gone. Instead, and in the last 20 years, there are many new kind of image being brought by the need in new
application domains, be they: medical (3D images from MRI), video games (real time 3D rendering, meshes, visual
effects), astronomy (hyperspectral images with thousands of bands), trees (tree of shapes), graphs (for segmentation,
maps), and so on.

However, despite those kinds of images may originates from different technology domains, they still are being processed
through common, more simple algorithms (such as mathematical morphology) which are the basis of more complex
computations. Thus, it makes sense to have a common base of algorithms to build upon, later, for more complex field
specific applications.

As such, the concept of genericity was introduced. It aims at providing a common ground about how an image should behave
when passed to basic algorithms needed for complex applications. This way, in theory, one only needs to write the
algorithm once for it to work with any given kind of image. In practice, it is also possible to provide a specific
version of a specific algorithm taking advantage of specific properties when available, to for instance, increase
execution speed or decrease memory consumption.

Another aspect that Image processing is in a dire need nowadays is efficiency. Be it with Artificial Intelligence that
needs deep learning on large data set of images or simply the images themselves that are very larges (e.g. 3D mesh with
over 5 million triangles, several hundred of Go for a satellite image), efficiency is pivotal and mandatory. However
genericity and efficiency are often conflicting. Coming up with a solution allying those two aspects is a long time
ongoing work, which is still of topicality nowadays.



\section{The practitioner}

When first approaching the image processing area, one becomes what we call a practitioner. A practitioner is the end
user of image processing libraries. Its skills mainly revolve around applied mathematics for image processing,
prototyping and algorithms. A practitioner aims at leveraging the features the libraries can offer to build his
application. For instance, a practitioner can be a researcher in medical imaging, an engineer build a facial recognition
application, a data scientist labeling its image set, etc. The needs of practitioner are mainly revolving around a fast
feedback loop. The developing environment must be easily accessible and installable. This way a practitioner can judge
quickly wether one library will answer his needs. The documentation of the library must be exhaustive and didactic with
examples. When prototyping, the library must provide fast feedback loops, as in a python notebook for instance. Finally
it must be easily integrated in a standard ecosystem such as being able to work with NumPy's array natively without
imposing its own types. To sum up, practitioner's programmatic skills do not need to be high as his main goal is to
focus on algorithms and mathematics formulas.


\section{The contributer}

A contributer is an advanced user of a library who is very comfortable with its inner working, philosophy, aims,
strengths and potential shortcomings. As such, he is able to add new specific features to library, fix some shortcomings
or bugs. Usually a contributer is able to add a feature needed for a practitioner to finish his application. Furthermore
he can then contribute back his features to the main project via pull requests if it is relevant. This way, a maintainer
will assess the pull request and review it. The two main points of a contributer are his deep knowledge of a library and
his ability to write code in the same language as the source code of it. Also, a contributer must have knowledge of
coding best practices such as writing unit tests which are mandatory when adding a feature to an existing library. To
facilitate contribution, a library must provide clear guidelines about the way to contribute, be easy to bootstrap and
compile without having heavy requirements on dependencies. The best case would be that the library is handled by
standard packages managers such as system apt or python conan.

\section{The maintainer}

The maintainer is usually the creator, founder of the library or someone that took over the project when the founder
stepped back. Also, when a library grows, it is not rare that regular contributers end up being maintainer as well to
help the project. The maintainer is in charge of keeping alive the project by fulfilling several aspects: upgrade and
release new features according to the user (practitioner) needs and the library philosophy. Also, a library may not
evolve as fast as the user may want it because of lack of time from maintainers. A lot of open source projects are
maintained by volunteers and lack of time is usually the main aspect slowing development progress. The maintainer is
also in charge of reviewing all the contributers pull requests. He must check if they are relevant and completed enough,
(for instance, presence of tests and documentation) to be integrated in the project. Indeed, merging a pull requests
equals to accepting to take care of this code in the future too. It means that further upgrade, bug fix, refactoring of
the project will consider this new code too. If the maintainer is not able to take care of this code then it should
propably not be integrated in the project in the first place. Any project and library has its maintainers. A maintainer
is someone very familiar with the inner working and architectural of the project. He is also someone that has some
history in the project to understand why some decisions has been made, what choices has been made at some points and
what the philosophy of the project is. It is important to be able to refuse a contribution that would go contrary to the
philosophy of the project, even a very interesting one. Finally the profile of a maintainer is one of a developer that
is used to the standard workflow in open source based on: forks, branches, merge/pull requests and continuous
integration.