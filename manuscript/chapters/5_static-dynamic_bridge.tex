\chapter{Static dynamic bridge}
\label{chap.static_dynamic_bridge}

%\section{Coexistence between the static world and the dynamic world}
%introduction

In the programming world, there are two main families of programming language. There are the \emph{compiled}
programming, such as C, C++, Rust or Go. There are also the \emph{interpreted} programming languages, such as Python,
PHP, Lisp or Javascript. Finally, there are languages such as Java that are both at the same time.

The \emph{compiled} programming languages have the advantage of being very end-user friendly. Indeed, the implementer
distribute compiled self-sufficient binaries and the user select the binary that is compatible with his operating
system. Then, the program is supposed to work out of the box without more work than that, as illustrated
in~\cref{fig:static.dynamic.compiled.runtime}.

\begin{figure}[tbh]
  \centering
  \includegraphics[width=.6\linewidth]{figs/static_runtime}
  \caption{Compiled languages: run-time}
  \label{fig:static.dynamic.compiled.runtime}
\end{figure}

Opposite to this apparent simplicity for the end-user, all the burden is shouldered by the programmer. Indeed, to
generate a binary, there are many steps, as illustrated in~\cref{fig:static.dynamic.compiled.compiletime}. There is a
first pass with the compiler to generate intermediate machine code. Then there is a linker pass to resolve any
dependency between machine code and system code into one or multiple final distributable binaries. However, this last
pass tie the binary with a distribution. Indeed, the location of system libraries may vary between operating system,
between version of the same operating system, between compiler variants etc. Also, as the developer wants to distribute
efficient programs, he will use last optimized vectorized instructions if possible, which can tie further the binary to
a certain set of hardware supporting some assembly instructions (SSE4, XOP, FMA4, AVX-512, etc.). Upstream from those
issues, there are also issues with code. Indeed, many libraries are not cross-platform and leveraging all the
equivalences from one OS to another incurs an increase in code quantity, tests and maintenance cost to support many
platforms. For instance, the native GUI Windows libraries does not exist in Linux and must be rewritten with another
framework, such as GTK or Qt. Or else, the developer can choose to use a cross-platform GUI library from start however
this decision may not have been viable if the software was first windows-only and the cross-platform support was added
at a later date. Another caveat is that using code introspection is often very difficult at compile-time because only
few information are available (only static information). Dynamic reflection at runtime is impossible.

\begin{figure}[tbh]
  \centering
  \includegraphics[width=.6\linewidth]{figs/static_compiletime}
  \caption{Compiled languages: compile-time}
  \label{fig:static.dynamic.compiled.compiletime}
\end{figure}

The \emph{interpreted} programming language are a little less end-user friendly but are much more comfortable for
developer to distribute their software. Indeed, as shown in~\cref{fig:static.dynamic.dynamic.pipeline}, everything
happens at runtime. The maintainer only distribute the source code, the dependency list and the assets necessaries for
his program. The burden is mostly shouldered by the end-user this time. He must download and install all the language
interpreter and environment in order to execute the program from the source code. He must resolve the dependencies and
be able to execute the source code on his computer. This has the advantage of having a very rich ecosystem as
distributing, maintaining and using programs is very easy once integrated in a package manager (often delivered with the
language SDK natively). However, the main disadvantage is the performance. As the source code is not compiled into
optimized assembly code ready to be executed, the interpreter must do all the work in one go and very often this is
slow. Nowadays, all the interpreter embarks a Just-In-Time (JIT) compiler that detected the portions of a program that
are used heavily (a.k.a. hot code) and will compile them into native machine code to increase the performance
drastically without having the user pay for a long compilation time. Also, those languages usually have very developed
introspection facilities. Dynamic reflection at runtime is possible and some language, such as Common Lisp, even go
further by allowing the developer to mutate the program Abstract Syntax Tree (AST) at runtime (macro). This allows very
powerful integrations such as defining one's own DSL as if it was part of the core language itself.

\begin{figure}[tbh]
  \centering
  \includegraphics[width=.6\linewidth]{figs/dynamic_pipeline}
  \caption{Compiled languages: compile-time}
  \label{fig:static.dynamic.dynamic.pipeline}
\end{figure}

Image processing communities like to have bridges with interpretable language such as Python or Matlab, to interface
with their favorite tools, algorithms and/or facilities. As an example, with Python, the module
NumPy~\cite{oliphant.2006.numpy} is community standard which is heavily used. Henceforth, to broaden the usage of our
library, we should be able to provide a way to communicate between our library and NumPy. However here is a showstopper:
we only distribute source code, we don't hand over binaries. Indeed, genericity in C++ is achieved via usage of template
metaprogramming. One caveat of it is that the C++ compiler cannot generate a binary until it knows which type (of image,
of value) will be used. But we don't know this information: the user (on Python's end) is not going to recompile our
library each time he has another set of types to exercise. From here, there are still multiple ways to achieve our goal.

First option is to embark a JIT (Just-in-time) compiler whose job would be to generate the binaries and bindings just as
they are used. This solution brings speed (excluding the first run that includes the compilation time) and unrestrained
genericity. However we are now bound to specificities of a compiler vendor and loose platform portability.

Another option is to type-erase our types to enables the use of various concrete types through a single generic
interface. This would translate into a class hierarchy whose concrete classes are on the leaves (thus, whose value type
and dimension are known). This induces a non negligible slow down but allow us to keep the genericity and portability at
the cost of maintaining the class hierarchy.

Type generalization can also be considered: cast everything into a super-type that is suitable for the vast majority of
cases. For instance, we could say that we have a super-type \texttt{image4D<double>} into which we can easily cast
sub-types such as \texttt{image2D<int>} or \texttt{image3D<float>}. Of course we would loose the generic aspect and
induce non negligible speed cost. Although portability is kept.

And finally there is the dynamic dispatch. It consists in embarking dynamic information at runtime about types, and
dispatch (think of switch/case) to the correct facility which can handle those types. The obvious caveat is the cost of
maintenance induced by the genericity as we would have a number of possible dispatches that grow in a multiplicative way
with the number of handled types. Which is not very generic. On the other hand there is almost no speed loss and the
portability is guaranteed. Theoretical models exists that could bring solutions to lower the number of dispatcher to
write, such as multi-method~\cite{pirkelbauer.2010.multimethods}. Unfortunately they are currently not part of C++.

%\section{Design hybrid solution, motivations and choices}

%\FIXME{TODO: schémas solution hybride, arbre de dispatching etc.}

\section{Hybrid solution: type-erasure and $n*n$ dispatch}


In Pylene we have chosen an hybrid solution between type-erasure and dynamic dispatch. The aim is to have a set of known
types for which we have no speed cost as well as continuing to handle other types to remain generic. To achieve this
goal, we have worked together with Célian Gossec~\cite{gossec.2019.pybind}, a student co-supervised by the authors of
this thesis, in order to provide a facility to expose our generic code to Python. As seen in the previous chapter, it is
not possible to bind C++ source code to Python. We need to have a compiled binary implementing Python binding (we chose
Pybind11~\parencite{jakob.2017.pybind11}) in order to be able to call C++ code from Python. In order to achieve the
binding without sacrificing the genericity and the performances, we have designed a solution in two steps. We do not
want to provide an abstract interface that will resolve the calls to access data on the call-site via virtual call
because it would be very slow when the C++ code is executed. This would defeat the purpose of having to rely on C++ in a
first place. However, it is possible to convert an abstract class into an instantiated concrete generic class whose
template parameter are known. This requires, however, to enumerate all the possible cases. With modern C++, it has
become possible to design $n*n$ dispatch without gigantic switch-case clauses.

\paragraph{The step one} of our solution consists in designing a buffer class that holds all the informations about an
image: dimension, underlying type, strides and pointer to data buffer. This class is named \texttt{ndimage\_buffer}.
When interfacing with Python, it is necessary to convert the Python image which is a \texttt{NumpPy.array} into our
image type. The purpose of this buffer image is to holds all the informations from the \texttt{NumpPy.array} to then
instantiate a concrete C++ type. The first pitfall here is due to a limitation from the abstraction interface used in
Python. Indeed, when using for instance \emph{Scikit-Image}, it is not possible to differentiate a 2D multichannel image
from a 3D grayscale image. Indeed, the image is always broken down to its most simple value and a 3D multichannel image
is turned into a 3-dimensional \texttt{NumpPy.array} containing 8-bits values, the last dimension contains only 3
elements at max but can theoretically contain more as there is no limitation from the used abstraction to prevent that.
A 3D grayscale image will be broken down into a 3-dimensional \texttt{NumpPy.array} containing 8-bits values, the last
dimension will contain many values as it is expected of a 3D-image. To prevent this confusion, there is a need to
explicitly say to the Python/C++ wrapper wether the image is multichannel or not. This information must be carried
through the \texttt{ndimage\_buffer} into C++ for a correct instanciation. This process is illustrated
in~\cref{fig:type-erased.buffer}.

\begin{figure}[tbh]
  \centering
  \includegraphics[width=.6\linewidth]{figs/type-erased_buffer}
  \caption{Bridge from Python to C++ via Pybind11 and a type-erased C++ class.}
  \label{fig:type-erased.buffer}
\end{figure}

From the point of view of a practitioner, the code on the callsite (python side) should be as follow:
\begin{minted}{python}
  from skimage import data
  import numpy as np
  import Pylena as pln # our python binding
  img = data.astronaut() # 2D-rgb8 image -> Numpy.array(ndim=3, dtype='uint8')
  pln_img = pln.ndimage(img, multichannel=True) # manualy point out multichannel information
  # use(pln_img) for any pln.<algorithm> exposed to Python
\end{minted}

From the point of view of the library implementer, the code to expose the binding looks like this one:
\begin{minted}{C++}
  #include "ndimage.hpp"
  #include <pybind11/pybind11.h>

  // Expose pybind module
  void init_class_ndimage(pybind11::module& m);
  PYBIND11_MODULE(Pylena, m) { init_class_ndimage(m); }

  // declare the conversion function
  namespace mln::py {
    mln::ndbuffer_image   ndimage_from_buffer(pybind11::buffer b);
    pybind11::buffer_info ndimage_to_buffer(const mln::ndbuffer_image& img);
  }

  // expose the python ndimage class with the conversion from/to py::buffer (numpy.array buffer)
  void init_class_ndimage(py::module& m)
  {
    py::class_<mln::ndbuffer_image>(m, "ndimage", py::buffer_protocol())
        .def(py::init([](py::buffer b, bool multichannel) {
          return mln::py::ndimage_from_buffer(b, multichannel); }))
        .def_buffer(mln::py::ndimage_to_buffer);
  }

  // implement the conversion from Python to C++
  mln::ndbuffer_image ndimage_from_buffer(::py::buffer b, bool multichannel)
  {
    /* Request a buffer descriptor from Python */
    ::py::buffer_info info = b.request();

    std::ptrdiff_t      strides[16];
    int                 dims[16];
    int                 ndim = info.ndim - static_cast<int>(multichannel);
    int                 bpp  = info.itemsize;

    // convert the type information from Python to C++ (string to enum) for faster dispatch
    mln::sample_type_id st   = get_sample_type(info.format, multichannel);

    for (int i = 0; i < ndim; ++i) {
      dims[i]    = info.shape[ndim - 1 - i];
      strides[i] = info.strides[ndim - 1 - i];
    }

    if (strides[0] != bpp)
      throw std::runtime_error("Unsupported image stride along the last dimension.");

    // construct the type-erased image with all informations
    return mln::ndbuffer_image::from_buffer(
      reinterpret_cast<std::byte*>(info.ptr), st, ndim, dims, strides);
  }

  // implement the conversion from C++ to Python
  ::py::buffer_info ndimage_to_buffer(const mln::ndbuffer_image& img)
  {
    auto [ti, multichannel] = get_sample_type_id_traits(img.sample_type());

    int ndim = img.pdim() + static_cast<int>(multichannel);

    std::vector<ssize_t> dims(ndim);
    std::vector<ssize_t> strides(ndim);

    for (int i = 0; i < ndim - static_cast<int>(multichannel); ++i) {
      dims[i]    = img.size(ndim - 1 - i);
      strides[i] = img.byte_stride(ndim - 1 - i);
    }
    // compute manually the multichanneled information
    if(multichannel) {
      dims[ndim-1] = img.size(ndim - 1)
      strides[ndim-1] = img.byte_stride(ndim - 1) / dims[ndim-1];
    }
    // construct the python buffer with all the information
    return ::py::buffer_info(img.buffer(), ti.size(),
            get_sample_type(img.sample_type(), multichannel), ndim, dims, strides);
  }
\end{minted}

\bigskip

Let us illustrate this path with an example: the stretch algorithm. First let's see the naive algorithm:
\begin{minted}{C++}
  template <typename T>
  image2d<float> stretch(const image2d<T>& src)
  {
    auto res = image2d<float>(src.width(), src.height());
    auto values_span = src.values();
    std::transform(values_span.begin(), values_span.end(), res.values().begin(),
      [](T val) -> float
      {
        return static_cast<float>(val) / std::numeric_limits<T>::max();
      }
    );
    return res;
  }
\end{minted}

One should observe that the function parameter is templated by a type \texttt{T}. This induces that "span" further in
the code is also templated. Both needs to be type erased. Furthermore, getting the max value of the type \texttt{T} is
also an issue that needs to be abstracted away.

We aim at obtaining this prototype:

\begin{minted}{C++}
  image2d<> stretch_py(const image2d<>& src);
\end{minted}

Here \texttt{image2d<>} which is also \texttt{image2d<void>} is the type-erased type of \texttt{image2d<T>}. This means
that we have hierarchy where \texttt{image2d<T>} inherits from \texttt{image2d<void>}. We then introduce an intermediate
step:

\begin{minted}[linenos]{C++}
  template <typename T>
  struct apply_stretch_t
  {
    auto operator()(const image2d<>& src)
    {
      return stretch(*src.cast_to<T>());
    }
  };

  image2d<float> stretch(const image2d<>& src)
  {
    return visit<apply_stretch_t>(src.type().tid(), src);
  };
\end{minted}

This piece of code is interesting in many ways. It introduces the way we dispatch according to the known types (line
12): there is the embedded runtime type information we are going to use for the dispatch. Then there is the call to
\texttt{visit} parametrized by the templated structure \texttt{apply\_stretch\_t}. This visitor will statically
instantiate the correct \texttt{apply\_stretch\_t} with the correct dynamic type (\text{src.type().tid()}) and call a
non type-erased version of the function stretch after having cast the values of the images. However, for this to work we
still have to tweak the first implementation a little.

\begin{minted}[linenos]{C++}
  template <class T>
  image2d<float> stretch(const image2d<T>& src)
  {
    auto        res  = image2d<float>(src.width(), src.height());
    auto        span = src.values();
    const auto& vs   = src.get_value_set();
    std::transform(span.begin(), span.end(), res.values().begin(),
                   [&vs](auto val) -> float
                   {
                     auto tmp = vs.max();
                     return vs.template cast<float>(val) / vs.template cast<float>(tmp);
                   });
    return res;
  }
\end{minted}

We introduce a new tool: the value-set (line 6). This value-set is a type-erased way to provide basic operations on
types such as casting, division, addition, getting the global max etc. This powerful tool, also embedded in the image,
allow us to write the algorithm in a generic way lines 10-11.

Thanks to this design, we have been able to type-erase our image types so that our algorithms can be called through
python via bindings generated by pybind~\cite{jakob.2017.pybind11}. As an example, we can then call our stretch
algorithm this way:

\begin{minted}{python}
  import pylena as pln, imageio, numpy as np
  img_in = imageio.imread("lena.png")
  np_arr = np.array(img_in, dtype='int8')
  img = pln.image2d(np_arr)
  print(timeit.timeit('img_out = pln.stretch(img)', number=1000,
        globals=globals()))
  >> 0.24129085899949132 # Seconds for 1000 cycles

  # Using a type that isn't int8 or int16
  np_arr64 = np.array(img_in, dtype='int64')
  img64 = pln.image2d(np_arr64)
  print(timeit.timeit('img_out64 = pln.invert(img64)', number=1000,
        globals=globals()))
  >> 26.124844277999728 # Seconds for 1000 cycles
\end{minted}

We can observe a hundred time factor between the fast and optimized path and the slow dynamically dispatched path.

\section{Performances \& overhead}

\FIXME{TODO: courbes de performances mesurées depuis Python}

\section{JIT-based solutions: pros. and cons.}

\FIXME{TODO: état de l'art, schémas de fonctionnement du JIT}
