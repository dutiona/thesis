\chapter{Static dynamic bridge}
\label{chap.static_dynamic_bridge}

%\section{Coexistence between the static world and the dynamic world}
%introduction

In the programming world, there are two main families of programming language. There are the \emph{compiled}
programming, such as C, C++, Rust or Go. There are also the \emph{interpreted} programming languages, such as Python,
PHP, Lisp or Javascript. Finally, there are languages such as Java that are both at the same time.

The \emph{compiled} programming languages have the advantage of being very end-user friendly. Indeed, the implementer
distribute compiled self-sufficient binaries and the user select the binary that is compatible with his operating
system. Then, the program is supposed to work out of the box without more work than that, as illustrated
in~\cref{fig:static.dynamic.compiled.runtime}.

\begin{figure}[tbh]
  \centering
  \includegraphics[width=.6\linewidth]{figs/static_runtime}
  \caption{Compiled languages: run-time}
  \label{fig:static.dynamic.compiled.runtime}
\end{figure}

Opposite to this apparent simplicity for the end-user, all the burden is shouldered by the programmer. Indeed, to
generate a binary, there are many steps, as illustrated in~\cref{fig:static.dynamic.compiled.compiletime}. There is a
first pass with the compiler to generate intermediate machine code. Then there is a linker pass to resolve any
dependency between machine code and system code into one or multiple final distributable binaries. However, this last
pass tie the binary with a distribution. Indeed, the location of system libraries may vary between operating system,
between version of the same operating system, between compiler variants etc. Also, as the developer wants to distribute
efficient programs, he will use last optimized vectorized instructions if possible, which can tie further the binary to
a certain set of hardware supporting some assembly instructions (SSE4, XOP, FMA4, AVX-512, etc.). Upstream from those
issues, there are also issues with code. Indeed, many libraries are not cross-platform and leveraging all the
equivalences from one OS to another incurs an increase in code quantity, tests and maintenance cost to support many
platforms. For instance, the native GUI Windows libraries does not exist in Linux and must be rewritten with another
framework, such as GTK or Qt. Or else, the developer can choose to use a cross-platform GUI library from start however
this decision may not have been viable if the software was first windows-only and the cross-platform support was added
at a later date. Another caveat is that using code introspection is often very difficult at compile-time because only
few information are available (only static information). Dynamic reflection at runtime is impossible.

\begin{figure}[tbh]
  \centering
  \includegraphics[width=.6\linewidth]{figs/static_compiletime}
  \caption{Compiled languages: compile-time}
  \label{fig:static.dynamic.compiled.compiletime}
\end{figure}

The \emph{interpreted} programming language are a little less end-user friendly but are much more comfortable for
developer to distribute their software. Indeed, as shown in~\cref{fig:static.dynamic.dynamic.pipeline}, everything
happens at runtime. The maintainer only distribute the source code, the dependency list and the assets necessaries for
his program. The burden is mostly shouldered by the end-user this time. He must download and install all the language
interpreter and environment in order to execute the program from the source code. He must resolve the dependencies and
be able to execute the source code on his computer. This has the advantage of having a very rich ecosystem as
distributing, maintaining and using programs is very easy once integrated in a package manager (often delivered with the
language SDK natively). However, the main disadvantage is the performance. As the source code is not compiled into
optimized assembly code ready to be executed, the interpreter must do all the work in one go and very often this is
slow. Nowadays, all the interpreter embarks a Just-In-Time (JIT) compiler that detected the portions of a program that
are used heavily (a.k.a. hot code) and will compile them into native machine code to increase the performance
drastically without having the user pay for a long compilation time. Also, those languages usually have very developed
introspection facilities. Dynamic reflection at runtime is possible and some language, such as Common Lisp, even go
further by allowing the developer to mutate the program Abstract Syntax Tree (AST) at runtime (macro). This allows very
powerful integrations such as defining one's own DSL as if it was part of the core language itself.

\begin{figure}[tbh]
  \centering
  \includegraphics[width=.6\linewidth]{figs/dynamic_pipeline}
  \caption{Compiled languages: compile-time}
  \label{fig:static.dynamic.dynamic.pipeline}
\end{figure}

Image processing communities like to have bridges with interpretable language such as Python or Matlab, to interface
with their favorite tools, algorithms and/or facilities. As an example, with Python, the module
NumPy~\cite{oliphant.2006.numpy} is community standard which is heavily used. Henceforth, to broaden the usage of our
library, we should be able to provide a way to communicate between our library and NumPy. However here is a showstopper:
we only distribute source code, we don't hand over binaries. Indeed, genericity in C++ is achieved via usage of template
metaprogramming. One caveat of it is that the C++ compiler cannot generate a binary until it knows which type (of image,
of value) will be used. But we don't know this information: the user (on Python's end) is not going to recompile our
library each time he has another set of types to exercise. From here, there are still multiple ways to achieve our goal.

First option is to embark a JIT (Just-in-time) compiler whose job would be to generate the binaries and bindings just as
they are used. This solution brings speed (excluding the first run that includes the compilation time) and unrestrained
genericity. However we are now bound to specificities of a compiler vendor and loose platform portability.

Another option is to type-erase our types to enables the use of various concrete types through a single generic
interface. This would translate into a class hierarchy whose concrete classes are on the leaves (thus, whose value type
and dimension are known). This induces a non negligible slow down but allow us to keep the genericity and portability at
the cost of maintaining the class hierarchy.

Type generalization can also be considered: cast everything into a super-type that is suitable for the vast majority of
cases. For instance, we could say that we have a super-type \texttt{image4D<double>} into which we can easily cast
sub-types such as \texttt{image2D<int>} or \texttt{image3D<float>}. Of course we would loose the generic aspect and
induce non negligible speed cost. Although portability is kept.

And finally there is the dynamic dispatch. It consists in embarking dynamic information at runtime about types, and
dispatch (think of switch/case) to the correct facility which can handle those types. The obvious caveat is the cost of
maintenance induced by the genericity as we would have a number of possible dispatches that grow in a multiplicative way
with the number of handled types. Which is not very generic. On the other hand there is almost no speed loss and the
portability is guaranteed. Theoretical models exists that could bring solutions to lower the number of dispatcher to
write, such as multi-method~\cite{pirkelbauer.2010.multimethods}. Unfortunately they are currently not part of C++.

\FIXME{TODO: schémas static/dynamic worlds}

\section{Design hybrid solution, motivations and choices}

\FIXME{TODO: schémas solution hybride, arbre de dispatching etc.}

\section{Hybrid solution: $n*n$ dispatch thanks to variants}

\FIXME{TODO: liens, plus d'examples}


In Pylene we have chosen an hybrid solution between type-erasure and dynamic dispatch. The aim is to have a set of known
types for which we have no speed cost as well as continuing to handle other types to remain generic. To achieve this
goal, we have worked together with Célian Gossec~\cite{gossec.2019.pybind}, a student co-supervised by the authors of
this report, in order to type-erased the most important types (images) as well as the algorithms. We then embark runtime
information about carried types in the type-erased object. When the algorithm is called on the type-erased object, we
attempt to cast this object into a known set of types (dimensions: 2, 3, 4; value: int, double, rgba). Should the cast
succeed then we can call the fast, optimized routine. Otherwise we fallback onto an algorithm relying on dynamic
dispatch even for its most basic operation (e.g. addition).

Let us illustrate this path with an example: the stretch algorithm. First let's see the naive algorithm:
\begin{minted}{C++}
  template <typename T>
  image2d<float> stretch(const image2d<T>& src)
  {
    auto res = image2d<float>(src.width(), src.height());
    auto values_span = src.values();
    std::transform(values_span.begin(), values_span.end(), res.values().begin(),
      [](T val) -> float
      {
        return static_cast<float>(val) / std::numeric_limits<T>::max();
      }
    );
    return res;
  }
\end{minted}

One should observe that the function parameter is templated by a type \texttt{T}. This induces that "span" further in
the code is also templated. Both needs to be type erased. Furthermore, getting the max value of the type \texttt{T} is
also an issue that needs to be abstracted away.

We aim at obtaining this prototype:

\begin{minted}{C++}
  image2d<> stretch_py(const image2d<>& src);
\end{minted}

Here \texttt{image2d<>} which is also \texttt{image2d<void>} is the type-erased type of \texttt{image2d<T>}. This means
that we have hierarchy where \texttt{image2d<T>} inherits from \texttt{image2d<void>}. We then introduce an intermediate
step:

\begin{minted}[linenos]{C++}
  template <typename T>
  struct apply_stretch_t
  {
    auto operator()(const image2d<>& src)
    {
      return stretch(*src.cast_to<T>());
    }
  };

  image2d<float> stretch(const image2d<>& src)
  {
    return visit<apply_stretch_t>(src.type().tid(), src);
  };
\end{minted}

This piece of code is interesting in many ways. It introduces the way we dispatch according to the known types (line
12): there is the embedded runtime type information we are going to use for the dispatch. Then there is the call to
\texttt{visit} parametrized by the templated structure \texttt{apply\_stretch\_t}. This visitor will statically
instantiate the correct \texttt{apply\_stretch\_t} with the correct dynamic type (\text{src.type().tid()}) and call a
non type-erased version of the function stretch after having cast the values of the images. However, for this to work we
still have to tweak the first implementation a little.

\begin{minted}[linenos]{C++}
  template <class T>
  image2d<float> stretch(const image2d<T>& src)
  {
    auto        res  = image2d<float>(src.width(), src.height());
    auto        span = src.values();
    const auto& vs   = src.get_value_set();
    std::transform(span.begin(), span.end(), res.values().begin(),
                   [&vs](auto val) -> float
                   {
                     auto tmp = vs.max();
                     return vs.template cast<float>(val) / vs.template cast<float>(tmp);
                   });
    return res;
  }
\end{minted}

We introduce a new tool: the value-set (line 6). This value-set is a type-erased way to provide basic operations on
types such as casting, division, addition, getting the global max etc. This powerful tool, also embedded in the image,
allow us to write the algorithm in a generic way lines 10-11.

Thanks to this design, we have been able to type-erase our image types so that our algorithms can be called through
python via bindings generated by pybind~\cite{jakob.2017.pybind11}. As an example, we can then call our stretch
algorithm this way:

\begin{minted}{python}
  import pylena as pln, imageio, numpy as np
  img_in = imageio.imread("lena.png")
  np_arr = np.array(img_in, dtype='int8')
  img = pln.image2d(np_arr)
  print(timeit.timeit('img_out = pln.stretch(img)', number=1000,
        globals=globals()))
  >> 0.24129085899949132 # Seconds for 1000 cycles

  # Using a type that isn't int8 or int16
  np_arr64 = np.array(img_in, dtype='int64')
  img64 = pln.image2d(np_arr64)
  print(timeit.timeit('img_out64 = pln.invert(img64)', number=1000,
        globals=globals()))
  >> 26.124844277999728 # Seconds for 1000 cycles
\end{minted}

We can observe a hundred time factor between the fast and optimized path and the slow dynamically dispatched path.

\section{Performances \& overhead}

\FIXME{TODO: courbes de performances mesurées depuis Python}

\section{JIT-based solutions: pros. and cons.}

\FIXME{TODO: état de l'art, schémas de fonctionnement du JIT}
