\chapter{Static dynamic bridge}
\label{chap.static_dynamic_bridge}

%\section{Coexistence between the static world and the dynamic world}
%introduction

In the programming world, there are two main families of programming language. There are the \emph{compiled}
programming, such as C, C++, Rust or Go. There are also the \emph{interpreted} programming languages, such as Python,
PHP, Lisp or Javascript. Finally, there are languages such as Java that are both at the same time.

The \emph{compiled} programming languages have the advantage of being very end-user friendly. Indeed, the implementer
distribute compiled self-sufficient binaries and the user select the binary that is compatible with his operating
system. Then, the program is supposed to work out of the box without more work than that, as illustrated
in~\cref{fig:static.dynamic.compiled.runtime}.

\begin{figure}[tbh]
  \centering
  \includegraphics[width=.6\linewidth]{figs/static_runtime}
  \caption{Compiled languages: run-time}
  \label{fig:static.dynamic.compiled.runtime}
\end{figure}

Opposite to this apparent simplicity for the end-user, all the burden is shouldered by the programmer. Indeed, to
generate a binary, there are many steps, as illustrated in~\cref{fig:static.dynamic.compiled.compiletime}. There is a
first pass with the compiler to generate intermediate machine code. Then there is a linker pass to resolve any
dependency between machine code and system code into one or multiple final distributable binaries. However, this last
pass tie the binary with a distribution. Indeed, the location of system libraries may vary between operating system,
between version of the same operating system, between compiler variants etc. Also, as the developer wants to distribute
efficient programs, he will use last optimized vectorized instructions if possible, which can tie further the binary to
a certain set of hardware supporting some assembly instructions (SSE4, XOP, FMA4, AVX-512, etc.). Upstream from those
issues, there are also issues with code. Indeed, many libraries are not cross-platform and leveraging all the
equivalences from one OS to another incurs an increase in code quantity, tests and maintenance cost to support many
platforms. For instance, the native GUI Windows libraries does not exist in Linux and must be rewritten with another
framework, such as GTK or Qt. Or else, the developer can choose to use a cross-platform GUI library from start however
this decision may not have been viable if the software was first windows-only and the cross-platform support was added
at a later date. Another caveat is that using code introspection is often very difficult at compile-time because only
few information are available (only static information). Dynamic reflection at runtime is impossible.

\begin{figure}[tbh]
  \centering
  \includegraphics[width=.6\linewidth]{figs/static_compiletime}
  \caption{Compiled languages: compile-time}
  \label{fig:static.dynamic.compiled.compiletime}
\end{figure}

The \emph{interpreted} programming language are a little less end-user friendly but are much more comfortable for
developer to distribute their software. Indeed, as shown in~\cref{fig:static.dynamic.dynamic.pipeline}, everything
happens at runtime. The maintainer only distribute the source code, the dependency list and the assets necessaries for
his program. The burden is mostly shouldered by the end-user this time. He must download and install all the language
interpreter and environment in order to execute the program from the source code. He must resolve the dependencies and
be able to execute the source code on his computer. This has the advantage of having a very rich ecosystem as
distributing, maintaining and using programs is very easy once integrated in a package manager (often delivered with the
language SDK natively). However, the main disadvantage is the performance. As the source code is not compiled into
optimized assembly code ready to be executed, the interpreter must do all the work in one go and very often this is
slow. Nowadays, all the interpreter embarks a Just-In-Time (JIT) compiler that detected the portions of a program that
are used heavily (a.k.a. hot code) and will compile them into native machine code to increase the performance
drastically without having the user pay for a long compilation time. Also, those languages usually have very developed
introspection facilities. Dynamic reflection at runtime is possible and some language, such as Common Lisp, even go
further by allowing the developer to mutate the program Abstract Syntax Tree (AST) at runtime (macro). This allows very
powerful integrations such as defining one's own DSL as if it was part of the core language itself.

\begin{figure}[tbh]
  \centering
  \includegraphics[width=.6\linewidth]{figs/dynamic_pipeline}
  \caption{Compiled languages: compile-time}
  \label{fig:static.dynamic.dynamic.pipeline}
\end{figure}

Image processing communities like to have bridges with interpretable language such as Python or Matlab, to interface
with their favorite tools, algorithms and/or facilities. As an example, with Python, the module
NumPy~\cite{oliphant.2006.numpy} is community standard which is heavily used. Henceforth, to broaden the usage of our
library, we should be able to provide a way to communicate between our library and NumPy. However here is a showstopper:
we only distribute source code, we don't hand over binaries. Indeed, genericity in C++ is achieved via usage of template
metaprogramming. One caveat of it is that the C++ compiler cannot generate a binary until it knows which type (of image,
of value) will be used. But we don't know this information: the user (on Python's end) is not going to recompile our
library each time he has another set of types to exercise. From here, there are still multiple ways to achieve our goal.

First option is to embark a JIT (Just-in-time) compiler whose job would be to generate the binaries and bindings just as
they are used. This solution brings speed (excluding the first run that includes the compilation time) and unrestrained
genericity. However we are now bound to specificities of a compiler vendor and loose platform portability.

Another option is to type-erase our types to enables the use of various concrete types through a single generic
interface. This would translate into a class hierarchy whose concrete classes are on the leaves (thus, whose value type
and dimension are known). This induces a non negligible slow down but allow us to keep the genericity and portability at
the cost of maintaining the class hierarchy.

Type generalization can also be considered: cast everything into a super-type that is suitable for the vast majority of
cases. For instance, we could say that we have a super-type \texttt{image4D<double>} into which we can easily cast
sub-types such as \texttt{image2D<int>} or \texttt{image3D<float>}. Of course we would loose the generic aspect and
induce non negligible speed cost. Although portability is kept.

And finally there is the dynamic dispatch. It consists in embarking dynamic information at runtime about types, and
dispatch (think of switch/case) to the correct facility which can handle those types. The obvious caveat is the cost of
maintenance induced by the genericity as we would have a number of possible dispatches that grow in a multiplicative way
with the number of handled types. Which is not very generic. On the other hand there is almost no speed loss and the
portability is guaranteed. Theoretical models exists that could bring solutions to lower the number of dispatcher to
write, such as multi-method~\cite{pirkelbauer.2010.multimethods}. Unfortunately they are currently not part of C++.

%\section{Design hybrid solution, motivations and choices}

%\FIXME{TODO: schémas solution hybride, arbre de dispatching etc.}

\section{Hybrid solution: type-erasure and $n*n$ dispatch}


In Pylene we have chosen an hybrid solution between type-erasure and dynamic dispatch. The aim is to have a set of known
types for which we have no speed cost as well as continuing to handle other types to remain generic. To achieve this
goal, we have worked together with Célian Gossec~\cite{gossec.2019.pybind}, a student co-supervised by the authors of
this thesis, in order to provide a facility to expose our generic code to Python. As seen in the previous chapter, it is
not possible to bind C++ source code to Python. We need to have a compiled binary implementing Python binding (we chose
Pybind11~\parencite{jakob.2017.pybind11}) in order to be able to call C++ code from Python. In order to achieve the
binding without sacrificing the genericity and the performances, we have designed a solution in two steps. We do not
want to provide an abstract interface that will resolve the calls to access data on the call-site via virtual call
because it would be very slow when the C++ code is executed. This would defeat the purpose of having to rely on C++ in a
first place. However, it is possible to convert an abstract class into an instantiated concrete generic class whose
template parameter are known. This requires, however, to enumerate all the possible cases. With modern C++, it has
become possible to design $n*n$ dispatch without gigantic switch-case clauses.

\subsection{First step: type-erasure}

The first step of our solution consists in designing a buffer class that holds all the informations about an image:
dimension, underlying type, strides and pointer to data buffer. This class is named \texttt{ndimage\_buffer}. When
interfacing with Python, it is necessary to convert the Python image which is a \texttt{NumpPy.array} into our image
type. The purpose of this buffer image is to holds all the informations from the \texttt{NumpPy.array} to then
instantiate a concrete C++ type. The first pitfall here is due to a limitation from the abstraction interface used in
Python. Indeed, when using for instance \emph{Scikit-Image}, it is not possible to differentiate a 2D multichannel image
from a 3D grayscale image. Indeed, the image is always broken down to its most simple value and a 3D multichannel image
is turned into a 3-dimensional \texttt{NumpPy.array} containing 8-bits values, the last dimension contains only 3
elements at max but can theoretically contain more as there is no limitation from the used abstraction to prevent that.
A 3D grayscale image will be broken down into a 3-dimensional \texttt{NumpPy.array} containing 8-bits values, the last
dimension will contain many values as it is expected of a 3D-image. To prevent this confusion, there is a need to
explicitly say to the Python/C++ wrapper wether the image is multichannel or not. This information must be carried
through the \texttt{ndimage\_buffer} into C++ for a correct instanciation. This process is illustrated
in~\cref{fig:type-erased.buffer}.

\begin{figure}[tbh]
  \centering
  \includegraphics[width=.6\linewidth]{figs/type-erased_buffer}
  \caption{Bridge from Python to C++ via Pybind11 and a type-erased C++ class.}
  \label{fig:type-erased.buffer}
\end{figure}

From the point of view of a practitioner, the code on the call-site (python side) should be as follow:
\begin{minted}{python}
  from skimage import data
  import numpy as np
  import Pylena as pln # our python binding
  img = data.astronaut() # 2D-rgb8 image -> Numpy.array(ndim=3, dtype='uint8')
  pln_img = pln.ndimage(img, multichannel=True) # manualy point out multichannel information
  # use(pln_img) for any pln.<algorithm> exposed to Python
\end{minted}

From the point of view of the library implementer, the code to expose the binding looks like this one:
\begin{minted}{C++}
  #include "ndimage.hpp"
  #include <pybind11/pybind11.h>

  // Expose pybind module
  void init_class_ndimage(pybind11::module& m);
  PYBIND11_MODULE(Pylena, m) { init_class_ndimage(m); }

  // declare the conversion function
  namespace mln::py {
    mln::ndbuffer_image   ndimage_from_buffer(pybind11::buffer b);
    pybind11::buffer_info ndimage_to_buffer(const mln::ndbuffer_image& img);
  }

  // expose the python ndimage class with the conversion from/to py::buffer (numpy.array buffer)
  void init_class_ndimage(py::module& m)
  {
    py::class_<mln::ndbuffer_image>(m, "ndimage", py::buffer_protocol())
        .def(py::init([](py::buffer b, bool multichannel) {
          return mln::py::ndimage_from_buffer(b, multichannel); }))
        .def_buffer(mln::py::ndimage_to_buffer);
  }
\end{minted}

This code declares a new module named \texttt{Pylena}. It then declares a class named \texttt{ndimage} which is a bridge
to Python's \texttt{buffer\_protocol}. This \texttt{buffer\_protocol} is an abstraction to allow the usage of NumPy's
array. Finally, the code declares that the class is convertible to and from the \texttt{buffer\_protocol} thanks to
provided callbacks. The code of those callbacks is as follow:

\begin{minted}{C++}
  // implement the conversion from Python to C++
  mln::ndbuffer_image ndimage_from_buffer(::py::buffer b, bool is_multichannel)
  {
    /* Request a buffer descriptor from Python */
    ::py::buffer_info info = b.request();

    std::ptrdiff_t      strides[16];
    int                 dims[16];
    int                 ndim = info.ndim - is_multichannel ? 1 : 0;
    int                 bpp  = info.itemsize;

    // convert the type information from Python to C++ (string to enum) for faster dispatch
    mln::sample_type_id st   = get_sample_type(info.format, is_multichannel);

    for (int i = 0; i < ndim; ++i) {
      dims[i]    = info.shape[ndim - 1 - i];
      strides[i] = info.strides[ndim - 1 - i];
    }

    if (strides[0] != bpp)
      throw std::runtime_error("Unsupported image stride along the last dimension.");

    // construct the type-erased image with all informations
    return mln::ndbuffer_image::from_buffer(
      reinterpret_cast<std::byte*>(info.ptr), st, ndim, dims, strides);
  }

  // implement the conversion from C++ to Python
  ::py::buffer_info ndimage_to_buffer(const mln::ndbuffer_image& img)
  {
    // return the python format of the underlying type, as well as information about multichanneling
    auto [ti, is_multichannel] = get_sample_type_id_traits(img.sample_type());

    int ndim = img.pdim() + is_multichannel ? 1 : 0;

    std::vector<ssize_t> dims(ndim);
    std::vector<ssize_t> strides(ndim);

    for (int i = 0; i < ndim; ++i) {
      dims[i]    = img.size(ndim - 1 - i);
      strides[i] = img.byte_stride(ndim - 1 - i);
    }
    // construct the python buffer with all the information
    return ::py::buffer_info(img.buffer(), ti.size(),
            get_sample_type(img.sample_type(), multichannel), ndim, dims, strides);
  }
\end{minted}

This code forward informations about the buffer and handle the special case of multichannel images which Python treat
as 3D images.

\subsection{Second step: multi-dispatcher}
The second step of our hybrid solution is to dispatch the type-erased code to efficient generic code. The naive way of
doing so would be to include a gigantic switch-case clause in each algorithm implementation and dispatch to the correct
instantiated generic algorithm from there. Aside from being a nightmare to maintain, the size of those clause can grow
several fold depending on the cardinality of the generic implementation. For instance, for a generic dilation, there are
3 axis of cardinality: the underlying type, the dimension, the structuring element shape. In the case where the library
support 5 different structuring element shape, 10 underlying types and 6 dimension for the image, the switch-case
statement will have 300 clauses to dispatch. And each algorithm will have to dispatch. This solution is not viable,
defeat the purpose of genericity which is to write less code in the first place. We had to find a solution to have those
dispatch while keeping our code short and efficient. The idea we took to solve this problem comes from the design of a
C++ feature, the variant, and especially the visitor. We need to have a way to write the implementation of the algorithm
once while enumerating all the possible cases. Also, if possible, the list of supported types should be written once at
one place for maintenance purpose.

We then had the idea of writing a dispatcher. This dispatcher list all the supported types and call the given callbacks
forwarding the given arguments by instantiating a specific type. For instance, let us first expose the binary threshold
operator to Python. The Python call-site code will look like this:

\begin{minted}{python}
  img_grayscale = skimage.data.grass()
  pln.operators.binary_threshold(img_grayscale)
\end{minted}

On C++ side, we need to expose the function with this code:
\begin{minted}{C++}
  void init_module_operators(pybind11::module& m);

  mln::ndbuffer_image binary_threshold(::py::buffer buffer)

  void init_module_operators(::py::module& m) {
    using namespace pybind11::literals;

    m.def("binary_threshold", binary_threshold,
          "Perform a binary threshold.\n",
          "Input"_a);
  }

  PYBIND11_MODULE(Pylena, m) {
    /* ... */

    auto operators = m.def_submodule("operators", "Image processing operators.");
    init_module_operators(operators);
  }
\end{minted}

Now that our python submodule and that our \texttt{binary\_threshold} operator are declared, let us have a look to the
operator's implementation:

\begin{minted}{C++}
  mln::ndbuffer_image dilate(::py::buffer buffer)
  {
    // grayscale image mandatory
    auto input = mln::py::ndimage_from_buffer(buffer);

    // dispatch along dimension (dimension is a valued template parameter, hence _v)
    return dispatch_v<binary_threshold_operator_t>(input.pdim(), input);
  }
\end{minted}

We have replaced the gigantic switch-case clause by a dispatcher templated by an operator. This operator will cast the
input image into the concrete generic type and call the fast generic algorithm on it. Let us have a look to what this
operator look like:

\begin{minted}{C++}
  // Operator templated by the dimension
  template <auto Dim>
  struct binary_threshold_operator_t {
    // Function templated by the image type
    template <typename Img>
    mln::ndbuffer_image operator()(Img&& img) const {
      // Cast to a grayscale (information known) of the correct dimension
      if (auto* image_ptr = std::forward<Img>(img).template cast_to<std::uint8_t, Dim>(); image_ptr)
        // call generic algorithm
        return mln::operators::binary_threshold(*image_ptr);
      else {
        std::runtime_error("Unable to convert the image to the required type.");
        return {};
      }
    }
  };
\end{minted}

This operator will attempt to cast the given image into a grayscale image of the correct dimension and then use the
resulting concrete type to pass it the fast generic \texttt{binary\_threshold} operator. Now let us have a look at where
the magic happen, at the dispatcher which list all the supported type.

\begin{minted}{C++}
template <template <auto> class V, typename... Args>
auto dispatch_v(std::size_t dim, Args&&... args) {
  switch (pdim) {
  case (1):
    return F<1>{}(std::forward<Args>(args)...);
  case (2):
    return F<2>{}(std::forward<Args>(args)...);
  case (3):
    return F<3>{}(std::forward<Args>(args)...);
  case (4):
    return F<4>{}(std::forward<Args>(args)...);
  case (5):
    return F<5>{}(std::forward<Args>(args)...);

  /* ... */

  case (0):
    [[fallthrough]];
  default:
    throw std::runtime_error("Unsupported dimension.");
}
\end{minted}

The dispatcher is instantiate the given type by the correct dimension number and then call the operator parenthesis
(function call) forwarding all the given parameters. In our case, it will instantiate the type
\texttt{binary\_threshold\_operator\_t<2>} and then call the function
\texttt{binary\_threshold\_operator\_t<2>.operator()(input)}, forwarding the input image to the underlying algorithm.

The main advantage of this approach is that all the supported features are to be listed only in one place, the
dispatcher, while any number of dispatcher can be piped to achieve the cardinality wanted. Let us push our example to
implement the mathematical morphology operator dilation. We now have two more generic axis to cover: the structuring
element shape and the underlying datatype. First, let us expose the operator to the Python code. Here is what the Python call-site look like:

\begin{minted}{python}
img_grayscale = skimage.data.grass()
rect = pln.se.rect2d(width=3, height=3)
pln.operators.dilate(img_grayscale, se)
\end{minted}

We need to expose the new structuring element's sub-module for usage in the dilation operator:

\begin{minted}{C++}
void init_module_se(pybind11::module& m);

void init_module_se(::py::module& m) {
  ::py::class_<mln::se::disc>(m, "disc").def(
      ::py::init([](float radius) { return mln::se::disc{radius}; }));

  ::py::class_<mln::se::sphere>(m, "sphere").def(::py::init([](float radius) {
    return mln::se::sphere{radius};
  }));

  ::py::class_<mln::se::rect2d>(m, "rect2d").def(::py::init([](int width, int height) {
    return mln::se::rect2d{width, height};
  }));

  ::py::class_<mln::se::rect3d>(m, "rect3d").def(::py::init([](int width, int height, int depth) {
    return mln::se::rect3d{width, height, depth};
  }));
}

PYBIND11_MODULE(Pylena, m) {
  /* ... */

  auto mse = m.def_submodule("se", "Structuring elements module.");
  init_module_se(mse);
}
\end{minted}

Now we need to expose the dilate function into the operator submodule:
\begin{minted}{C++}
// using std::variant
using se_t = std::variant<mln::se::disc, mln::se::sphere,
                          mln::se::rect2d, mln::se::cube>;

mln::ndbuffer_image dilate(::py::buffer buffer, const se_t& se)

void init_module_operators(::py::module& m) {
  /* ... */

  m.def("dilate", dilate,
    "Perform a morphological dilation.\n"
    "\n"
    "structuring element must be valid.",
    "Input"_a, "se"_a);
}
\end{minted}

We are all set to now implement the dilation operator. First, let us have a look at the underlying operator that will be
dispatched:

\begin{minted}{C++}
template <auto Dim, typename T>
struct dilate_operator_t {
  template <typename Img, typename SE>
  mln::ndbuffer_image operator()(Img&& img, SE se) const {
    if (auto* image_ptr = std::forward<Img>(img).template cast_to<T, Dim>(); image_ptr)
      return mln::dilation(*image_ptr, se);
    else {
      std::runtime_error("Unable to convert the image to the required type.");
      return {};
    }
  }
};
\end{minted}

Here we can see that we need a double dispatch. Also, the structuring element is no longue a variant and needs to be
dispatched before instantiating this operator. Finally, there is an issue here because there are two template parameter
and our dispatcher \texttt{dispatch\_v} does only handle one. We workaround this issue by writing another intermediate
operator dispatcher \texttt{dilate\_operator\_intermediate\_t} serving as trampoline that will partially instantiate the
final operator \texttt{dilate\_operator\_t} along the dimension template parameter to feed it to the last dispatcher,
\texttt{dispatch\_t}:

\begin{minted}{C++}
template <auto Dim>
struct dilate_operator_intermediate_t {
  template <typename Img, typename SE>
  mln::ndbuffer_image operator()(Img&& img, SE&& se) const {
    // Partial instantiation
    return double_dispatch_t<dilate_operator_t, Dim>(
            input.sample_type(), std::forward<Img>(input), std::forward<SE>(se));
  }
};
\end{minted}

The final function implementation will look like this:

\begin{minted}{C++}
mln::ndbuffer_image dilate(::py::buffer buffer, const se_t& se) {
  auto input = mln::py::ndimage_from_buffer(buffer);
  // dispatch the structuring elements through using std::visit for std::variant 
  return std::visit(
      [&input](const auto& se_) {
        return dispatch_v<dilate_operator_intermediate_t>(input.pdim(), input, se_);
      }, se);
}
\end{minted}

The final piece of our puzzle would be the double dispatch function that will handle the last dispatch along the
underlying data while forwarding the first dispatch along the dimension. Here is how we implemented our double dispatch:

\begin{minted}{C++}
template <template <auto, typename> class F, auto Dim, typename... Args>
auto double_dispatch_t(mln::sample_type_id tid, Args&&... args) {
  switch (tid) {
    case (mln::sample_type_id::INT8):
      return F<Dim, std::int8_t>{}(std::forward<Args>(args)...);
    case (mln::sample_type_id::INT16):
      return F<Dim, std::int16_t>{}(std::forward<Args>(args)...);
    case (mln::sample_type_id::INT32):
      return F<Dim, std::int32_t>{}(std::forward<Args>(args)...);
    case (mln::sample_type_id::UINT8):
      return F<Dim, std::uint8_t>{}(std::forward<Args>(args)...);
    case (mln::sample_type_id::UINT16):
      return F<Dim, std::uint16_t>{}(std::forward<Args>(args)...);
    case (sample_type_id::UINT32):
      return F<Dim, std::uint32_t>{}(std::forward<Args>(args)...);
    case (mln::sample_type_id::DOUBLE):
      return F<Dim, double>{}(std::forward<Args>(args)...);

      /* ... */

    case (mln::sample_type_id::OTHER):
      [[fallthrough]];
    default:
      throw std::runtime_error("Unhandled data type");
  }
}
\end{minted}

Now we have all the pieces to build operators that are agnostic from the supported data-types. Indeed, the maintainer
has gathered all the logic about listing supported data types and dimension into variant or custom dispatcher. He just
need to maintain those to enable, by default, all exposed algorithm to support them. This hybrid solution mixes
type-erasure and modern C++ facilities to allow maximum performance. Indeed, the dispatch is done before entering
algorithms and the buffer protocol facility allows us to plug directly into the Python image without having any
unnecessary copies. The only caveat would be the code bloat incurred by all the explicit instanciation leading to
compiling a large binary. Another point not covered right now would be a way to inject Python types into C++. Indeed,
our hybrid solution only support the types provided by the library. It will instantiate all the code relative to them
and support all of the combinations. But the user may be tempted to plug a user-defined type from Python as an
underlying data-type. To allow this use-case, we introduce a new concept: the value-set. The value-set is a standard way
manipulate the underlying values. Through type-erasure, we can either manipulate a known underlying value with native
facilities (near-zero overhead) or fallback on a virtual call that may report an error or callback user-provided Python
routine to manipulate an unknown user value.

\subsection{Third and final step: the value-set}

\FIXME{TODO: write subsection.}

\subsection*{Material for value-set}


Let us illustrate this path with an example: the stretch algorithm. First let's see the naive algorithm:
\begin{minted}{C++}
  template <typename T>
  image2d<float> stretch(const image2d<T>& src)
  {
    auto res = image2d<float>(src.width(), src.height());
    auto values_span = src.values();
    std::transform(values_span.begin(), values_span.end(), res.values().begin(),
      [](T val) -> float
      {
        return static_cast<float>(val) / std::numeric_limits<T>::max();
      }
    );
    return res;
  }
\end{minted}

One should observe that the function parameter is templated by a type \texttt{T}. This induces that "span" further in
the code is also templated. Both needs to be type erased. Furthermore, getting the max value of the type \texttt{T} is
also an issue that needs to be abstracted away.

We aim at obtaining this prototype:

\begin{minted}{C++}
  image2d<> stretch_py(const image2d<>& src);
\end{minted}

Here \texttt{image2d<>} which is also \texttt{image2d<void>} is the type-erased type of \texttt{image2d<T>}. This means
that we have hierarchy where \texttt{image2d<T>} inherits from \texttt{image2d<void>}. We then introduce an intermediate
step:

\begin{minted}[linenos]{C++}
  template <typename T>
  struct apply_stretch_t
  {
    auto operator()(const image2d<>& src)
    {
      return stretch(*src.cast_to<T>());
    }
  };

  image2d<float> stretch(const image2d<>& src)
  {
    return visit<apply_stretch_t>(src.type().tid(), src);
  };
\end{minted}

This piece of code is interesting in many ways. It introduces the way we dispatch according to the known types (line
12): there is the embedded runtime type information we are going to use for the dispatch. Then there is the call to
\texttt{visit} parametrized by the templated structure \texttt{apply\_stretch\_t}. This visitor will statically
instantiate the correct \texttt{apply\_stretch\_t} with the correct dynamic type (\text{src.type().tid()}) and call a
non type-erased version of the function stretch after having cast the values of the images. However, for this to work we
still have to tweak the first implementation a little.

\begin{minted}[linenos]{C++}
  template <class T>
  image2d<float> stretch(const image2d<T>& src)
  {
    auto        res  = image2d<float>(src.width(), src.height());
    auto        span = src.values();
    const auto& vs   = src.get_value_set();
    std::transform(span.begin(), span.end(), res.values().begin(),
                   [&vs](auto val) -> float
                   {
                     auto tmp = vs.max();
                     return vs.template cast<float>(val) / vs.template cast<float>(tmp);
                   });
    return res;
  }
\end{minted}

We introduce a new tool: the value-set (line 6). This value-set is a type-erased way to provide basic operations on
types such as casting, division, addition, getting the global max etc. This powerful tool, also embedded in the image,
allow us to write the algorithm in a generic way lines 10-11.

Thanks to this design, we have been able to type-erase our image types so that our algorithms can be called through
python via bindings generated by pybind~\cite{jakob.2017.pybind11}. As an example, we can then call our stretch
algorithm this way:

\begin{minted}{python}
  import pylena as pln, imageio, numpy as np
  img_in = imageio.imread("lena.png")
  np_arr = np.array(img_in, dtype='int8')
  img = pln.image2d(np_arr)
  print(timeit.timeit('img_out = pln.stretch(img)', number=1000,
        globals=globals()))
  >> 0.24129085899949132 # Seconds for 1000 cycles

  # Using a type that isn't int8 or int16
  np_arr64 = np.array(img_in, dtype='int64')
  img64 = pln.image2d(np_arr64)
  print(timeit.timeit('img_out64 = pln.invert(img64)', number=1000,
        globals=globals()))
  >> 26.124844277999728 # Seconds for 1000 cycles
\end{minted}

We can observe a hundred time factor between the fast and optimized path and the slow dynamically dispatched path.

\section{Performances \& overhead}

\FIXME{TODO: courbes de performances mesurées depuis Python}

\section{JIT-based solutions: pros. and cons.}

\FIXME{TODO: état de l'art, schémas de fonctionnement du JIT}
