\chapter{A bridge between the static world and the dynamic world}
\label{chap:static_dynamic_bridge}

\lettrine[lines=2]{I}{n} the programming world, there are three main families of programming
language~\parencite{prechelt.2000.comparison}. There are (i) \emph{compiled} programming languages, such as C, C++, Rust
or Go, (ii) \emph{interpreted} programming languages, such as Python, PHP or Javascript, and (iii) hybrid
programming languages, such as Java or C\#. The latter have a fast compilation pass that compiles the source code into
an intermediate bytecode. Then, this bytecode is interpreted via an interpreter on the host (runner) machine.


\section{Introducing the static and dynamic bridge}

Many studies have been carried out to compare the advantages and disadvantages of each family of programming
languages~\parencite{boehm.1984.economics}. In this thesis we focus mainly on comparing the burden that are shouldered
by the maintainer and the end-user.


\subsection{Languages types}
\label{subsec:languages.types}

\paragraph{Compiled languages} From the maintainer point of view, there is a lot of burden to shoulder. First he must
decide whether he wants to distribute a package of source code or a package of binaries to the end-user. In the case of
source code, he requires the end-user to have a compiler infrastructure, supported and validated by the library, on the
end-user's machine, as well as all the source dependencies resolved via specific package managers such as cargo, conan
or vcpkg, or via the system-wide package manager.

If the maintainer distribute binaries, he must generate one version for each couple of Operating System, Processor
architecture he supports. Indeed, to generate a binary, there are many steps, as illustrated
in~\cref{fig:static.dynamic.compiled}. First the compiler does a pass to generate machine code for each translation
unit. There can be as many machine code as there are architecture and/or operating system supported. The maintainer may
want to support different operating systems (last two Windows and OSX version, a handful Linux or Unix distributions,
maybe mobile phone portages). Each of these OSes requires their own bundle. Additionally, the hardware may change, or the
maintainer may want to take advantage of some specific hardware when available (like vectorized SIMD instructions such
as SSE4, XOP, FMA4, AVX-512, etc.): this also requires the maintainer to multiply the number of binaries he compiles and
distributes. Finally, the linker resolves the dependencies of the program and assembles the final binary. At that time
the maintainer has to sort out how he wants to bundle the dependencies of his program. Should he statically link them
alongside the binary and distribute them, at the risk of having the size of his binary exploding? Or should he state
that the user has to install the dependencies on his system (via the system-wide package manager for instance) so that
the binary can run? The burden of handling the dependencies is then shifted to the end-user when installing the program.
Usually the package manager, such as \emph{apt}, \emph{yum} or \emph{pacman}, solves this transparently for the end-user
and the programs works ``out-of-the-box'' once installed, as illustrated in~\cref{fig:static.dynamic.compiled}. The
downside is that the maintainer has to publish many bundles of his package for each couple of Operating System,
Processor architecture he supports.

\begin{figure}[htbp]
  \centering
  \subfloat[Compile-time]{
    \includegraphics[width=.48\linewidth]{../figures/static_compiletime}
  }
  \hfil
  \subfloat[Runtime]{
    \includegraphics[width=.48\linewidth]{../figures/static_runtime}
  }
  \caption{Compiled languages: compile-time (a) vs. runtime (b).}
  \label{fig:static.dynamic.compiled}
\end{figure}

\paragraph{Interpreted languages} From the maintainer point of view, this is the ideal standpoint. It is easier to
distribute software via an interpreted language because only the source code, a dependency tree and the assets are
released in the distributed package. All the burden about resolving the dependencies and installing the framework to run
the script is shouldered by the end-user that is using the program. Indeed, as shown
in~\cref{fig:static.dynamic.dynamic.pipeline}, everything happens at runtime. The main advantage of this approach is to
build a very rich ecosystem as distributing, maintaining and using programs is very easy once integrated in a package
manager (often delivered alongside the language SDK natively, e.g. pip for Python). However, the most notable
disadvantage is the performance which is explained by the fact that the source code is not compiled into optimized
assembly code ready to be executed by the computer. Instead, the interpreter must do all the work in one go and, very
often, this is slow (at least the first pass). Nowadays, interpreters differentiate two use cases. One is opening the
console interpreter from the command line and typing commands to get the immediate interpreted results. This is called
the read-eval-print-loop (REPL)~\parencite{vanbinsbergen.2020.repl}. This use-case usually does not provide heavy
optimization because the user is likely prototyping his script and thus does not need it in the first place. The second
use case is when the interpreter parses files and/or libraries as a whole. In this use-case, it is likely that the files
do not change, while they are used a lot. It is then relevant for the interpreter to pay a pass to generate intermediate
bytecode that can be interpreted faster for the future passes onward. As an example, the Python programming language has
several implementations: CPython, PyPy, Jython or IronPython. CPython generate intermediate bytecode in \texttt{*.pyc}
files while Jython, IronPython and PyPy embed a Just-In-Time (JIT) compiler to generate resp. JVM bytecode, CLR (.NET)
bytecode, or a large variety of bytecode format.

\begin{figure}[htbp]
  \centering
  \includegraphics[width=.6\linewidth]{../figures/dynamic_pipeline}
  \caption{Interpreted languages: runtime}
  \label{fig:static.dynamic.dynamic.pipeline}
\end{figure}

\paragraph{Hybrid languages} The burden is shared evenly between the maintainer and the user, while remaining minimal.
Indeed, languages such as Java or C\# are in this category. Those programming languages need a compiling pass which is
designed to be fast, so that the feedback loop while prototyping remains fast. The result of the compilation is bytecode
which is then executed on a hosting Virtual Machine (VM) that the user must install on his computer. The main advantages
of this solution are the portability and the small distributed binary size. Indeed, in theory, any machine supporting
the VM may also support the program. Also, as the VM executes the bytecode and resolves system dependencies, the
distributed binary does not need to embed any system dependency. Finally, the user has the advantage of running a
compiled program which provides fast user experience. The goal of hybrid languages is to bring together the advantages
of both compiled and interpreted languages; no dependency management for the user, one small binary to distribute for
the maintainer, good execution performance, and fast feedback loop when prototyping (fast incremental compilation),
while minimizing the downsides; usually a garbage collector is working inside the VM to handle memory allocations and
de-allocations. In this regard, both Java and C\# have achieved this feat quite elegantly. In theory, VM can further
increase performance by implementing hot code detection which would compile the bytecode into native optimized machine
code. This area is still a field of research to this day (cf. Java
HotSpot~\parencite{xie.improving,kotzmann.2008.hotspot,halli.2016.java-hpc}).

\paragraph{To summarize} Interpreted and hybrid programming languages produces more portable artifacts and therefore are
easier to deploy in a dynamic environment. We summarize in~\cref{fig:static.dynamic.summary.pipeline} the different
approaches in order to be able to execute a binary from source code.

\begin{figure}[htbp]
  \centering
  \includegraphics[width=.99\linewidth]{../figures/comp_inter_hybrid_summary}
  \caption{Languages types: summary diagram}
  \label{fig:static.dynamic.summary.pipeline}
\end{figure}

\subsection{Static and dynamic information}

Compiled programming languages usually have poor support of introspection facilities. At best, static reflection is
available at compile-time, but dynamic reflection is not an option. The structure of the program does not change at
runtime. Some flexibility exists when delving into the area of hot-swapping dynamic libraries at runtime, however these
techniques drag alongside security-related issues that injecting possible foreign machine code into one's program may
generate. The only exception is Common Lisp. Indeed, there exists fully compliant implementation of this standard which
are compiler-only, and runtime introspection is part of the Common Lisp standard. Interpreted programming languages
usually have very developed introspection facilities. Dynamic reflection at runtime is possible and some language, such
as Python (notably via the functions \texttt{dir} and \texttt{getattr}). Hybrid programming languages usually offers
very good static and dynamic introspection facility at both compile-time and runtime, even if it means that runtime
facilities will hurt performance. Also, those languages are usually designed to be able to hot-swap code at runtime. It
is then possible to have the application running, recompile part of the binary of the application, replace the old
running binary by the new compiled one, all at runtime.

The next important step is to classify what information is known at \emph{compile-time} (machine/bytecode code
generation): we call it \emph{static} information; and what information is known at \emph{runtime} (program execution):
we call it \emph{dynamic} information. In image processing, we have, on the one hand, knowledge about the following
static information:
\begin{itemize}
  \item Image's value type (unit8, rgb8, complex, etc.),
  \item Image's dimension size (1D, 2D, 3D, etc.),
  \item Architecture of the hardware hosting the program (x86, ARM, PowerPC, GPU, etc.).
\end{itemize}
This means that, while the information may not be known at compile-time, we are able to write (or, more accurately,
generate) code dedicated for those common types that we know constitute a large portion of the use cases. Furthermore,
we can write optimized portion of code dedicated to handle some particular known types that the program will use when it
encounters them at runtime.
On the other hand, the following information are always dynamic:
\begin{itemize}
  \item Image's actual values,
  \item Image's actual size,
  \item Architecture of the hardware hosting the program (x86, ARM, PowerPC, GPU, etc.).
\end{itemize}
The library needs both information type (static and dynamic) however, even if some information are missing, it is not a
fatality and the library can still recover and work efficiently at runtime.

On another note, we notice that the architecture hosting the program is an information which is both static and dynamic.
This translates the complexity of this information. Indeed, the maintainer needs to guess the array of architectures he
wants to support and generate binaries for them (static). Also, the program needs to detect at runtime (dynamically) on
which hardware he is running to possibly leverage it to increase performance. This is an area of research on its own
called heterogeneous computing~\parencite{wong.2019.heterogeneous,brown.2019.heterogeneous}.


\subsection{Introducing our hybrid solution}

Image processing communities like to have bridges with interpretable language such as Python or Matlab, to interface
with their favorite tools, algorithms and/or facilities. As an example, with Python, the module
NumPy~\parencite{harris.2020.numpy} is a community standard which is heavily used. Henceforth, to broaden the usage of
our library, we should be able to provide a way to communicate between our library and NumPy. There is always a need for
genericity in both C++ and Python. Indeed, in C++ genericity is achieved via template programming, which is static,
whereas in Python genericity is achieved via duck typing, which is dynamic, as shown
in~\cref{fig:static.vs.dynamic.genericity}.

\begin{figure}[htbp]
  \centering
  \subfloat[C++ static genericity]{
    \includegraphics[width=2in]{../figures/cpp_static_code}
  }
  \hfil
  \subfloat[Python dynamic genericity]{
    \includegraphics[width=1.5in]{../figures/python_dynamic_code}
  }
  \caption{C++ Static (a) vs. Python Dynamic (b) genericity.}
  \label{fig:static.vs.dynamic.genericity}
\end{figure}

On the one hand, static polymorphism induces no indirection in the generated code as the type is known at compile-time.
It is then possible to generate optimized code for specific types. It is not possible to add a new supported type at
runtime as the code has already been compiled. On the other hand, dynamic polymorphism implies that there will be some
indirection when executing the code. Indeed, the code first needs to dispatch onto the appropriate function handling the
input types to perform the operation properly. Nevertheless, it is possible to add new supported type at runtime without
recompiling the library binary.

From the maintainer point of view, however, only distributing the C++ templated source code is a showstopper to the
usability of his library by a Python user, because he does not hand over binaries. Indeed, one caveat of using C++
template programming is that the C++ compiler cannot generate a binary until it knows which type (of image, of value)
will be used. But the maintainer does not know this information and the user (on Python's end) does not want to
recompile the generic library code each time he has another set of types to try out. From here, there are still
multiple ways to achieve our goal.

The first option is to embed and distribute, alongside the library, a JIT compiler whose job would be to generate the
binaries and bindings just as they are used. This solution brings speed (excluding the first run that includes the
compilation time) and unrestrained genericity. However, it binds both user and maintainer to the specificities of a
compiler vendor, which means loosing in platform portability.

Another option is to type-erase (dynamic polymorphism) our types to enable the use of various concrete types through a
single generic interface. This would translate into a class hierarchy whose concrete classes are the leaves (thus, whose
value types and dimensions are known). This induces a non-negligible performance overhead but enables us to keep the
genericity and portability at the cost of maintaining the class hierarchy.

Type generalization can also be considered. It is possible to cast everything into a super-type that is suitable for the
vast majority of cases. For instance, we could say that we have a super-type \texttt{image4D<double>} into which we can
easily promote subtypes such as \texttt{image2D<int>} or \texttt{image3D<float>}. Of course, we would lose the generic
aspect and induce non-negligible speed cost whereas we would keep the platform portability.

And finally there is the dynamic dispatch. It consists in embedding dynamic information about types at runtime, and in
dispatching (think of switch/case) to the correct facility that can handle those types. The obvious caveat is the cost
of maintenance induced by the genericity as we would have numerous possible dispatches that would grow in a
multiplicative way with the number of handled types, which is not very generic. On the other hand there is almost no
speed loss and the portability is guaranteed. Theoretical models exist that could bring solutions to lower the number of
dispatcher to write, such as multi-method~\parencite{pirkelbauer.2010.multimethods}. Unfortunately they are currently
not part of the C++ programming language.


\section{Designing the hybrid solution}

In Pylene we have chosen a hybrid solution midway between type-erasure and dynamic dispatch. The goal is to have a set
of known types for which we have no speed cost, as well as supporting other types to ensure we remain generic.
In~\parencite{gossec.2019.pybind} we provide a facility to expose our generic code to Python. As seen in the previous
chapter, it is not possible to bind C++ source code to Python. We need to have a compiled binary implementing Python
binding (we chose Pybind11~\parencite{jakob.2017.pybind11}) to be able to call C++ code from Python. In order to achieve
the binding without sacrificing the genericity and the performance, we have designed a solution in two steps. We do not
want to provide an abstract interface that will resolve the calls to access data on the call-site via virtual call
because it would be very slow when the C++ code is executed. This would defeat the purpose of having to rely on C++ in a
first place. However, it is possible to convert an abstract class into an instantiated concrete generic class whose
template parameter are known. This requires, however, to enumerate all the possible cases. With modern C++, it has
become possible to design \(n \times n\) dispatch without gigantic switch-case clauses.


\subsection{First step: converting back and forth}

The first step of our solution consists in designing a buffer class that holds all the information about an image:
dimension, underlying type, strides and pointer to data buffer. This class is named \texttt{ndimage\_buffer}. When
interfacing with Python, it is necessary to convert the Python image which is a \texttt{NumpPy.array} into our image
type and vise versa, converting our C++ image type back into a Python image. The purpose of this buffer image is to hold
all the information from the \texttt{NumpPy.array} to then instantiate a concrete C++ type. This process is illustrated
in~\cref{fig:type-erased.buffer}. The first pitfall here is due to a limitation from the abstraction interface used in
Python. Indeed, when using, for instance \emph{Scikit-Image}, it is not possible to differentiate a 2D multichannel
image from a 3D grayscale image because the image is always broken down to its most simple value and a 2D multichannel
image is turned into a 3-dimensional \texttt{NumpPy.array} containing a single 8-bits channel, the last dimension
contains only 3 elements at max but can theoretically contain more as the type system does not prevent that. To prevent
this confusion, the C++ wrapper code may choose between two strategies; first is to consider all 3D/1-channel image as
2D/RGB images by default, second is to let the user give the information. For the sake of simplicity, we have chosen the
first strategy.

\begin{figure}[htbp]
  \centering
  \includegraphics[width=.6\linewidth]{../figures/type-erased_buffer}
  \caption{Bridge from Python to C++ via Pybind11 and a type-erased C++ class.}
  \label{fig:type-erased.buffer}
\end{figure}

From the point of view of a practitioner, the code on the call-site (python side) should be as followed:
\begin{minted}{python}
  from skimage import data
  import numpy as np
  import Pylena as pln # our Python binding
  img = data.astronaut() # 2D-rgb8 image -> NumPy.ndarray(ndim=3, dtype='uint8')
  # pln.<any_algorithm>(img)
\end{minted}

The C++ code contains lots of glue code necessary to expose the module to Python. In this thesis we have chosen to work
with Pybin11~\parencite{jakob.2017.pybind11} which provides a modern API and is being actively maintained and improved.
The glue code exposing the Python module from C++ is given in~\cref{appendix:static-dynamic-bridge.pylena}. In order to
have a seamless interaction between Python's \texttt{NumPy.ndarray} and C++, we need to define a proper strategy to
convert the Python type into the C++ type without copying all data around. Pybind11 offers us two possibilities to
achieve this. The first one is to use the buffer protocol to pass around NumPy's buffer information to C++ in a way so
that C++ can properly interpret the data into a proper C++ class. The second one is to use a custom type-caster to
implicitly convert the Python type into a C++ type each time it is needed.

With the first method, one would need to write the following code on Python's side:
\begin{minted}{python}
  np_img = data.astronaut() # 2D-rgb8 image -> NumPy.ndarray(ndim=3, dtype='uint8')
  pln_img = pln.ndimage(np_img) # conversion into the C++ image type
  pln_img_ret = pln.<any_algorithm>(pln_img) # call to any C++ algorithm
  np_img_ret = pln_img.to_numpy(); # convert back into NumPy.ndarray
  # use np.<...>(np_img_ret) # use resulting image with NumPy
\end{minted}
Whereas the second method would require the user to only write the following code on Python's side:
\begin{minted}{python}
  np_img = data.astronaut() # 2D-rgb8 image -> NumPy.ndarray(ndim=3, dtype='uint8')
  np_img_ret = pln.<any_algorithm>(np_img) # implicit conversion with custom type-caster on C++ side
  # use np.<...>(np_img_ret) # use resulting image with NumPy
\end{minted}
Removing this conversion step is the major reason we have chosen the second method: the custom type-caster. The C++ code
for this part is given in~\cref{appendix:static-dynamic-bridge.ndimage}.

We are now all set and are able to convert back-and-forth a Python image into a C++ image and vise versa.

\subsection{Second step: multi-dispatcher (a.k.a. \(\protect n \times n\) dispatch)}

The second step of our hybrid solution is to dispatch the abstract buffer type coming from Python to an efficient
generic code. The naive way of doing so would be to include a gigantic switch-case clause in each algorithm
implementation and dispatch to the correct instantiated generic algorithm from there. Aside from being a nightmare to
maintain, the size of those clauses would grow several folds depending on the cardinality of the generic implementation.
For instance, for a generic dilation, there are 3 axes of cardinality: the underlying type, the dimension and the
structuring element shape. In the case where the library support 5 different structuring element shapes, 10 underlying
types and 6 dimension for the image, the switch-case statement would need to dispatch over 300 clauses. Also, each
supported algorithm would need to have dispatcher in their code. This solution defeats the purpose of genericity which
is to write less code in the first place. We need to design a solution to implement those dispatchers while keeping
our code short and efficient. The idea we took to solve this problem comes from the design of a C++ feature, the
variant, and especially the visitor, applied to image processing, as in~\parencite{bourdev.2011.runtimedispatch} for
instance. We need to have a way to write the implementation of the algorithm once while enumerating all the possible
cases. Also, if possible, the list of supported types should be written once at one place for maintenance purpose.


\paragraph{Simple dispatcher}

We then had the idea of writing a dispatcher. This dispatcher lists all the supported types and calls the given
callbacks forwarding the given arguments by instantiating a specific type. Let us try to expose to Python, for instance,
the generic existing algorithm for thresholding a binary image. The Python call-site code will look like this:
\begin{minted}{python}
  img_grayscale = skimage.data.grass()
  pln.operators.binary_threshold(img_grayscale)
\end{minted}
On the C++ side, we want to avoid writing code that looks like this:
\begin{minted}{C++}
  mln::ndbuffer_image binary_threshold(mln::ndbuffer_image input) {
    auto dim = input.dim();
    auto tid = input.tid();
    switch(dim) {
      case 1: // 1D image
        switch(tid) {
          case UINT8:
            if(auto* image_ptr = input.template cast_to<uint8_t, 1>(); image_ptr)
              return mln::binary_threshold(*image_ptr);
          case RGB8:
            // error support only RGB8 images
        }
        break;
      case 2: // 2D image
        // ...
        break;
      // ... 3D, 4D, ...
    }
  }
\end{minted}
Instead, it is possible to separate the dispatching code and the logical code entirely by using a templated operator,
the same way we use lambdas in the pattern \texttt{std::variant}/\texttt{std::visit}. For our binary threshold example,
the operator can be implemented just by writing the following code:
\begin{minted}{C++}
  // Operator templated by the dimension
  template <auto Dim>
  struct binary_threshold_op_t {
    // Function templated by the image type
    template <typename Img>
    mln::ndbuffer_image operator()(Img&& img) const {
      // Cast to a grayscale (information known) of the correct dimension
      if (auto* image_ptr = std::forward<Img>(img).template cast_to<std::uint8_t, Dim>(); image_ptr)
        // ACTUAL call to the generic algorithm
        return mln::binary_threshold(*image_ptr);
      else {
        std::runtime_error("Unable to convert the image to the required type.");
        return {};
      }
    }
  };
\end{minted}
This code allows us to dispatch over any number of dimensions. We are required to pass a grayscale image for the
algorithm so here the example is limited to dispatching over just one cardinality: the dimension. Let us now take a look
at how we can implement the dispatcher for our example to work. The dispatcher must take the dimension as first
parameter and any number of arguments to forward to the instantiated operator. The dispatcher then looks like the
following code:
\begin{minted}{C++}
template <template <auto> class Op, typename... Args>
auto dispatch_v(std::size_t dim, Args&&... args) {
  switch (dim) {
    case (1):
      return Op<1>{}(std::forward<Args>(args)...);
    case (2):
      return Op<2>{}(std::forward<Args>(args)...);
    case (3):
      return Op<3>{}(std::forward<Args>(args)...);
    /* ... */
  }
}
\end{minted}
The operator \texttt{Op} is instantiated with the correct dimension number. Then the \texttt{operator()} (parenthesis)
is called while taking as parameters the forwarded arguments passed to the dispatcher. In our case, it will instantiate
the type \texttt{binary\_threshold\_op\_t<2>} and then call the function
\mintinline{c++}/binary_threshold_op_t<2>.operator()(input)/, forwarding the input image to the underlying algorithm.
Indeed, using the dispatcher is as simple as writing \mintinline{c++}/dispatch_v<binary_threshold_op_t>(input.dim(),
input);/

The main advantage of this approach is that we respect all the requirements. First the logical code is bounded in the
operator, second, the supported types are all listed in one place (the dispatcher), only once. Also, while our example
is limited to one cardinality, any number of dispatcher can be piped to one after another to achieve the cardinality
wanted.


\paragraph{Double dispatcher}

Let us push our example to implement the mathematical morphology dilation operator. We now have two more generic axes to
cover: the structuring element shape and the underlying datatype. First, let us take a look at what the Python code may
look like:
\begin{minted}{python}
  img_grayscale = skimage.data.grass()
  rect = pln.se.rect2d(width=3, height=3)
  img_dil = pln.operators.dilate(img_grayscale, se)
\end{minted}
The first thing to notice is the need to add additional bindings to expose our C++ structuring elements. The glue code
to achieve this is given in~\cref{appendix:static-dynamic-bridge.se}. Let us take a look at our dilation operator:
\begin{minted}{C++}
template <auto Dim, typename T>
struct dilate_operator_t {
  template <typename Img, typename SE>
  mln::ndbuffer_image operator()(Img&& img, SE se) const {
    if (auto* image_ptr = std::forward<Img>(img).template cast_to<T, Dim>(); image_ptr)
      // ACTUAL call to the generic algorithm
      return mln::dilation(*image_ptr, se);
    else {
      std::runtime_error("Unable to convert the image to the required type.");
      return {};
    }
  }
};
\end{minted}
This operator needs double dispatch over two cardinalities: the dimension \texttt{Dim} and the value type \texttt{T}. We
can skip the dispatch of the structuring element's shape as we have made a \texttt{std::variant} of all the supported
structuring element for the sake of simplicity. Dispatching over the supported structuring elements can then be
offloaded upstream from the call of the double dispatch, just by calling \texttt{std::visit}. We can immediately notice
that there is an issue with our dilation operator. Indeed, there are two template parameters and our dispatcher
\texttt{dispatch\_v} does only handle one. We solve this issue by writing another intermediate operator dispatcher
\texttt{dilate\_operator\_intermediate\_t} serving as trampoline operator that will partially instantiate the final
operator \texttt{dilate\_operator\_t} along the dimension template parameter to feed it to the last dispatcher,
\texttt{dispatch\_t}:
\begin{minted}{C++}
template <auto Dim>
struct dilate_operator_intermediate_t {
  template <typename Img, typename SE>
  mln::ndbuffer_image operator()(Img&& img, SE&& se) const {
    // Partial instantiation
    return double_dispatch_t<dilate_operator_t, Dim>(
            input.sample_type(), std::forward<Img>(input), std::forward<SE>(se));
  }
};
\end{minted}
Dispatching the operator alongside two cardinalities (even three including the structuring element handled by
\texttt{std::variant}) would then become as simple as calling:
\begin{minted}{C++}
// dispatch the structuring elements through using std::visit for std::variant
return std::visit(
[&input](const auto& se_) { // dispatch over the trampoline
    return dispatch_v<dilate_operator_intermediate_t>(input.dim(), input, se_);
  }, se);
\end{minted}

In order for this to work, we need to piece together the final part of our puzzle, which is the double dispatch function
that will handle the last dispatch along the underlying data while forwarding the first dispatch along the dimension.
This dispatcher works the same as the simple one (\texttt{dispatch\_v}) but take an additional template parameter (here
\texttt{Dim}) that will be forwarded as-is to the given operator \texttt{Op}. The implementation then looks like this:
\begin{minted}{C++}
template <template <auto, typename> class Op, auto Dim, typename... Args>
auto double_dispatch_t(type_id tid, Args&&... args) {
  switch (tid) {
    case (type_id::INT8):
      return Op<Dim, std::int8_t>{}(std::forward<Args>(args)...);
    case (type_id::UINT8):
      return Op<Dim, std::uint8_t>{}(std::forward<Args>(args)...);
    case (type_id::DOUBLE):
      return Op<Dim, double>{}(std::forward<Args>(args)...);
      /* ... */
  }
}
\end{minted}
We have now presented all the techniques and design required to build operators that are agnostic from the supported
data-types, dimensions and/or additional data such as structuring elements. Indeed, the maintainer has gathered all the
logic about listing the supported data types and dimension in one place: the custom dispatcher. He just needs to
maintain those facilities to enable full support for all exposed algorithm, by default. This hybrid solution mixes
type-erasure and modern C++ facilities to allow maximum performance. Indeed, the dispatch is performed before entering
algorithms and the custom type-caster facility allows plugging C++'s image directly to the Python's image without having
any unnecessary copies. The only caveat would be the code bloat incurred by all the explicit instantiation leading to
compiling a larger and larger binary the more algorithms are being exposed. This can lead to performance issues due to
potential pre-fetching memory optimization missed or code locality issues~\parencite{badawy.2001.locality}. Another
point not covered right now would be a way to support arbitrary data types, possibly injected from Python, into C++.
Indeed, our hybrid solution only support the types provided by the library and listed in the dispatchers. It will
instantiate all the code relative to them and support all the combinations, but the user may be tempted to plug a
user-defined type from Python as an underlying image data-type. To allow this use-case, we introduce a new concept: the
\emph{value-set}. The value-set is a standard way to manipulate the underlying values. Through type-erasure, we can
either manipulate known underlying value type with native facilities (near-zero overhead), or fallback to a virtual call
that may report an error, or callback user-provided Python routine to manipulate unknown user values.


\subsection{Third and final step: type-erasure \& the value-set}

As common thread in this section, we will work on the \emph{stretch} algorithm which is naively defined
in~\cref{fig:stretch.naive.code}. We can represent the pipeline calling this algorithm from Python
in~\cref{fig:static_dyn.nxndispatcher}. The motivation here is to abstract away the logic related to the underlying type
inside the algorithm. In our example, it means reworking the lines 4 and 5 so that the value operations max and divide
does not appear in our algorithm anymore. Instead, they will be delegated to a \emph{value-set}. This would allow,
theoretically, having all algorithm working for every underlying value type possible (be they static, dynamic, custom,
injected from Python, etc.).

\begin{figure}[htbp]
  \begin{minted}[linenos,highlightlines={4-5}]{C++}
template <class T>
mln::image2d<float> naive_stretch(const mln::image2d<T>& src) {
  mln::image2d<float> res  = mln::transform(src, [](auto val) -> float {
    auto max = std::numeric_limits<T>::max();
    return static_cast<float>(val) / static_cast<float>(max);
  });
  return res;
}
\end{minted}
  \caption{Stretch algorithm, naive C++ version.}
  \label{fig:stretch.naive.code}
\end{figure}

\begin{figure}[htbp]
  \centering
  \includegraphics[width=.8\linewidth]{../figures/static_dynamic_bridge/nxndispatch_pipeline}
  \caption{Python to C++ pipeline algorithm through the \(n \times n\) dispatcher.}
  \label{fig:static_dyn.nxndispatcher}
\end{figure}



\paragraph{Introducing the value-set}

The \emph{value-set} is an abstraction layer around common operations needed when implementing an image processing
algorithm such as an addition, a multiplication, a type conversion, getting the maximum, etc. It can be defined in C++
as a class template whose parameter is the manipulated type. The following code shows how to define a value-set:
\begin{minted}{C++}
template <class T = void>
struct value_set {
  template <class U>
  U cast(T v) const { return static_cast<U>(v); }

  T max() const noexcept { return std::numeric_limits<T>::max(); }
  T min() const noexcept { return std::numeric_limits<T>::min(); }
  /* inf, sup, ... */

  T add(T l, T r) const noexcept { return l + r; }
  T sub(T l, T r) const noexcept { return l - r; }
  /* mod, pow, min, max, ... */
};
\end{minted}
We can see that the default parameter of the class template is \texttt{void}. Indeed, we use the same technique as what
is used in the standard library for all the comparison operators (\texttt{std:less}, \texttt{std::greater}, \ldots)
which is known as the ``diamond''~\parencite{lavavej.2012.transparent,munoz.2012.comparison} operator (or transparent
functions~\parencite{wakely.2013.transparent,horvath.2016.transparent}). It consists in providing a default (void)
specialization that accept any types (by templates) and forward them directly to the underlying operator. The following
code shows how to implement this specialization:
\begin{minted}{C++}
template <>
struct value_set<void> {
  template <class U, class T>
  U cast(T&& t) const { return static_cast<U>(std::forward<T>); }

  template <class T, class U>
  auto add(T&& l, U&& r) const noexcept { return std::forward<T>(l) + std::forward<U>(r); }
  template <class T, class U>
  auto sub(T&& l, U&& r) const noexcept { return std::forward<T>(l) - std::forward<U>(r); }
  /* ... */
};
\end{minted}
The full code of the value-set is given in~\cref{appendix:static-dynamic-bridge.mm.vs}. The template parameter is
shifted from the class to the member functions. It is also important to note that the member functions are not static,
which requires to instantiate the \texttt{value-set} before using it. It may sound like a disadvantage at first glance,
but it can be turned into an advantage later on. Indeed, this design allows a subclass to hold member variables which
will be crucial for injecting user-types from Python.

Now that we have designed how our value-set is intended to work, we can deduce that an image is able to provide its own
value-set. Indeed, an image knows what values it holds and thus is able to instantiate the proper value-set
corresponding to this type. The member function returning the value-set in the class template \texttt{ndimage<T, D>} is
then implemented as followed:
\begin{minted}{C++}
template <class T, std::size_t D>
class ndimage {
  /* ... */
  auto get_value_set() const noexcept {
    return value_set<T>{};
  }
};
\end{minted}

\begin{figure}[htbp]
  \centering
  \includegraphics[width=.55\linewidth]{../figures/static_dynamic_bridge/naive_stretch}
  \caption{Naive stretch algorithm, pipeline to perform operations on values.}
  \label{fig:static_dyn.naive_stretch}
\end{figure}

Let us recall our naive stretch algorithm presented earlier. The pipeline representing the operations on values inside
the algorithm is presented in~\cref{fig:static_dyn.naive_stretch}. Typically, this algorithm performs three operations
that are the responsibility of a value-set: getting the max, performing a cast, and performing a division. The first
step is then to use the value set shown above to abstract away those operations. The new algorithm is shown
in~\cref{fig:stretch.fast.code}.

\begin{figure}[htbp]
  \begin{minted}[linenos,highlightlines={3-4,6,7-8,9}]{C++}
template <class T>
mln::image2d<float> fast_stretch(const mln::image2d<T>& src) {
  auto                vs   = src.get_value_set();     // value-set for T
  auto                vs_f = mln::value_set<float>{}; // fast value-set for float
  mln::image2d<float> res  = mln::transform(src, [&vs, &vs_f](auto val) -> float {
    auto max  = vs.max();                     // returns T
    auto fval = vs.template cast<float>(val); // returns float
    auto fmax = vs.template cast<float>(max); // returns float
    return vs_f.div(fval, fmax);              // div directly returns float
  });
  return res;
}
\end{minted}
  \caption{Stretch algorithm, fast C++ version.}
  \label{fig:stretch.fast.code}
\end{figure}

\begin{figure}[htbp]
  \centering
  \includegraphics[width=.55\linewidth]{../figures/static_dynamic_bridge/fast_stretch}
  \caption{Fast stretch algorithm, pipeline to perform operations on values.}
  \label{fig:static_dyn.fast_stretch}
\end{figure}

We instantiate the value-set needed for \texttt{T} values and for \texttt{float} values on lines 3 and 4. Then the
maximum value is obtained via the value-set of \texttt{T} on line 6. Then a cast is performed via the value-set to get
floating point value on lines 7 and 8. Finally, a floating point division is performed on line 9 via the formerly
instantiates floating point value-set defined on line 4. Indeed, using the value-set instantiated for \texttt{T} would
have performed a Euclidean division, which would have resulted in a bug. Calling this algorithm from Python is as simple
as writing \mintinline{python}/ret = pln.fast_stretch(input)/ once it is exposed. The pipeline representing the actual
operations in the algorithm to access values is shown in~\cref{fig:static_dyn.fast_stretch}. The glue code to expose
this algorithm is given in~\cref{appendix:static-dynamic-bridge.mm.algos}.

\paragraph{Type-erasure interface for value-set}

Moving one step further, we ultimately want to be able to dynamically inject a value-set into our algorithm. In order to
achieve this feat, we need to design an abstract value-set as an interface so that a user can subclass it and provide
his own value set. This abstract value-set needs to work with \texttt{std::any} as input value-type in order to provide
a generic interface. Here, the genericity is achieved via type-erasure (the input value is type-erased into a
\texttt{std::any}). The interface looks like the following code (full code is given
in~\cref{appendix:static-dynamic-bridge.mm.vs}):
\begin{minted}{C++}
struct abstract_value_set {
  virtual ~abstract_value_set() {}

  virtual std::any max() const = 0;
  /* min, sup, inf, ... */

  virtual std::any add(const std::any& l, const std::any& r) const  = 0;
  virtual std::any div(const std::any& l, const std::any& r) const  = 0;
  /* sub, mult, ... */
};
\end{minted}
The important part here is to notice that all values (returned and passed as argument) are now type-erased behind a
\texttt{std::any}. From this interface, it is trivial to define the canonical subclasses for trivial types. We do this
by defining the class template \texttt{concrete\_value\_set} which is able to generate a concrete interface for any
given template type. The implementation will look like this:
\begin{minted}{C++}
template <typename T>
struct concrete_value_set : abstract_value_set {
  ~concrete_value_set() override {}

  template <class U>
  std::any cast(std::any v) const { return {static_cast<U>(std::any_cast<T>(v))}; }

  std::any max() const override { return {std::numeric_limits<T>::max()}; };
  /* min, sup, inf, ... */

  std::any add(const std::any& l, const std::any& r) const override {
    return {std::any_cast<T>(l) + std::any_cast<T>(r)};
  }
  std::any div(const std::any& l, const std::any& r) const override {
    return {std::any_cast<T>(l) / std::any_cast<T>(r)};
  }
  /* sub, mult, ... */
};
\end{minted}
This concrete value-set implements simple dispatch via casting the type-erased \texttt{std::any} into the wanted value
type to properly perform the operation. Thanks to this implementation, we are able to rewrite our stretch algorithm
using this value-set to perform the value operations. The new algorithm is shown
in~\cref{fig:stretch.virtual.dispatch.code}.

\begin{figure}[htbp]
  \begin{minted}[linenos,highlightlines={3-4,6,7-8,9}]{C++}
  template <class T>
  mln::image2d<float> virtual_dispatch_stretch(const mln::image2d<T>& src) {
    auto                vs   = mln::concrete_value_set<T>{};     // value-set for T
    auto                vs_f = mln::concrete_value_set<float>{}; // value-set for float
    mln::image2d<float> res  = mln::transform(src, [&vs, &vs_f](auto val) -> float {
      auto anymax  = vs.max();                                 // returns std::any
      auto fanyval = vs.template cast<float>(val);             // cast to float in std::any
      auto fanymax = vs.template cast<float>(anymax);          // cast to float in std::any
      return std::any_cast<float>(vs_f.div(fanyval, fanymax)); // div returns float
    });
    return res;
  }
\end{minted}
  \caption{Stretch algorithm, virtual dispatch version.}
  \label{fig:stretch.virtual.dispatch.code}
\end{figure}

\begin{figure}[htbp]
  \centering
  \includegraphics[width=.9\linewidth]{../figures/static_dynamic_bridge/virtual_dispatch_stretch}
  \caption{Virtual dispatch stretch algorithm, pipeline to perform operations on values.}
  \label{fig:static_dyn.virtual_dispatch_stretch}
\end{figure}

This algorithm uses two value sets (l.3 and l.4). One to get the maximum value corresponding to the original underlying
value type in the image \texttt{T} (l.6), and to properly cast the values into float values (l.7--8). The other one is
used to perform the floating point division (l.9). This algorithm is almost identical to the one given for
\texttt{fast\_stretch} earlier. Only the lines instantiating the value-set changes (l. 3--4) as well as the line handing
over the result (l. 9) where we added a downcast from \texttt{std::any}. The pipeline presenting the operations needed
to access values is presented in~\cref{fig:static_dyn.virtual_dispatch_stretch}.


\paragraph{Going forward: type-erasing the value entirely}

The need may arise where the user wants to handle images where the input value is abstracted away behind a dynamic
type-erased type. This happens when handling image with heterogeneous value-type (different channel number from one
value to another, optional information embed with the value, etc.). To handle this use-case, this value-type needs to be
aware of its own value-set to perform the required operations. To achieve this, the value must embed the value set (as a
pointer for instance) directly alongside the value. This embedding would allow writing such code possible:
\begin{minted}[highlightlines={10}]{C++}
class type_erased_value {
  type_erased_value add(const type_erased_value& rhs);
  /* ... */
};

void my_algo(ndimage<type_erased_value, Dim> img1,
              ndimage<type_erased_value, Dim> img2) {
  ndimage<type_erased_value, Dim> img_out = /* ... */;
  for (auto [v1, v2, out] : zip(img1.values(), img2.values(), img_out.values())) {
    out = v1.add(v2); // the value v1 knows how to perform the addition with v2
  }
}
\end{minted}

This code allows supporting a fallback facility when all the supported values have been exhausted. For instance, when
considering the previously defined \texttt{abstract\_value\_set}, and attempting to dispatch over all the supporting
native C++ type unwrapped from the given \texttt{std::any}, if no type is matched, we can attempt one final unwrap to
this type-erased value which is aware itself of how to perform the value operation. In pseudocode, it breaks down to the
following logic:
\begin{minted}[linenos,highlightlines={3,4-5,6,9-10}]{C++}
std::any value_set<type_erased_value>::add(const std::any& lhs, const std::any& rhs){
  abstract_value_set* vs = lhs.get_embedded_vs();
  if (lhs.type() == typeid(int) && rhs.type() == typeid(int)) {
    auto ret = std::any_cast<int>(lhs) + std::any_cast<int>; // unwrap, do the work
    return std::any{ret}; // rewrap value
  } else if (lhs.type() == typeid(float) && rhs.type() == typeid(float)) {
    /* ... same ... */
  } else {
    auto te_lhs = std::any_cast<type_erased_value>(lhs); // last attempt
    return lhs.add(rhs); // fallback on embedded value-set
  }
}
\end{minted}
First step is to conditionally attempt to cast the type-erased value over the supported native values (lines 3 and 6).
When the type is supported then we unwrap it and perform the operation before rewrapping it in a \texttt{std::any}, and
returning it. If we could not unwrap the value into a supported value-type, we make a last attempt on line 9 into our
type-erased value-type. If this attempt succeeds, we rely on the fact that this value-type is aware of its own value-set
and embed it to perform the required operation on line 10. The full code of the implementation for this value-set aware
value-type is given in~\cref{appendix:static-dynamic-bridge.mm.vs}. We have relied on metaprogramming techniques in
order to efficiently write the code that will do the work.

Thanks to this technique, we are able to write another version of our stretch algorithm which is shown
in~\cref{fig:stretch.virtual.dispatch.type.erased.code}.

\begin{figure}[htbp]
  \begin{minted}[linenos,highlightlines={7,9,11-13,16-17,21,23-24}]{C++}
template <class T>
mln::image2d<float> stretch_virtual_dispatch_type_erased_value(const mln::image2d<T>& src) {
  auto                vs   = mln::concrete_value_set<T>{};     // value-set for T
  auto                vs_f = mln::concrete_value_set<float>{}; // value-set for float
  mln::image2d<float> res  = mln::transform(src, [&vs, &vs_f](auto val) -> float {
    // simulate having an image<type_erased_value>
    auto anyval = std::any{val}; // std::any of T
                                  // type_erased_value of std::any of T aware of value-set of T
    auto abs_anyval = mln::type_erased_value{anyval, vs};
    // instantiate a value-set for type_erased_value
    auto abs_vs = mln::value_set<mln::type_erased_value>{abs_anyval};
    auto anyabs_anymax =
        abs_vs.max(); // returns std::any of type_erased_value
                      // cast underlying std::any of type_erased_value of std::any of T into
                      // std::any of type_erased_value of std::any of float aware of value-set for float
    auto anyabs_fanyval = abs_vs.template cast<T, float>(std::any{abs_anyval}, &vs_f);
    auto anyabs_fanymax = abs_vs.template cast<T, float>(anyabs_anymax, &vs_f);
    // dispatch on known type, find a type_erased_value, then call
    // anyabs_fanyval.div(anyabs_fanymax) to perform division which will call
    // the underlying value-set for float for this operation
    auto anyabs_fanyret = abs_vs.div(anyabs_fanyval, anyabs_fanymax);
    // convert result back into float for returning to the image
    auto anyfret = std::any_cast<mln::type_erased_value>(anyabs_fanyret).val();
    return std::any_cast<float>(anyfret);
  });
  return res;
}
\end{minted}
  \caption{Stretch algorithm, virtual dispatch with a type-erased value version.}
  \label{fig:stretch.virtual.dispatch.type.erased.code}
\end{figure}

\begin{figure}[htbp]
  \centering
  \includegraphics[width=.9\linewidth]{../figures/static_dynamic_bridge/virtual_dispatch_type_erased_value_stretch}
  \caption{Virtual dispatch stretch algorithm with a type-erased value, pipeline to perform operations on values.}
  \label{fig:static_dyn.virtual_dispatch_type_erased_value_stretch}
\end{figure}

This version is verbose because we do not yet support \texttt{mln::image2d<type\_erased\_value>} as a proper image type.
Thus, we need to first convert the value of type \texttt{T} into the value-set aware type-erased value type. This work
is done from lines 7 to 11. Then on lines 12 to 21 we perform the actual algorithmic work on the values. This is where
the dispatch mechanic, whose pipeline is shown in detail
in~\cref{fig:static_dyn.virtual_dispatch_type_erased_value_stretch}, will happen. Finally, on lines 23 and 24, we unwrap
the previously wrapped type-erased value into a float to return for the algorithm.


\paragraph{Everything comes to a full circle: injecting a value-set from Python}

We have seen how to write an algorithm independently from its underlying types on C++ side thanks to relying on an
abstraction layer: the value-set. This enables one fundamental feature which is code injection from Python. Indeed,
every Python value is a \texttt{pybind11::object} (which is in itself a wrapper around the C-type \texttt{PyObject}),
which is the generic way to refer to a non-trivially-convertible Python type we can write a value-set handling this
value type. The value-set handling Python data-type provides the following interface:

\begin{minted}[linenos,highlightlines={4,8,10,14-16,19-21,25}]{C++}
template <>
struct value_set<pybind11::object> : abstract_value_set
{
  value_set(pybind11::object python_vs_instance): vs_instance_(python_vs_instance) {}
  ~value_set() override {}

  template <typename U>
  std::any cast(const std::any& v) const { /* ... */ }

  std::any max() const override { {vs_instance_.attr("max")()}; }
  /* min, sup, inf, ... */

  std::any add(const std::any& l, const std::any& r) const override {
    auto pyl = std::any_cast<pybind11::object>(l);
    auto pyr = std::any_cast<pybind11::object>(r);
    return {vs_instance_.attr("add")(pyl, pyr)};
  }
  std::any div(const std::any& l, const std::any& r) const override {
    auto pyl = std::any_cast<pybind11::object>(l);
    auto pyr = std::any_cast<pybind11::object>(r);
    return {vs_instance_.attr("div")(pyl, pyr)};
  }
  /* max, min, sub, mult, ... */
private:
  pybind11::object vs_instance_;
};
\end{minted}

In this code we can clearly see at lines 4 and 25 that we are storing our Python's value-set instance into our class.
This is possible due to the fact that our value-set abstraction is not providing static class function but member
function. Hence, it is possible to offload the work of the value-set to a member variable at lines 10, 14--16 and 19--21
that will call the Python's value-set and get the wanted result. Also, at line 8 we use multiple techniques at once to
get the correct resulting cast from a Python type. Indeed, the cast is done on Python side before being converted back
into the corresponding C++ type. As such, we have to translate the wanted C++ type information into Python type
information to request the cast. Once the cast is done, we need to unwrap the Python type into the corresponding C++
type and rewrap it into our, now favorite, \texttt{std::any}. The full implementation of this facility is given
in~\cref{appendix:static-dynamic-bridge.mm.vs.py_value_set.hpp}.

On this particular matter, the user will find a Python abstract class to implement in order for his value-set to be
usable by the library. This abstract class is defined by the following Python code:

\begin{minted}{python}
# ABC stands for Abstract Base Class
class AbstractValueSet(ABC):  # AbstractValueSet is a metaclass that
                              # cannot be instantiated
  @abstractmethod # Forces the abstract semantic on the method: must be overridden
                  # in child classes
  def cast(self, value: Any, type_): pass
    if type_ in ["int", "float", "bool", "str"]:
      module = importlib.import_module('builtins')
      cls = getattr(module, type_)
      return cls(value)
    else:
      raise ValueError()
  @abstractmethod
  def max(self): return math.inf

  # ... min, sup, inf, ...

  @abstractmethod
  def add(self, lhs: Any, rhs: Any) -> Any: return lhs + rhs
  @abstractmethod
  def div(self, lhs: Any, rhs: Any) -> Any: return lhs / rhs

  # ... sub, mult, ...
\end{minted}

This abstract class provides a facility to cast a value into a given type from its representation as a string. It also
provides default/standard way of computing values. Those methods need to be overridden by a child class as they are all
tagged with the \texttt{@abstractmethod} attribute. The full code of this data structure is given
in~\cref{appendix:static-dynamic-bridge.python.vs.BaseValueSet.py}.

Let us assume our user wants to build an image whose value type are his own custom Python data structure. For the sake
of this example, we will name this specific value type~\texttt{MyStruct}. The Python structure will look
like this:
\begin{minted}{python}
class MyStruct:
  v_: Any
  def __init__(self, v: Any): self.v_ = v
  def getV(self) -> Any:      return self.v_
  def setV(self, v: Any):     self.v_ = v
\end{minted}
It is just a strong wrapper around a value with setters and getters. If we want to use this data structure as an image
value-type and downstream in our C++ library, we need to provide a value-set which is aware of how to handle this
value type properly. The user may want to write such a code:
\begin{minted}{python}
img = np.array([MyStruct(1), MyStruct(2), MyStruct(6.5), MyStruct(3.14)] * 10, ndmin=2)
pln_img = pln.stretch(img) # Error, C++ does not know how to handle a value of type MyStruct
\end{minted}
In this case, the user must provide his own value-set defined after the Python \texttt{AbstractValueSet} seen earlier.
Such a value-set would look like this:
\begin{minted}{python}
class MyValueSet(AbstractValueSet):
  def get_MyStruct__(self, v: Any):
    return v.getV() if isinstance(v, MyStruct) else v
  def cast(self, value: Any, type_):
    v = self.get_MyStruct__(value)
    return super().cast(v, type_)
  def max(self):
    return 255

  # ... min, sup, inf, ...

  def add(self, lhs: Any, rhs: Any) -> Any:
    l = self.get_MyStruct__(lhs)
    r = self.get_MyStruct__(rhs)
    return MyStruct(super().add(l, r))
  def div(self, lhs: Any, rhs: Any) -> Any:
    l = self.get_MyStruct__(lhs)
    r = self.get_MyStruct__(rhs)
    return MyStruct(super().div(l, r))

  # ... sub, mult, ...
\end{minted}
The full code of this implementation is given in~\cref{appendix:static-dynamic-bridge.python.vs.ExampleValueSet.py}.
With this information, we can now write the following Python code:
\begin{minted}{python}
img = np.array([MyStruct(1), MyStruct(2), MyStruct(6.5), MyStruct(3.14)] * 10, ndmin=2)
pln_img = pln.stretch(img, value_set=MyValueSet()) # This works !
\end{minted}
And this works fine.

On the C++ side, the maintainer just needs to write another version of the stretch algorithm supporting the Python
value-set which is shown in~\cref{fig:stretch.injected.python.code}.

\begin{figure}[htbp]
  \begin{minted}[linenos,highlightlines={4,5,6,7,8}]{C++}
    template <class T>
    mln::image2d<float> slow_stretch(const mln::image2d<T>& src, const mln::value_set<pybind11::object>& py_vs) {
      mln::image2d<float> res = mln::transform(src, [&py_vs](auto val) -> float {
        auto anymax  = py_vs.max();                        // returns std::any of pybind11:object
        auto anyval  = std::any{pybind11::cast(val)};      // converts to std::any of pybind11::object
        auto anyret  = py_vs.div(anyval, anymax);          // returns std::any of pybind11::object
        auto anyfret = py_vs.template cast<float>(anyret); // returns std::any of float
        return std::any_cast<float>(anyfret);              // returns float
      });
      return res;
    }
    \end{minted}
  \caption{Stretch algorithm, injected value-set from Python version.}
  \label{fig:stretch.injected.python.code}
\end{figure}

\begin{figure}[htbp]
  \centering
  \includegraphics[width=.95\linewidth]{../figures/static_dynamic_bridge/python_injected_value_set_stretch}
  \caption{Stretch algorithm with an injected value-set from Python code, pipeline to perform operations on values.}
  \label{fig:static_dyn.python_injected_value_set_stretch}
\end{figure}

The \mintinline{c++}/mln::value_set<pybind11::object>/ is constructed from the passed \texttt{value\_set} argument on
python side as it is a \texttt{pybind11::object}. The dispatcher then forward it to the algorithm as an additional
parameter. We then have actual Python call on lines 4, 6 and 7. The line 5 just wrap the image value into a Python
object so that it can then be forwarded to the Python code upstream, as described in the pipeline shown
in~\cref{fig:static_dyn.python_injected_value_set_stretch}. The line 7 casts the Python type into an actual C++ type
(wrapped into our \texttt{std::any} wrapper). Finally, the line 8 unwrap the float value to return it to the algorithm.


\section{Summary and continuation}

\subsection{Performance \& overhead}

In this chapter, we have designed many solutions to solve several kinds of issues related to injecting dynamic code in
our generic code. However, layering one abstraction layer after another, or even calling Python code does come with
performance cost. This is why we have run a benchmark to outline the cost of the proposed solutions. The full code of
the benchmark is given in~\cref{appendix:static-dynamic-bridge.benchmark}. This benchmark compares the four version of
our stretch algorithm. The result is shown in~\cref{table:static.dynamic.perfs}.

\begin{table}[htbp]
  \footnotesize
  \centering
  \begin{tabular}{l|ccc}
    \toprule
    Dispatch type                                                                                                   &
    Compute Time                                                                                                    &
    \(\Delta{}\)Compute Time
    \\ \midrule Native value-set with native C++ value-type (baseline)~\ref{fig:stretch.fast.code}
                                                                                                                    & \(0.0093s\) & \(0\) \\
    Value-set with virtual dispatch with native C++ value-type~\ref{fig:stretch.virtual.dispatch.code}              &
    \(0.1213s\)                                                                                                     &
    \(\times 13\)
    \\
    Value-set with virtual dispatch with C++ type-erased values~\ref{fig:stretch.virtual.dispatch.type.erased.code} &
    \(1.0738s\)                                                                                                     &
    \(\times 115\)
    \\
    Injected Python value-set with native C++ value-type~\ref{fig:stretch.injected.python.code}                     &
    \(21.5444s\)                                                                                                    &
    \(\times 2316\)
    \\
    \bottomrule
  \end{tabular}
  \caption{Benchmarks of all our version of the stretch algorithm.}
  \label{table:static.dynamic.perfs}
\end{table}

This benchmark shows that each time an abstraction layer is added on top of the baseline, the user must expect a
\(10\times\) slowness factor for his code performance. Also, calling Python code is immensely slower (\(2300\times\) !)
than the baseline. This renews the interest there is to recompile the templated C++ library with an additional known
type rather than injecting it from Python code. Being able to inject dynamic Python code eases prototyping and increase
the speed at which the user can write his code. However, the benchmark shows that this is not a viable solution once the
prototype needs to upgrade into to a production-ready program.


\subsection{Continuation: JIT-based solutions, pros. and cons.}

Our hybrid solution certainly has advantages, however the main disadvantage is the slowness of injecting our own types
from the Python side. There exists another solution that this thesis did not have the opportunity to study in-depth.
This solution is based on a well-known technology: the Just-In-Time (JIT) compilation which has been previously
illustrated in~\cref{fig:static.dynamic.dynamic.pipeline} (and which itself is based on the notion of generative
programming~\parencite{czarnecki.2000.generative}). Library such as AsmJit~\parencite{kobalicek.2011.asmjit} are able to
emit machine code directly by making call in C++ code. JIT is a technology already used by interpreted languages such as
Java or PHP to generate on-the-fly native and optimized machine code for the section of the source code that is
considered ``hot'' by the interpreter. A source code is ``hot'' when it is executed a lot: the end-user would gain
paying the compilation time once to have this code executed faster several times later on. When applying this strategy
to our problematic, it would mean that the user must be able to compile native machine code from the templated generic
C++ code by injecting the requested type when it is used. Such an operation shifts a heavy burden on the user, and it is
well-known that compiling C++ code is notably \emph{complicated} and \emph{slow}. In addition, the library needs to be
able to auto-generate Python binding once the C++ code is compiled, and to handle \emph{NumPy.ndarray} types in the
interface. There are several solutions to achieve this process.

The first solution is to use basic system call to the compilers to actually \emph{compile} C++ code once the templated
types are known and explicitly instantiated in the source code. This solution requires careful code-generation design
and that the user actually possess a compiling infrastructure on his computer. Furthermore, the user must resolve all
the library dependencies, such as \emph{freeimage} for IO etc. This solution is engineered in the VCSN
library~\parencite{demaille.2013.vcsn}. Indeed, each time the user declares a new automaton in his Jupyter notebook,
corresponding source code is compiled in the background and then cached. It is a very perilous solution to implement
when the final execution environment (OS, installed software) is not well-known in advance. Nowadays, the issue may be
lesser thanks to containerization, however, it still requires to maintain both the library and the container solution to
use it (Docker, Rocket, etc.).

The second solution is to use Cython~\parencite{behnel.2010.cython}. It is a transpiling infrastructure which transforms
a Python source code directly into C-language source code so that it can be compiled by a standard C compiler just by
linking against the Python/C API. This remove the burden of writing the careful code-generation routine, system-calls to
the C++ compiler and removes the need to resolve all the dependencies. This infrastructure takes care of everything for
the user. Cython even support C++ template code~\parencite{behnel.2022.cython-template} which is mandatory for our
use-case.

The third solution consists in relying on recent projects that are all relying on the LLVM infrastructure. We can
notably note AutoWIG~\parencite{fernique.2018.autowig}, Cppyy~\parencite{wimtlplavrijsen.2016.cppyy},
Xeus-cling~\parencite{quantstack.2021.xeus-cling} and Pythran~\parencite{guelton.2015.pythran}. AutoWIG has in-house
code based on LLVM/Clang to parse C++ code in order to generate and compile a Swig Python binding using the Mako
templating engine. AutoWIG, coupled with Cython would permit the user to, for instance, generate C code related to a
custom Python structure. Then a simple call to AutoWIG will parse the C code and inject it into the C++ library to
generate the appropriate bindings for the user. As for Cppyy, it is based on LLVM/Cling, a C++ interpreter, and can
directly interpret C++ code from a Python string. This enables injecting custom types easily, be they in Python code
(transpiled by Cython) or C++ code (directly interpreted by Cling). Afterwards, the infrastructure generates the
appropriate binding from the templated C++ library for the injected type. Xeus-cling is a ready-to-use Jupyter kernel
and allow the usage of C++ code directly from within a notebook. This completely bypass the need of Python bindings in
the first place and allow the user to use the library from within the notebook as if he was using a Python library.
Finally, Pythran is an ahead of time compiler for a subset of the Python language, with a focus on scientific computing.
It takes a Python module annotated with a few interface descriptions and turns it into a native Python module with the
same interface, but hopefully faster. Pythran takes advantages of multicore and SIMD instructions to turns its subset of
the Python language into heavily templated C++ code instantiated for particular optimized types. All those
infrastructures, however, come with a hefty cost in terms of binary size. Indeed, a C++ compiler is not small and
embarking it alongside the image processing library can easily impact greatly the final binary. For instance, without
the LLVM infrastructure the binary would weight around 3MB. However, with the LLVM infrastructure, the binary would
weight at the bare minimum 50MB. Also, these solutions may not be immediately faster. Indeed, when prototyping back and
forth with a variety of types, the user may not be eager to wait for long compilations times each time he is testing a
new iteration of his work. Despite those facts, those solutions offers great avenue of research for the future and the
author is eager to explore them.
