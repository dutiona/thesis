\chapter{Definition of images and algorithms}


\chapter{Rewriting an algorithm to extract a concept}



\subsection{Gamma correction}

Let us take the gamma correction algorithm as an example. The naive way to write this algorithm can be:

\begin{minted}[linenos]{C++}
template <class Image>
void gamma_correction(Image& ima, double gamma)
{
  const auto gamma_corr = 1 / gamma;

  for (int x = 0; x < ima.width(); ++x)
    for (int y = 0; y < ima.height(); ++y)
    {
      ima(x, y).r = std::pow((255 * ima(x, y).r) / 255, gamma_corr);
      ima(x, y).g = std::pow((255 * ima(x, y).g) / 255, gamma_corr);
      ima(x, y).b = std::pow((255 * ima(x, y).b) / 255, gamma_corr);
    }
}
\end{minted}

\noindent This algorithm here does the job but it also makse a lot of hypothesis. Firstly, we suppose that we can write
in the image via the \texttt{=} operator (l.9-11): it may not be true if the image is sourced from a generator function.
Secondly, we suppose that we have a 2D image via the double loop (l.6-7). Finally, we suppose we are operating on 8bits
range (0-255) RGB via \texttt{'.r'}, \texttt{'.g'}, \texttt{'.b'} (l.9-11). Those hypothesis are unjustified.
Intrinsically, all we want to say is \blockquote{\emph{For each value of \texttt{ima}, apply a gamma correction on
    it.}}. Let us proceed to make this algorithm the most generic possible by lifting those unjustified constraints one by
one.



\paragraph{Lifting RGB constraint:}
First, we get rid of the 8bits color range (0-255) RGB format requirement. The loops become:

\begin{minted}{C++}
  using value_t = typename Image::value_type;

  const auto gamma_corr = 1 / gamma;
  const auto max_val = std::numeric_limits<value_t>::max();

  for(int x = 0; x < ima.width(); ++x)
    for(int y = 0; y < ima.height(); ++y)
      ima(x, y) = std::pow((max_val * ima(x, y)) / max_val, gamma_corr);
\end{minted}

\noindent By lifting this constraint, we now require the type Image to define a nested type \texttt{Image::value\_type}
(returned by \texttt{ima(x, y)}) on which \texttt{std::numeric\_limits} and \texttt{std::pow} are defined. This way the
compiler will be able to check the types at compile-time and emit warning and/or errors in case it detects
incompatibilities. We are also able to detect it beforehand using a \texttt{static\_assert} for instance.



\paragraph{Lifting bi-dimensional constraint:}
Here we need to introduce a new abstraction layer, the \emph{pixel}. A \emph{pixel} is a couple $(point, value)$. The
double loop then becomes:

\begin{minted}{C++}
  for (auto&& pix : ima.pixels())
    pix.value() = std::pow((max_val * pix.value()) / max_val, gamma_corr);
\end{minted}

\noindent This led to us requiring that the type \emph{Image} requires to provide a method \texttt{Image::pixels()} that
returns \emph{something} we can iterate on with a range-for loop: this \emph{something} is a \emph{Range} of
\emph{Pixel}. This \emph{Range} is required to behave like an \emph{iterable}: it is an abstraction that provides a way
to browse all the elements one by one. The \emph{Pixel} is required to provide a method \texttt{Pixel::value()} that
returns a \emph{Value} which is \emph{Regular}~(see \cref{term.regular}). Here, we use \texttt{auto\&\&} instead of
\texttt{auto\&} to allow the existence of proxy iterator (think of \texttt{vector<bool>}). Indeed, we may be iterating
over a lazy-computed view~\ref{part.image_views}.



\paragraph{Lifting writability constraint:}
Finally, the most subtle one is the requirement about the \emph{writability} of the image. This requirement can be
expressed directly via the new C++20 syntax for \emph{concepts}. All we need to do is changing the template declaration
by:

\begin{minted}{C++}
template <WritableImage Image>
\end{minted}

\noindent In practice the C++ keyword \texttt{const} is not enough to express the \emph{constness} or the
\emph{mutability} of an image. Indeed, we can have an image whose pixel values are returned by computing $cos(x+y)$ (for
a 2D point). Such an image type can be instantiated as \emph{non-const} in C++ but the values will not be
\emph{mutable}: this type will not model the \emph{WritableImage} concept.



\paragraph{Final version}

\begin{minted}{C++}
template <WritableImage Image>
void gamma_correction(Image& ima, double gamma)
{
  using value_t = typename Image::value_type;

  const auto gamma_corr = 1 / gamma;
  const auto max_val = numeric_limits<value_t>::max();

  for (auto&& pix : ima.pixels())
    pix.value() = std::pow((max_val * pix.value()) / max_val, gamma_corr);
}
\end{minted}

\noindent When re-writing a lot of algorithms this way: lifting constraints by requiring behavior instead, we are able
to deduce what our \emph{concepts} needs to be. The real question for a \emph{concept} is: \blockquote{\emph{what
    behavior should be required?}}



\subsection{Dilation algorithm}
To show the versatility of this approach, we will now attempt to deduces the requirements necessary to write a classical
\emph{dilate} algorithm. First let us start with a naive implementation:

\begin{minted}[linenos]{C++}
template <class InputImage, class OutputImage>
void dilate(const InputImage& input_ima, OutputImage& output_ima)
{
  assert(input_ima.height() == output_ima.height()
    && input_ima.width() == output_ima.width());

  for (int x = 2; x < input_ima.width() - 2; ++x)
    for (int y = 2; y < input_ima.height() - 2; ++y)
    {
      output_ima(x, y) = input_ima(x, y)
      for (int i = x - 2; i <= x + 2; ++i)
        for (int j = y - 2; j <= y + 2; ++j)
          output_ima(x, y) = std::max(output_ima(x, y), input_ima(i, j));
    }
}
\end{minted}

\noindent Here we are falling into the same pitfall as for the \emph{gamma correction} example: there are a lot of
unjustified hypothesis. We suppose that we have a 2D image (l.7-8), that we can write in the \texttt{output\_image}
(l.10, 13). We also require that the input image does not handle borders, (cf. loop index arithmetic l.7-8, 11-12).
Additionally, the \emph{structuring element} is restricted to a $5 \times 5$ window (l.11-12) whereas we may need to
dilate via, for instance, a $11 \times 15$ window, or a sphere. Finally, the algorithm does not exploit any potential
properties such as the \emph{decomposability} (l.11-12) to improve its efficiency. Those hypothesis are, once again,
unjustified. Intrinsically, all we want to say is \blockquote{For each value of \texttt{input\_ima}, take the maximum
  of the $X \times X$ window around and then write it in \texttt{output\_ima}}.

To lift those constraints, we need a way to know which kind of \emph{structuring element} matches a specific algorithm.
Thus, we will pass it as a parameter. Additionally, we are going to lift the first two constraints the same way we did
for \emph{gamma correction}:

\begin{minted}{C++}
template <Image InputImage, WritableImage OutputImage, StructuringElement SE>
void dilate(const InputImage& input_ima, OutputImage& output_ima, const SE& se)
{
  assert(input_ima.size() == output_ima.size());

  for(auto&& [ipix, opix] : zip(input_ima.pixels(), output_ima.pixels())
  {
    opix.value() = ipix.value();
    for (const auto& nx : se(ipix))
      opix.value() = std::max(nx.value(), opix.value());
  }
}
\end{minted}

\noindent We now do not require anything except that the \emph{structuring element} returns the neighbors of a pixel.
The returned value must be an \emph{iterable}. In addition, this code uses the \texttt{zip} utility which allows us to
iterate over two ranges at the same time. Finally, this way of writing the algorithm allows us to delegate the issue
about the border handling to the neighborhood machinery. Henceforth, we will not address this specific point deeper in
this paper.




\subsection{Concept definition}
The more algorithms we analyze to extract their requirements, the clearer the \emph{concepts} become. They are slowly
appearing. Let us now attempt to formalize them. The formalization of the \emph{concept Image} from the information and
requirements we have now is shown in~\cref{concept.tables.definitions} for the required type definitions and
in~\cref{concept.tables.expressions} for the required valid expressions.

\begin{table}[htbp]

  \begin{scriptsize}
    \texttt{Let \emph{Ima} be a type that models the concept \emph{Image}. Let \emph{WIma} be a type that models the concept
      \emph{WritableImage}. Then \emph{WIma} inherits all types defined for \emph{Image}. Let \emph{SE} be a type that models
      the concept \emph{StructuringElement} . Let \emph{DSE} be a type that models the concept \emph{Decomposable}. Then
      \emph{DSE} inherits all types defined for \emph{StructuringElement}. Let \emph{Pix} be a type that models the concept
      \emph{Pixel}. Then we can define:}

    \smallskip
    \begin{tabular}{l|l|l|l|}
      \cline{2-4}
                                                   & \thead{Definition }                            & \thead{Description}   & \thead{Requirement}               \\
      % Image
      \cline{1-4}
      \multicolumn{1}{|c|}{\multirow{3}{*}{Image}} & \scriptsize{\texttt{Ima::const\_pixel\_range}} & \makecell{type of the
      range to iterate over                                                                                                                                     \\ all the constant pixels} & \makecell{models the concept \\
      \emph{ForwardRange}}                                                                                                                                      \\
      \cline{2-4}
      \multicolumn{1}{|c|}{}                       & \scriptsize{\texttt{Ima::pixel\_type}}         & type of a pixel       & models the concept \emph{Pixel}   \\
      \cline{2-4}
      \multicolumn{1}{|c|}{}                       & \scriptsize{\texttt{Ima::value\_type}}         & type of a value       & models the concept \emph{Regular}
      \\
      \cline{1-4}
      % Writable Image
      \multicolumn{1}{|c|}{\makecell{Writable                                                                                                                   \\ Image}} & \scriptsize{\texttt{WIma::pixel\_range}} & \makecell{type of the
      range to iterate over                                                                                                                                     \\ all the non-constant pixels} & \makecell{models the concept \\
      \emph{ForwardRange}}                                                                                                                                      \\
      \cline{1-4}
      % StructuringElement
      %  \multicolumn{1}{|c|}{StructuringElement} &  &  & \\
      %  \cline{1-4}
      % Decomposable
      %  \multicolumn{1}{|c|}{Decomposable} &  &  & \\
      %  \cline{1-4}
    \end{tabular}
  \end{scriptsize}
  \smallskip

  \caption{Concepts formalization: definitions}
  \label{concept.tables.definitions}
\end{table}


\begin{table}[htbp]

  \begin{scriptsize}
    \texttt{Let \emph{cima} be an instance of \emph{const Ima}. Let \emph{wima} be an instance of \emph{WIma}. Then all the
      valid expressions defined for \emph{Image} are valid for \emph{WIma}. Let \emph{cse} be an instance of \emph{const SE}.
      Let \emph{cdse} be an instance of \emph{const DSE}. Then all the valid expressions defined for \emph{StructuringElement}
      are valid for \emph{const DSE} Let \emph{cpix} be an instance of \emph{const Pix}. Then we have the following valid
      expressions:}

    \smallskip
    \begin{tabular}{l|l|l|l|}
      \cline{2-4}
                                                     & \thead{Expression}                  & \thead{Return Type} & \thead{Description} \\
      \cline{1-4}
      % Image
      \multicolumn{1}{|c|}{Image}                    & \texttt{cima.pixels()}              &
      \scriptsize{\texttt{Ima::const\_pixel\_range}} & \makecell{returns a range of
      constant pixels                                                                                                                  \\ to iterate over it} \\
      \cline{1-4}
      % Writable Image
      \multicolumn{1}{|c|}{\makecell{Writable                                                                                          \\ Image}} &\texttt{wima.pixels()} &
      \scriptsize{\texttt{WIma::pixel\_range}}       & \makecell{returns a range of pixels
      \\ to iterate over it} \\
      \cline{1-4}
      % StructuringElement
      \multicolumn{1}{|c|}{\makecell{Structuring                                                                                       \\ Element}} &\texttt{cse(cpix)} &
      \scriptsize{\texttt{WIma::pixel\_range}}       & \makecell{returns a range of the
      neighboring                                                                                                                      \\ pixels to iterate over it} \\
      \cline{1-4}
      % Decomposable
      \multicolumn{1}{|c|}{Decomposable}             & \texttt{cdse.decompose()}           &
      \scriptsize{\texttt{implementation defined}}   & \makecell{ returns a range of
      structuring                                                                                                                      \\ elements to iterate over it} \\
      \cline{1-4}
    \end{tabular}
  \end{scriptsize}
  \smallskip

  \caption{Concepts formalization: expressions}
  \label{concept.tables.expressions}
\end{table}

The \emph{concept Image} does not provide a facility to write inside it. To do so, we have refined a second
\emph{concept} named \emph{WritableImage} that provides the necessary facilities to write inside it. We say
\blockquote{\emph{WritableImage} refines \emph{Image}}.

The \emph{sub-concept ForwardRange} can be seen as a requirement on the underlying type. We need to be able to browse
all the pixels in a forward way. Its \emph{concept} will not be detailed here as it is very similar to \emph{concept} of
the same name~\cite{niebler.2018.mergingranges,niebler.2018.deepranges} (soon in the STL). Also, in practice, the
\emph{concepts} described here are incomplete. We would need to analyze several other algorithms to deduce all the
requirements so that our \emph{concepts} are the most complete possible. One thing important to note here is that to
define a simple \emph{Image concept}, there are already a large amount of prerequisites:
\label{term.regular}\emph{Regular}, \emph{Pixel} and \emph{ForwardRange}. Those \emph{concepts} are basic but are also
tightly linked to the \emph{concept} in the STL~\cite{carter.2018.concepts}. We refer to the STL \emph{concepts} as
\emph{fundamental concepts}. \emph{Fundamentals concepts} are the basic building blocks on which we work to build our
own \emph{concepts}. We show the C++20 code implementing those \emph{concepts} in~\ref{concept.cpp20.code}.

\begin{figure}[htbp]

  \begin{minipage}[l]{0.48\linewidth}
    \begin{minted}{C++}
template <class Ima>
concept Image = requires {
    typename Ima::value_type;
    typename Ima::pixel_type;
    typename Ima::const_pixel_range;
  } && Regular<Ima::value_type>
  && ForwardRange<Ima::const_pixel_range>
  && requires(const Ima& cima) {
    { cima.pixels() }
      -> Ima::const_pixel_range;
  };

template <class I>
using pixel_t = typename I::pixel_type;
template <class SE, class Ima>
concept StructuringElement = Image<Ima>
  && requires(const SE& cse,
       const pixel_t<Ima> cpix){
    { se(cpix) } -> Ima::const_pixel_range;
  };
\end{minted}
  \end{minipage}
  \hfill
  \begin{minipage}[r]{0.48\linewidth}
    \begin{minted}{C++}
template <class WIma>
concept WritableImage = requires Image<WIma>
  && requires {
    typename WIma::pixel_range;
  } && ForwardRange<WIma::pixel_range>
  && ForwardRange<WIma::pixel_range,
       WIma::pixel_type>
  && requires(WIma& wima) {
    { wima.pixels() } -> WIma::pixel_range;
  };

template <class DSE, class Ima>
concept Decomposable =
  StructuringElement<DSE, Ima>
  && requires(const DSE& cdse) {
    { cdse.decompose() }
      -> /*impl. defined*/;
  };
\end{minted}
  \end{minipage}

  \caption{Concepts in C++20 codes}
  \label{concept.cpp20.code}
\end{figure}




\chapter{Set vision of images types: version \& specialization}

Achieving true genericity in a satisfactory way is a complex problem that has components of different levels. The first
goal is to natively support as many sets of image type as possible. Natively means that there is no need for a
conversion from one type to a supertype under the hood. The second step is to support an abstraction layer above the
underlying data type for each pixel. Indeed, the structure of an image is decorrelated from the underlying data type.
The third step is to write image processing algorithms for each set of image type. Fourthly, the performance trade-off
shall be negligible if not null. Finally, the final step is to provide a high degree of friendliness for the end user.
Ease of use is always to be considered.

Considering the available options to achieve our goal, the parametric polymorphism approach is the way to go. This
allows the implementer to design image types and algorithms with behavior in mind. To illustrate this remark, let us
consider the set of supported set of image types shown in figure~\ref{fig.image.version}.

\begin{figure}[tbh]
  \centering
  \includegraphics[width=.5\linewidth]{figs/image_version.pdf}
  \caption{Set of supported image type.}
  \label{fig.image.version}
\end{figure}

To implement a basic image algorithm such as \texttt{fill} there really are two distinct ways of writing it. For the
set of images type whose data type is encoded into each pixel, one must traverse the image and set each pixel's color
to the new one. However, for the set of images type whose data type is encoded in a look-up table, one only has to
traverse the look-up table to set each color to the new one. This translates into two distinct algorithms shown
in~\cref{traverse.vs.LUT}:

\begin{figure}[tbh]
  \centering
  \scriptsize
  \subfloat[Writable image fill algorithm]{
    $fill(I, v)\colon \forall{p}\in\mathcal{D}, I(p) = v$
  }
  \hfil
  \subfloat[Image LUT fill algorithm]{
    $fill(I, v)\colon \forall{i}\in I.LUT, i = v$
  }

  \caption{Comparison of implementation of the \texttt{fill} algorithm for two
    families of image type.}
  \label{traverse.vs.LUT}
\end{figure}

More generally, we consider that the set of image type is formed of several subset of image types. In the example there
are two subsets: images whose pixel are writable and images whose data type are ordered in a look-up table. \emph{For
  each one of these subsets, if there is a way to implement an algorithm then we have a \emph{version} of this algorithm}.

Sometimes, it is possible to take advantage of a property on a particular image set, that may be correlated to an
external data, to write the algorithm in a more efficient way. When those properties are linked to the types, this is
call \emph{specialization}. For instance, when considering a dilation algorithm, if the structuring element (typically
the disc) is decomposable then we can branch on an algorithm taking advantage of this opportunity: decompose the
dilation disc into small vectors and apply each one of them on the image through multiple passes. The speed-up comparing
to a single pass with a large dilation disc is really significant (illustrated in~\ref{fig.gen.bench.square.disc}). The
code in~\ref{fig.decomp.dilate} illustrate how an algorithm can be written to take advantage of the structuring
element's decomposability property. The algorithm will first decompose the structuring element into smaller 1D periodic
lines. It will then recursively call itself with those lines to do the multi-pass and thanks to known optimizations on
periodic lines~\cite{vanherk.1992.localminmax}, it will be much faster.


\begin{figure}[tbh]
  \centering
  \begin{minted}{c++}
  template <Image Img, StructuringElement SE>
  auto dilate(Img img, SE se) {
    if (se.is_decomposable()) {
      lst_small_se = se.decompose();
      for (auto small_se : lst_small_se)
        img = dilate(img, small_se) // Recursive call
      return img;
    } else if (is_pediodic_line(se))
      return fast_dilate1d(img, se) // Van Herk's algorithm;
    else
      return dilate_normal(img, se) // Classic algorithm;
  }
  \end{minted}

  \caption{Dilate algorithm with decomposable structuring element.}
  \label{fig.decomp.dilate}
\end{figure}

The figure~\ref{fig.image.specialization} shows how an algorithm specialization may exists in a set of algorithms
version. In this figure there exists a specialization of algorithms when it is known that the data buffer has the
following property: its memory is contiguous. This implies that, for example, an algorithm like \texttt{fill} can be
implemented using low level and fast primitives such as \texttt{memset} to increase its efficiency.

\begin{figure}[tbh]
  \centering
  \includegraphics[width=.5\linewidth]{figs/image_version_specialization.pdf}
  \caption{Algorithm specialization within a set.}
  \label{fig.image.specialization}
\end{figure}

There are more details that go in depth when considering the distinction between runtime dispatch (dynamic) and
compile time dispatch (static) that the interested reader can consult in appendix~\ref{appendix.dispatch.dyn.static}.
Those details are not mandatory for the overall comprehension of this paper, hence why they are omitted here.


\chapter{Algorithm genericity: canvas}
\label{sec.algo}

FIXME : modèles de programmation pour traiter une image :
* modèle type kernel/tuile (CUDA, Halide) sur GPU
* modèle type pipeline pour traitement complex
* modèle type deep learning (conv conv conv = filtres) + fonction de réduction dans des réseaux
parrallèle entre canvas et modèles programmatic
dissociation du parcours et du traitement

In image processing there are a lot of common patterns when looking at algorithms, the most famous being \emph{for all
  pixel of image, do something to pixel}. But there are other more high-level similarities that we can leverage to have
more generic algorithm. First let us study two basic algorithm: dilation and erosion. The python code of such algorithm
is naively be given in figure~\ref{fig.erode.dilate}.

\begin{figure}[tbh]
  \centering
  \subfloat[Dilation]{
    \includegraphics[width=1.64in]{figs/dilation_code}
  }%
  \hfil
  \subfloat[Erosion]{
    \includegraphics[width=1.64in]{figs/erosion_code}
  }%
  \caption{Dilate vs. Erode algorithms.}
  \label{fig.erode.dilate}
\end{figure}

The algorithms are almost written the same way. The only change is the operation \emph{min} and \emph{max} when
selecting the value to keep. As such, we can easily see a way to factorize code by passing the operator as an argument.
The algorithms can then be rewritten as shown in figure~\ref{fig.erode.dilate.factorized}.

\begin{figure}[tbh]
  \centering
  \subfloat[Local algorithm with custom operator]{
    \includegraphics[width=3.28in]{figs/local_op_code}
  }%
  \vfil
  \smallskip
  \subfloat[Dilation (delegated)]{
    \includegraphics[width=1.64in]{figs/local_op_dilation_code}
  }%
  \hfil
  \subfloat[Erosion (delegated)]{
    \includegraphics[width=1.64in]{figs/local_op_erosion_code}
  }%
  \caption{New Dilate vs. Erode algorithms.}
  \label{fig.erode.dilate.factorized}
\end{figure}

\subsection{Taxonomy and canvas}

This approach leads to question a way to classify algorithm in families where this factorization can be possible, more
broadly. In essence there are three big families of algorithm when looking at the state of the art of image processing
today. The first is the point-wise family. In essence those algorithms only need to know the current pixel to do the
work. Those are the most basic algorithm. Some useful point-wise algorithms are: gamma correction, thresholding,
contrast correction projection. The second family consists in all the local algorithm. To work they need to know a
structuring element which is the window to consider around a pixel. Those algorithms introduce several very important
notions: neighborhood (of a pixel), separability and decomposability (of a structuring element) and border management.
Some useful local algorithms are: dilation, erosion, gradient, rank filter, median filter or hit or miss. Finally, the
third family consists in all the algorithm that propagate their computation while traversing the image. The chamfer
distance tranform is such an algorithm. Those algorithms are less friendly to factorization of code.

For the first family of algorithm, one can write them all with views so that factorizing code is hardly an issue. The
second family of algorithm may be abstracted behind an algorithm canvas where the user provides the work to do at each
point of the algorithm. For instance, a single pass local algorithm will always have shape given
in~\ref{fig.local.algorithm.canvas}:
\begin{figure}[tbh]
  \centering
  \begin{minted}[linenos,xleftmargin=17pt,gobble=2]{python}
  def local_canvas(img, out, se):
    # do something before outer loop
    for pnt in img.points():
      # do something before inner loop
      for nx in se(pnt):
        # do something inner loop
      # do something after inner loop
    # do something after outer loop
  \end{minted}

  \caption{Local algorithm canvas.}
  \label{fig.local.algorithm.canvas}
\end{figure}

This canvas can be customized to do a specific job, especially at the lines 2, 4, 6, 7 and 8. The user would then
provide callbacks and the canvas would do the job. This is especially useful when knowing that the canvas would handle
the border management (the user would provide a handling strategy like mirroring the image or filling it with a value).
The canvas would also take advantage of optimization opportunities (such as the decomposability of a structuring
element) that the user would probably forget, or not know, when first writing his local algorithm. Another advantage is
the opportunity to do more complex optimization such as parallelizing the execution or offloading part of the
calculation on a GPU. More generally, all optimization done through heterogeneous computing would be available by
default even if the user is not an area expert.

Despite all these advantages, one big disadvantage is the readability of the algorithm user-side. For instance, the
dilation algorithm is rewritten in figure~\ref{fig.local.algorithm.dilate}.

\begin{figure}[tbh]
  \centering
  \begin{minted}{python}
def dilate(img, out, se):
  do_nothing = lambda *args, **kwargs: None

  def before_inner_loop(img, out, pnt):
    out(pnt) = img(pnt)
  
  def inner_loop(ipix, opix, nx):
    out(pnt) = max(out(pnt), img(nx))

  local_canvas(img, out, se,
    before_outer_loop = do_nothing,
    before_inner_loop = before_inner_loop,
    inner_loop        = inner_loop,
    after_inner_loop  = do_nothing,
    after_outer_loop  = do_nothing
  )
  \end{minted}

  \caption{Local algorithm canvas.}
  \label{fig.local.algorithm.dilate}
\end{figure}

This way of thinking algorithms is far less readable than the classic way. The user does not see the loops happening and
it can becomes very messy when several passes are happening (closing, opening, hit or miss, etc.)

\vspace{1cm}


\section{Heterogeneous computing: a partial solution, canvas}
\label{sec.hc.canvas}

One of the key aspect driving genericity is performance. We have the following mantra: "write once, work for every
types, run everywhere". However when considering the "run" aspect, one has a lot to do. Indeed, nowadays, exploiting the
available resources to their maximum is long standing issue. There are many ongoing work on the subject, such as
SyCL~\cite{brown.2019.heterogeneous,wong.2019.heterogeneous}, Boost.SIMD~\cite{esterie.2014.boostsimd} or even
VCL~\cite{fog.2013.vcl}. After taking some distance to study the subject, we can infer that there are three main aspects
to consider when optimizing performance.

The first one, the most important one is the algorithm to use in function of certain set of data. This aspect is covered
by the C++ language and its builtin genericity tool: template metaprogramming. Indeed, we select the most optimized
algorithm for a particular set of data.

The second one is the ability for the code to be understood by the compiler so that is is further optimized during the
generation of the binary. Indeed, when compiling for the native architecture of a recent processor, one can use the most
recent assembly instructions to use wide vectorized registries (AVX512). The use of a recent compiler also brings the
help much needed.

Finally, the third aspect is not as trivial as the first two ones. It consists in studying the structure of an algorithm
to allow distributed computation. Sometimes algorithm are friendly to be distributed on several processing unit that
compute a part of the result concurrently. This is what we call parallelism. There exists several way to take advantage
of parallelism. First there is the use of several CPU unit on the host computer. Then there is the use of GPU units
working in combination with the CPU units to take advantage of the massive amount of core a graphic card can provide.
Finally there is the use of cloud computing which consists in using several "virtual" computers, each of them offering
of CPU and GPU units in order to compute a result. One should be aware that each time we introduce a new layer of
abstraction, there is a cost to orchestrate the computation, send the input data and retrieve the results. It is thus
very important to study case by case what is needed. Some solutions exists that abstract away completely the hardware
through a DSL~\footnote{Domain Specific Language} such as Halide~\cite{ragankelley.2013.halide}: the DSL compiler's job
will be to try very hard to make the most out of both the available (or targeted) hardware and the code. Those solutions
are not satisfactory for us as we want to avoid DSL and remain at code level. We are not developing a compiler: we are
working with it.

There is one true issue when studying parallel algorithm: it is wether they can be parallelized or not. Not all
algorithms can be parallelized. Some just intrinsically cannot, typically, algorithms that immediately need the result
at the previous iteration to compute the next iteration. There are still way to parallelize those one but it is not
trivial and will not be treated in this paper. What interest us are the algorithms whose structure is an accumulation
over a data type that can be defined as a monoid. We assert that every algorithm that can be rewritten as an
accumulation over a monoid can be parallelized and/or distributed. This model that consists in distributing computation
like an accumulation over a monoid data structure is also call the map-reduce. This model has two steps: the
distribution (map) and then the accumulation (reduce).

The map step will dispatch computation on sub-units with small set of data. The reduce step will retrieve and accumulate
all those resulting data, as soon as they are ready.

The accumulation algorithm has this form:
\begin{minted}[linenos]{C++}
  template <class In, class T, class Op>
  auto accumulate(In input, T init, Op op)
  {
    for(auto e : input)
    {
      init = op(init, e);
    }
    return init;
  }
\end{minted}

The loop line 4 can be split into several calculation units which are going to be distributed, and then be accumulated
later once the units have finished their computation.

The issue left here is the monoid. What exactly is a monoid here? A monoid is a data structure which operates over a set
of values, finite or infinite. This data structure must provide a binary operation which is closed and associative.
Finally, this data structure must also provide a neutral element (aka the identity). Some trivial monoids comes to mind:
\begin{itemize}
  \item boolean. For binary operation "and", identity is "true" whereas for binary operation "or", identity is "false".
  \item integer. For binary operation "-" and "+", identity is "0" whereas for binary operation "*" and "/", identity is
        "1".
  \item string. For concatenation, identity is empty string.
  \item optional value (also known as monadic structure in haskell programming language).
\end{itemize}
There are many more monoids, less trivial but very handy, such as the unsigned integer/max/0 set and the signed
integer/min/global max set.

This theory is extremely benefic to image processing as the most commonly used algorithms, the local algorithms, can all
be written in the form of an accumulation over the pixels of an image. The fact that finding an identity for the
operation processed by the algorithm is often quite trivial led us to the idea of canvas. A canvas is a standard way to
write an iteration over an image which abstract the underlying data structure. A canvas is a tool for the user to
provide its computation model based on events such as: "entering inner loop" or "exiting inner loop". The user can then
provide its operations as if he was writing his algorithm himself (restricted to the accumulation model). As the
maintainer of the library provides the canvas of execution, he can know also make change to take advantage of it. For
instance, computing a CUDA kernel at one point and dispatching it on GPU units is totally within scope and transparent
for the user of the library. Although there is a caveat: rewriting our algorithm in an accumulate form and chunking it
in fragments to feed to the canvas is definitely not intuitive. Indeed, we require our user to change his way of
thinking from the procedural paradigm to the event-driven paradigm. This approach is not new and is used in other
libraries such as Boost.Graph~\cite{siek.2001.boostgraph} for similar purposes.

\FIXME{quote C++Now 2019: Ben Deane “Identifying Monoids: Exploiting Compositional Structure in Code”}

\vspace{1cm}
\begin{verbatim}

## Issue: wide subject, a lot to consider

Genericity: "write once, work for every types, run everywhere"

The 'run' aspect can be a combination of:

* as fast as possible on a single CPU unit
* as fast as possible on thanks to using many CPU units
* as fast as possible on thanks to using many GPU units
* as fast as possible on thanks to using many computers (cloud) and their
  CPU/GPU units.

There is no simple answer to this question.

## Challenge: find the customization point

* Find what can be parallelized/distributed.
* Find an algorithm abstraction.

For us it is the local algorithms. They all have an accumulation pattern:

```cpp
  template <class In, class Out, class SE, class T, class Op>
  auto local_accumulate(In input, Out output, SE se, T init, Op op)
  {
    for(auto&& row : ranges::rows(input.pixels()))
      for(auto p : row)
      {
        auto v = init;
        for(auto nb : se(p))
          v = op(init, nb.val());
        init += v;
      }
    return init;
  }
```

## Data structure requirement: monoid

\small
Monoid, definition:

1. operates over a set of values, finite or infinite
2. provides a binary operation which is closed and associative
3. provide a neutral element, the identity

Easy monoids:

* boolean, *and*, "true" -> binary erosion
* boolean, *or*, "false" -> binary dilation
* unsigned integer, *max", "0" -> dilation
* signed integer, *min", "global max" -> erosion

## Solution: algorithms canvas

\scriptsize

* Algorithm canvas: standard way to iterate over an image to perform a
  computation
* Structure similar to accumulation for local algorithms
* Friendly for factorizing code
* Decoupling image traversing from actual computation
* Change of paradigm: procedural -> event-driven
* Non intuitive way to decompose an algorithm for the user
* Allow customization points by maintainer without restraining the user.

```cpp
  Image img_in = ..., img_out = ... ;
  StructuringElement se = ... ;
  auto z = ranges::view::zip(img_in.pixels(), img_out.pixels());
  for (auto rows : ranges::rows(z)) {
    user_callbacks->ExecuteAtLineStart();
    for (auto [px_in, px_out] : rows) {
      user_callbacks->EvalBeforeLocalLoop(px_in.val(), px_out.val());
      for (auto nbhs_in : se(px_in))
        user_callbacks->EvalInLocalLoop(nbhs_in.val(), px_in.val(),
                                        px_out.val());
      user_callbacks->EvalAfterLocalLoop(px_in.val(), px_out.val());
    }
  }
```
\end{verbatim}

\chapter{Library concepts: listing and explanation}

\section{Index}

\begin{table}[!htbp]
  \begin{scriptsize}
    \texttt{Let \emph{Idx} be a type that models the concept \emph{Index}. Let \emph{idx} and \emph{idy} be an instance of \emph{Idx}.
      Then we have the following valid expressions:}

    \smallskip
    \begin{tabular}{llll}
      \cline{1-4}
      \thead{Concept}                             & \thead{Expression}                   & \thead{Return Type}      & \thead{Description}                          \\
      \cline{1-4}
      \multicolumn{1}{c|}{\multirow{2}{*}{Index}} & \texttt{std::signed\_integral<Idx>}  & \texttt{std::true\_type} & Idx is a signed integral arithmetic type     \\
      %\cline{2-4}
      \multicolumn{1}{c|}{}                       & \texttt{idx + idy, idx - idy, \dots} & \texttt{Idx}             & supports all trivial arithmetical operations \\
      \cline{1-4}
    \end{tabular}
    \smallskip

    \caption{Concepts Index: expressions}
  \end{scriptsize}
  \label{concept.tables.index.expressions}
\end{table}


\section{Value}

\begin{table}[!htbp]
  \begin{scriptsize}
    \texttt{Let \emph{Val}, \emph{CmpVal} and \emph{OrdVal} be types that models the concepts resp. \emph{Value},
      \emph{ComparableValue} and \emph{OrderedValue}. Let \emph{val}, \emph{cmp\_val} and \emph{ord\_val} be instances
      of types resp. \emph{Val}, \emph{CmpVal} and \emph{OrdVal}. Then we have the following valid expressions:}

    \smallskip
    \begin{tabular}{llll}
      \cline{1-4}
      \thead{Concept}                                       & \thead{Expression}                     & \thead{Return Type}      & \thead{Description}                                                     \\
      \cline{1-4}
      \multicolumn{1}{c|}{Value}                            & \texttt{std::semiregular<Val>}         & \texttt{std::true\_type} & \makecell{\emph{Val} is a semiregular type. It can be:                  \\
      copied, moved, swapped, and default constructed.}                                                                                                                                                   \\
      \cline{1-4}
      \multicolumn{1}{c|}{\multirow{2}{*}{ComparableValue}} & \texttt{std::regular<CmpVal>}          & \texttt{std::true\_type} & \makecell{\emph{CmpVal} is a regular type. It is a semiregular          \\
      type that is equality comparable.}                                                                                                                                                                  \\
      %\cline{2-4}
      \multicolumn{1}{c|}{}                                 & \texttt{cmp\_val1 == cmp\_val2}        & \texttt{boolean}         & supports equality comparison                                            \\
      \cline{1-4}
      \multicolumn{1}{c|}{\multirow{2}{*}{OrderedValue}}    & \texttt{std::totally\_ordered<OrdVal>} & \texttt{std::true\_type} & \makecell{\emph{CmpVal} is a totally ordered as well as a regular type. \\
      Additionally the expressions must be equality preserving.}                                                                                                                                          \\
      %\cline{2-4}
      \multicolumn{1}{c|}{}                                 & \texttt{ord\_val1 < ord\_val2}         & \texttt{boolean}         & \multicolumn{1}{l}{\multirow{2}{*}{supports inequality comparisons}}    \\
      %\cline{2-3}
      \multicolumn{1}{c|}{}                                 & \texttt{ord\_val1 <= ord\_val2, \dots} & \texttt{boolean}         & \multicolumn{1}{l}{}                                                    \\
      \cline{1-4}
    \end{tabular}
    \smallskip

    \caption{Concepts Value: expressions}
  \end{scriptsize}
  \label{concept.tables.value.expressions}
\end{table}


\section{Point}

\begin{table}[!htbp]
  \begin{scriptsize}
    \texttt{Let \emph{Pnt} be a type that models the concept \emph{Point}. Let \emph{pnt} be an instance of type
      \emph{Pnt}. Then we have the following valid expressions:}

    \smallskip
    \begin{tabular}{llll}
      \cline{1-4}
      \thead{Concept}                             & \thead{Expression}                     & \thead{Return Type}      & \thead{Description}                                                  \\
      \cline{1-4}
      \multicolumn{1}{c|}{\multirow{4}{*}{Point}} & \texttt{std::regular<Pnt>}             & \texttt{std::true\_type} & \makecell{\emph{Pnt} is a regular type. It can be:                   \\
      copied, moved, swapped, and default constructed.                                                                                                                                       \\
      It also is equality comparable.}                                                                                                                                                       \\                                                                                                                                                               \\
      %\cline{2-4}
      \multicolumn{1}{c|}{}                       & \texttt{std::totally\_ordered<OrdVal>} & \texttt{std::true\_type} & \makecell{\emph{Pnt} is a totally ordered as well as a regular type. \\
      Additionally the expressions must be equality preserving.}                                                                                                                             \\
      %\cline{2-4}
      \multicolumn{1}{c|}{}                       & \texttt{pnt1 < pnt2}                   & \texttt{boolean}         & \multicolumn{1}{l}{\multirow{2}{*}{supports inequality comparisons}} \\
      %\cline{2-3}
      \multicolumn{1}{c|}{}                       & \texttt{pnt1 <= pnt2, \dots}           & \texttt{boolean}         & \multicolumn{1}{l}{}                                                 \\
      \cline{1-4}
    \end{tabular}
    \smallskip

    \caption{Concepts Point: expressions}
  \end{scriptsize}
  \label{concept.tables.point.expressions}
\end{table}


\section{Pixel}

\begin{table}[!htbp]

  \begin{scriptsize}
    \texttt{Let \emph{Pix} and \emph{OPix} be types that model the concepts resp. \emph{Pixel} and \emph{OutputPixel}.
      Then \emph{OutputPixel} inherits all types defined for \emph{Pixel}. Then we can define:}

    \smallskip
    \begin{tabular}{llll}
      \cline{1-4}
      \thead{Concept}                             & \thead{Definition}                                                                 & \thead{Description}                                 & \thead{Requirement}             \\
      \cline{1-4}
      \multicolumn{1}{c|}{\multirow{3}{*}{Pixel}} & \scriptsize{\texttt{value\_type}}                                                  & \makecell{Type of the value contained in the pixel.                                   \\ Cannot be constant or reference.}       & Models the concept \emph{Value}. \\
      %\cline{2-4}
      \multicolumn{1}{c|}{}                       & \scriptsize{\texttt{reference\_type}}                                              & \makecell{Type used to mutate the pixel's value.                                      \\ Can be a proxy.}       & Models the concept \emph{Pixel}   \\
      %\cline{2-4}
      \multicolumn{1}{c|}{}                       & \scriptsize{\texttt{point\_type}}                                                  & Type of the pixel's point.                          & Models the concept \emph{Point} \\
      \cline{1-4}
      \multicolumn{1}{c|}{OutputPixel}            & \multicolumn{3}{|c}{Inherit \emph{Pixel}'s definitions. No additional definition.}                                                                                         \\
      \cline{1-4}
    \end{tabular}
  \end{scriptsize}
  \smallskip

  \caption{Concepts Pixel: definitions}
  \label{concept.tables.pixel.definitions}
\end{table}

\begin{table}[!htbp]
  \begin{scriptsize}
    \texttt{Let \emph{pix}, \emph{opix}, \emph{pnt}, \emph{val} be instances of types resp. \emph{Pix}, \emph{OPix},
      \emph{Pix::point\_type} and \emph{Pix::value\_type}. Then we have the following valid expressions:}

    \smallskip
    \begin{tabular}{llll}
      \cline{1-4}
      \thead{Concept}                             & \thead{Expression}        & \thead{Return Type}           & \thead{Description}                                                \\
      \cline{1-4}
      \multicolumn{1}{c|}{\multirow{3}{*}{Pixel}} & \texttt{pix.val()}        & \texttt{Pix::reference\_type} & \makecell{Access the pixel's value for read and/or write purpose.} \\
      %\cline{2-4}
      \multicolumn{1}{c|}{}                       & \texttt{pix.point()}      & \texttt{Pix::point\_type}     & \makecell{Read the pixel's point.}                                 \\
      %\cline{2-4}
      \multicolumn{1}{c|}{}                       & \texttt{pix.shift(pnt)}   & \texttt{void}                 & Shift pixel's point coordinate base on \emph{pnt}'s coordinates.   \\
      \cline{1-4}
      \multicolumn{1}{c|}{OutputPixel}            & \texttt{opix.val() = val} & \texttt{void}                 & Mutate pixel's value.                                              \\
      \cline{1-4}
    \end{tabular}
    \smallskip

    \caption{Concepts Pixel: expressions}
  \end{scriptsize}
  \label{concept.tables.pixel.expressions}
\end{table}


\section{Ranges}

\begin{table}[!htbp]

  \begin{scriptsize}
    \texttt{Let \emph{MDRng}, \emph{OMDRng} and \emph{RMDRng} be types that model the concepts resp. \emph{MDRange},
      \emph{OutputMDRange} and \emph{ReversibleMDRange}. Then we can define:}

    \smallskip
    \begin{tabular}{llll}
      \cline{1-4}
      \thead{Concept}                               & \thead{Definition}                                                                   & \thead{Description}                                 & \thead{Requirement} \\
      \cline{1-4}
      \multicolumn{1}{c|}{\multirow{2}{*}{MDRange}} & \texttt{value\_type}                                                                 & \makecell{Type of the value contained in the range.                       \\ Cannot be constant or reference.} &  Models the concept \emph{Value}.   \\
      %\cline{2-4}
      \multicolumn{1}{c|}{}                         & \texttt{reference\_type}                                                             & \makecell{Type used to mutate the pixel's value.                          \\ Can be a proxy.}    & Models the concept \texttt{std::indirectly\_writable}                                 \\
      \cline{1-4}
      \multicolumn{1}{c|}{OutputMDRange}            & \multicolumn{3}{|c}{Inherit \emph{MDRange}'s definitions. No additional definition.}                                                                             \\
      \cline{1-4}
      \multicolumn{1}{c|}{ReversibleMDRange}        & \multicolumn{3}{|c}{Inherit \emph{MDRange}'s definitions. No additional definition.}                                                                             \\
      \cline{1-4}
    \end{tabular}
  \end{scriptsize}
  \smallskip

  \caption{Concepts Ranges: definitions}
  \label{concept.tables.ranges.definitions}
\end{table}

\begin{table}[!htbp]
  \begin{scriptsize}
    \texttt{Let \emph{mdrng}, \emph{omdrng}, \emph{rmdrng} and \emph{val} be
      instances of types resp. \emph{MDRng}, \emph{OMDRng}, \emph{RMDRng} and \emph{std::ranges::range\_value\_t<MDRng>}.
      Then we have the following valid expressions:}

    \smallskip
    \begin{tabular}{llll}
      \cline{1-4}
      \thead{Concept}                                         & \thead{Expression}                          & \thead{Return Type}  & \thead{Description}                          \\
      \cline{1-4}
      \multicolumn{1}{c|}{\multirow{2}{*}{MDRange}}           & \texttt{mdrng.begin()}                      & \texttt{unspecified} & \makecell{Return a forward iterator allowing \\ a traversing of the range.} \\
      %\cline{2-4}
      \multicolumn{1}{c|}{}                                   & \texttt{mdrng.end()}                        & \texttt{unspecified} & \makecell{Return a sentinel allowing to      \\know when the end is reached.}                                 \\
      \cline{1-4}
      \multicolumn{1}{c|}{OutputMDRange}                      & \makecell{\texttt{auto it = omdrng.begin()}                                                                       \\ \texttt{*it++ = val}}        & \texttt{void}                 & \makecell{Mutate a value inside the range \\ then increment the iterator's position}   \\
      \cline{1-4}
      \multicolumn{1}{c|}{\multirow{2}{*}{ReversibleMDRange}} & \texttt{rmdrng.rbegin()}                    & \texttt{unspecified} & \makecell{Return a forward iterator allowing \\ a traversing of the range \\ starting from the end.}                                              \\
      \multicolumn{1}{c|}{}                                   & \texttt{rmdrng.rend()}                      & \texttt{unspecified} & \makecell{Return a sentinel allowing to      \\ know when the end is reached.}                               \\
      \cline{1-4}
    \end{tabular}
    \smallskip

    \caption{Concepts Ranges: expressions}
  \end{scriptsize}
  \label{concept.tables.ranges.expressions}
\end{table}

\section{Domain}

\begin{table}[!htbp]

  \begin{scriptsize}
    \texttt{Let \emph{Dom}, \emph{SDom}, \emph{ShDom} be types that model the concepts resp. \emph{Domain},
      \emph{SizedDomain} and \emph{ShapedDomain}. Then \emph{Domain} inherits all types defined for \emph{MDRange}. Then
      \emph{SizedDomain} inherits all types defined for \emph{Domain} and \emph{ShapedDomain} inherits all types defined
      for \emph{SizedDomain}. Then we can define:}

    \smallskip
    \begin{tabular}{llll}
      \cline{1-4}
      \thead{Concept}                   & \thead{Definition}                                                                       & \thead{Description} & \thead{Requirement} \\
      \cline{1-4}
      \multicolumn{1}{c|}{Domain}       & \multicolumn{3}{|c}{Inherit \emph{MDRange}'s definitions. No additional definition.}                                                 \\
      \cline{1-4}
      \multicolumn{1}{c|}{SizedDomain}  & \multicolumn{3}{|c}{Inherit \emph{Domain}'s definitions. No additional definition.}                                                  \\
      \cline{1-4}
      \multicolumn{1}{c|}{ShapedDomain} & \multicolumn{3}{|c}{Inherit \emph{SizedDomain}'s definitions. No additional definition.}                                             \\
      \cline{1-4}
    \end{tabular}
  \end{scriptsize}
  \smallskip

  \caption{Concepts Domain: definitions}
  \label{concept.tables.domain.definitions}
\end{table}

\begin{table}[!htbp]
  \begin{scriptsize}
    \texttt{Let \emph{dom}, \emph{sdom}, \emph{shdom} and \emph{pnt} be instances of types resp. \emph{Dom}, \emph{SDom},
      \emph{ShDom} and \emph{Dom::value\_type}. Then we have the following valid expressions:}

    \smallskip
    \begin{tabular}{llll}
      \cline{1-4}
      \thead{Concept}                              & \thead{Expression}               & \thead{Return Type}          & \thead{Description}                                       \\
      \cline{1-4}
      \multicolumn{1}{c|}{\multirow{4}{*}{Domain}} & \texttt{Point<Dom::value\_type>} & \texttt{std::true\_type}     & \makecell{Domain's value models the \emph{Point} concept} \\
      %\cline{2-4}
      \multicolumn{1}{c|}{}                        & \texttt{dom.has(pnt)}            & \texttt{bool}                & \makecell{Check if a points is included in the domain.}   \\
      %\cline{2-4}
      \multicolumn{1}{c|}{}                        & \texttt{dom.empty()}             & \texttt{void}                & \makecell{Read the pixel's point.}                        \\
      %\cline{2-4}
      \multicolumn{1}{c|}{}                        & \texttt{dom.dim()}               & \texttt{void}                & Returns the domain's dimension.                           \\
      \cline{1-4}
      \multicolumn{1}{c|}{SizedDomain}             & \texttt{sdom.size()}             & \texttt{unsigned int}        & Returns the number of points inside the domain.           \\
      \cline{1-4}
      \multicolumn{1}{c|}{ShapedDomain}            & \texttt{shdom.extends()}         & \texttt{std::forward\_range} & \makecell{Return a range that yields the number           \\ of elements for each dimension.}                                              \\
      \cline{1-4}
    \end{tabular}
    \smallskip

    \caption{Concepts Domain: expressions}
  \end{scriptsize}
  \label{concept.tables.domain.expressions}
\end{table}




\clearpage

\begin{itemize}
  \item Définitions des types/catégories de types/propriétés de types
  \item Conceptualisation expliquer par l'exemple (papier rrpr) la relation Image (n) <-> Implem (m) avec n >> m
        \begin{itemize}
          \item Concepts déduis des algorithmes et non des types
          \item Plusieurs algos pour le même opérateur
          \item Plusieurs implems pour le même algo
        \end{itemize}
  \item Vision ensembliste des types d'images/algo
        \begin{itemize}
          \item versions d'algorithmes
          \item spécialisations d'algorithmes
        \end{itemize}
  \item canvas d'algorithmes
        \begin{itemize}
          \item factorisation
          \item opportunités d'optimisation (utilisation de propriétés, parallélisation)
        \end{itemize}
  \item listing et explications des concepts de la bibliothèque (images, élément structurant)
\end{itemize}